{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `LadderVAE` module\n",
    "In this notebook we test the different layers of LadderVAE model to check:\n",
    "- Whether all the necessary blocks/layers are here,\n",
    "- Whether the current version of the blocks/layers does the right thing (i.e., model flow, size of outputs given inputs, ...).\n",
    "\n",
    "We will do this by initializing a standard LadderVAE model (default options). Afterward, we will progressively adding supplementary features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/miniforge3/envs/lvae_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import ml_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/federico.carrara/Documents/projects/careamics/src/careamics/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lvae.lvae import LadderVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a first thing we create a model `config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a default config object\n",
    "def get_default_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.data = ml_collections.ConfigDict()\n",
    "    # config.data.sampler_type = SamplerType.DefaultSampler\n",
    "    config.data.sampler_type = None\n",
    "\n",
    "    config.model = ml_collections.ConfigDict()\n",
    "    config.model.use_vampprior = False\n",
    "    config.model.encoder = ml_collections.ConfigDict()\n",
    "    config.model.decoder = ml_collections.ConfigDict()\n",
    "    config.model.decoder.conv2d_bias = True\n",
    "\n",
    "    config.loss = ml_collections.ConfigDict()\n",
    "\n",
    "    config.training = ml_collections.ConfigDict()\n",
    "    config.training.batch_size = 32\n",
    "\n",
    "    config.training.grad_clip_norm_value = 0.5  # Taken from https://github.com/openai/vdvae/blob/main/hps.py#L38\n",
    "    config.training.gradient_clip_algorithm = 'value'\n",
    "    config.training.earlystop_patience = 100\n",
    "    config.training.precision = 32\n",
    "    config.training.pre_trained_ckpt_fpath = ''\n",
    "\n",
    "    config.git = ml_collections.ConfigDict()\n",
    "    config.git.changedFiles = []\n",
    "    config.git.branch = ''\n",
    "    config.git.untracked_files = []\n",
    "    config.git.latest_commit = ''\n",
    "\n",
    "    config.workdir = '/home/federico.carrara/Documents/projects/careamics/src/careamics/models/lvae'\n",
    "    config.datadir = ''\n",
    "    config.hostname = ''\n",
    "    config.exptname = ''\n",
    "    \n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for editing `config.model` fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_edit_model_config(config: ml_collections.ConfigDict) -> None:\n",
    "    \n",
    "    model = config.model\n",
    "\n",
    "    # Set the size of the latent spaces in the hierarchical levels\n",
    "    # NOTE: each entry is the latent space size of the corresponding level\n",
    "    # The number of entries should be equal to the number of levels\n",
    "    model.z_dims = [128, 128, 128, 128]\n",
    "\n",
    "    # Set the Encoder architecture\n",
    "    model.encoder.batchnorm = True\n",
    "    model.encoder.blocks_per_layer = 1\n",
    "    model.encoder.n_filters = 64\n",
    "    model.encoder.dropout = 0.1\n",
    "    model.encoder.res_block_kernel = 3\n",
    "    model.encoder.res_block_skip_padding = False\n",
    "\n",
    "    # Set the Decoder architecture\n",
    "    model.decoder.batchnorm = True\n",
    "    model.decoder.blocks_per_layer = 1\n",
    "    model.decoder.n_filters = 64\n",
    "    model.decoder.dropout = 0.1\n",
    "    model.decoder.res_block_kernel = 3\n",
    "    model.decoder.res_block_skip_padding = False\n",
    "    model.decoder.conv2d_bias = True\n",
    "\n",
    "    # Set common architecture parameters\n",
    "    model.res_block_type = 'bacdbacd'\n",
    "    model.gated = True\n",
    "    model.nonlin = 'elu'\n",
    "    model.merge_type = 'residual'\n",
    "    model.learn_top_prior = False\n",
    "    model.analytical_kl = False\n",
    "    model.mode_pred = False\n",
    "    model.no_initial_downscaling = True\n",
    "\n",
    "    # Whether to use a stochastic skip connection in the top-down pass\n",
    "    model.stochastic_skip = False\n",
    "\n",
    "    # Whether to predict_logvar, to be chosen among [None,'global','channelwise','pixelwise']\n",
    "    model.predict_logvar = None\n",
    "\n",
    "    # Set LC-related fields\n",
    "    model.multiscale_lowres_separate_branch = False\n",
    "    model.multiscale_retain_spatial_dims = True\n",
    "\n",
    "    # Whether to use stochastic block in the top-down pass\n",
    "    model.non_stochastic_version = False\n",
    "\n",
    "    # For enabling/disabling noise model\n",
    "    model.enable_noise_model = False\n",
    "    model.noise_model_ch1_fpath = ''\n",
    "    model.noise_model_ch2_fpath = ''\n",
    "    model.noise_model_type = 'gmm' #hist\n",
    "\n",
    "    # Additional parameters (most likely we don't need to change these)\n",
    "    model.monitor = 'val_psnr'  # {'val_loss','val_psnr'}\n",
    "    model.skip_nboundary_pixels_from_loss = None\n",
    "    model.logvar_lowerbound = -5  # -2.49 is log(1/12), from paper \"Re-parametrizing VAE for stablity.\"\n",
    "    model.var_clip_max = 20\n",
    "    model.img_shape = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to edit other `config` fields (needed to init the `LadderVAE` model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_edit_others_config(config: ml_collections.ConfigDict) -> None:\n",
    "    # Data fields\n",
    "    data = config.data\n",
    "\n",
    "    # Set info about input data shape\n",
    "    data.image_size = 64\n",
    "    data.multiscale_lowres_count = 1\n",
    "\n",
    "    # These are not used in the model, so no need to touch them\n",
    "    data.normalized_input = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utility function for custom `config` objects \n",
    "Actually we'd like to have a utility function that enables us to modify a subset of the config's fields that needs to be changed while doing different tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_config(\n",
    "    z_dims: List[int] = [128, 128, 128, 128],\n",
    "    blocks_per_layer: int = 1,\n",
    "    n_filters: int = 64,\n",
    "    learn_top_prior: bool = False,\n",
    "    no_initial_downscaling: bool = True,\n",
    "    stochastic_skip: bool = False,\n",
    "    predict_logvar: str = None,\n",
    "    multiscale_lowres_separate_branch: bool = False,\n",
    "    non_stochastic_version: bool = False,\n",
    "    image_size: int = 64\n",
    "):\n",
    "    \n",
    "    config = get_default_config()\n",
    "    default_edit_model_config(config)\n",
    "    default_edit_others_config(config)\n",
    "    \n",
    "    model = config.model\n",
    "    model.z_dims = z_dims\n",
    "    model.encoder.blocks_per_layer = blocks_per_layer\n",
    "    model.encoder.n_filters = n_filters\n",
    "    model.decoder.blocks_per_layer = blocks_per_layer\n",
    "    model.decoder.n_filters = n_filters\n",
    "    model.learn_top_prior = learn_top_prior\n",
    "    model.no_initial_downscaling = no_initial_downscaling\n",
    "    model.stochastic_skip = stochastic_skip\n",
    "    model.predict_logvar = predict_logvar\n",
    "    model.multiscale_lowres_separate_branch = multiscale_lowres_separate_branch\n",
    "    model.non_stochastic_version = non_stochastic_version\n",
    "\n",
    "    config.data.image_size = image_size\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to check the functioning of the different components of the `LadderVAE` model.\n",
    "\n",
    "Specifically, for each component of the model we check:\n",
    "1. Whether all the submodules and parameters required to define the model are provided/available.\n",
    "2. Whether that module is consistent, i.e., given a certain input it produces outputs of the expected size.\n",
    "3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. LVAE model initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check if the LVAE model constructor works as expected given the right inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create `config` object and initialize other required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_custom_config(image_size=128)\n",
    "\n",
    "# Additional required parameters (not in the config)\n",
    "data_mean = data_std = np.array([0.5, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize `LadderVAE` instance to check constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvae_model = LadderVAE(\n",
    "    config=config, \n",
    "    data_mean=data_mean, \n",
    "    data_std=data_std\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check model architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LadderVAE` constructor: test passed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bottom-Up pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. First Bottom-Up layer\n",
    "Basically, we need to test the following:\n",
    "- `LadderVAE.create_first_bottom_up()` -> check that it builds the model correctly given the input parameters (we use the same as the ones in `LadderVAE` constructor).\n",
    "- Check that the forward method of the resulting `nn.Sequential` is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lvae.layers import BottomUpLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lateral Contextualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Top-Down pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Likelihood Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lvae_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
