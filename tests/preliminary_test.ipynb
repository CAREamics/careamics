{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `LadderVAE` module\n",
    "In this notebook we test the different layers of LadderVAE model to check:\n",
    "- Whether all the necessary blocks/layers are here,\n",
    "- Whether the current version of the blocks/layers does the right thing (i.e., model flow, size of outputs given inputs, ...).\n",
    "\n",
    "We will do this by initializing a standard LadderVAE model (default options). Afterward, we will progressively adding supplementary features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/miniforge3/envs/lvae_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import ml_collections\n",
    "from torchinfo import summary\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/federico.carrara/Documents/projects/careamics/src/careamics/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lvae.lvae import LadderVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DEPRECATED: functions to create custom config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to create the default module `config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a default config object\n",
    "def get_default_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.data = ml_collections.ConfigDict()\n",
    "    # config.data.sampler_type = SamplerType.DefaultSampler\n",
    "    config.data.sampler_type = None\n",
    "\n",
    "    config.model = ml_collections.ConfigDict()\n",
    "    config.model.use_vampprior = False\n",
    "    config.model.encoder = ml_collections.ConfigDict()\n",
    "    config.model.decoder = ml_collections.ConfigDict()\n",
    "    config.model.decoder.conv2d_bias = True\n",
    "\n",
    "    config.loss = ml_collections.ConfigDict()\n",
    "\n",
    "    config.training = ml_collections.ConfigDict()\n",
    "    config.training.batch_size = 32\n",
    "\n",
    "    config.training.grad_clip_norm_value = 0.5  # Taken from https://github.com/openai/vdvae/blob/main/hps.py#L38\n",
    "    config.training.gradient_clip_algorithm = 'value'\n",
    "    config.training.earlystop_patience = 100\n",
    "    config.training.precision = 32\n",
    "    config.training.pre_trained_ckpt_fpath = ''\n",
    "\n",
    "    config.git = ml_collections.ConfigDict()\n",
    "    config.git.changedFiles = []\n",
    "    config.git.branch = ''\n",
    "    config.git.untracked_files = []\n",
    "    config.git.latest_commit = ''\n",
    "\n",
    "    config.workdir = '/home/federico.carrara/Documents/projects/careamics/src/careamics/models/lvae'\n",
    "    config.datadir = ''\n",
    "    config.hostname = ''\n",
    "    config.exptname = ''\n",
    "    \n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for editing `config.model` fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_edit_model_config(config: ml_collections.ConfigDict) -> None:\n",
    "    \n",
    "    model = config.model\n",
    "\n",
    "    # Set the size of the latent spaces in the hierarchical levels\n",
    "    # NOTE: each entry is the latent space size of the corresponding level\n",
    "    # The number of entries should be equal to the number of levels\n",
    "    model.z_dims = [128, 128, 128, 128]\n",
    "\n",
    "    # Set the Encoder architecture\n",
    "    model.encoder.batchnorm = True\n",
    "    model.encoder.blocks_per_layer = 1\n",
    "    model.encoder.n_filters = 64\n",
    "    model.encoder.dropout = 0.1\n",
    "    model.encoder.res_block_kernel = 3\n",
    "    model.encoder.res_block_skip_padding = False\n",
    "\n",
    "    # Set the Decoder architecture\n",
    "    model.decoder.batchnorm = True\n",
    "    model.decoder.blocks_per_layer = 1\n",
    "    model.decoder.n_filters = 64\n",
    "    model.decoder.dropout = 0.1\n",
    "    model.decoder.res_block_kernel = 3\n",
    "    model.decoder.res_block_skip_padding = False\n",
    "    model.decoder.conv2d_bias = True\n",
    "\n",
    "    # Set common architecture parameters\n",
    "    model.res_block_type = 'bacdbacd'\n",
    "    model.gated = True\n",
    "    model.nonlin = 'elu'\n",
    "    model.merge_type = 'residual'\n",
    "    model.learn_top_prior = False\n",
    "    model.analytical_kl = False\n",
    "    model.mode_pred = False\n",
    "    model.no_initial_downscaling = True\n",
    "\n",
    "    # Whether to use a stochastic skip connection in the top-down pass\n",
    "    model.stochastic_skip = False\n",
    "\n",
    "    # Whether to predict_logvar, to be chosen among [None,'global','channelwise','pixelwise']\n",
    "    model.predict_logvar = None\n",
    "\n",
    "    # Set LC-related fields\n",
    "    model.multiscale_lowres_separate_branch = False\n",
    "    model.multiscale_retain_spatial_dims = True\n",
    "\n",
    "    # Whether to use stochastic block in the top-down pass\n",
    "    model.non_stochastic_version = False\n",
    "\n",
    "    # For enabling/disabling noise model\n",
    "    model.enable_noise_model = False\n",
    "    model.noise_model_ch1_fpath = ''\n",
    "    model.noise_model_ch2_fpath = ''\n",
    "    model.noise_model_type = 'gmm' #hist\n",
    "\n",
    "    # Additional parameters (most likely we don't need to change these)\n",
    "    model.monitor = 'val_psnr'  # {'val_loss','val_psnr'}\n",
    "    model.skip_nboundary_pixels_from_loss = None\n",
    "    model.logvar_lowerbound = -5  # -2.49 is log(1/12), from paper \"Re-parametrizing VAE for stablity.\"\n",
    "    model.var_clip_max = 20\n",
    "    model.img_shape = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to edit other `config` fields (needed to init the `LadderVAE` model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_edit_others_config(config: ml_collections.ConfigDict) -> None:\n",
    "    # Data fields\n",
    "    data = config.data\n",
    "\n",
    "    # Set info about input data shape\n",
    "    data.image_size = 64\n",
    "    data.multiscale_lowres_count = 1\n",
    "\n",
    "    # These are not used in the model, so no need to touch them\n",
    "    data.normalized_input = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utility function for custom `config` objects \n",
    "Actually we'd like to have a utility function that enables us to modify a subset of the config's fields that needs to be changed while doing different tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_config(\n",
    "    z_dims: List[int] = [128, 128, 128, 128],\n",
    "    blocks_per_layer: int = 1,\n",
    "    n_filters: int = 64,\n",
    "    learn_top_prior: bool = False,\n",
    "    no_initial_downscaling: bool = True,\n",
    "    stochastic_skip: bool = False,\n",
    "    predict_logvar: str = None,\n",
    "    multiscale_lowres_separate_branch: bool = False,\n",
    "    non_stochastic_version: bool = False,\n",
    "    image_size: int = 64,\n",
    "    multiscale_lowres_count: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    NOTE: `len(z_dims)` determines the number of hierarchical levels (e.g., number of `BottomUpLayers`)\n",
    "    in the model. The information is stored in the `self.n_layers` attribute.\n",
    "    \"\"\"\n",
    "    \n",
    "    config = get_default_config()\n",
    "    default_edit_model_config(config)\n",
    "    default_edit_others_config(config)\n",
    "    \n",
    "    model = config.model\n",
    "    model.z_dims = z_dims\n",
    "    model.encoder.blocks_per_layer = blocks_per_layer\n",
    "    model.encoder.n_filters = n_filters\n",
    "    model.decoder.blocks_per_layer = blocks_per_layer\n",
    "    model.decoder.n_filters = n_filters\n",
    "    model.learn_top_prior = learn_top_prior\n",
    "    model.no_initial_downscaling = no_initial_downscaling\n",
    "    model.stochastic_skip = stochastic_skip\n",
    "    model.predict_logvar = predict_logvar\n",
    "    model.multiscale_lowres_separate_branch = multiscale_lowres_separate_branch\n",
    "    model.non_stochastic_version = non_stochastic_version\n",
    "\n",
    "    config.data.image_size = image_size\n",
    "    config.data.multiscale_lowres_count = multiscale_lowres_count\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to check the functioning of the different components of the `LadderVAE` model.\n",
    "\n",
    "Specifically, for each component of the model we check:\n",
    "1. Whether all the submodules and parameters required to define the model are provided/available.\n",
    "2. Whether that module is consistent, i.e., given a certain input it produces outputs of the expected size.\n",
    "3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `get_config()` function to create `config` dictionary for the few customizable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(\n",
    "    image_size: int = 64,\n",
    "    z_dims: List[int] = [128, 128, 128, 128],\n",
    "    n_filters: int = 64,\n",
    "    dropout: float = 0.1, \n",
    "    nonlin: str = \"elu\",\n",
    "    enable_noise_model: bool = False,\n",
    "    multiscale_lowres_count: int = 1,\n",
    "    analytical_kl: bool = True,\n",
    ") -> ml_collections.ConfigDict:\n",
    "    config = ml_collections.ConfigDict()\n",
    "    \n",
    "    config.image_size = image_size\n",
    "    config.z_dims = z_dims\n",
    "    config.n_filters = n_filters\n",
    "    config.dropout = dropout\n",
    "    config.nonlin = nonlin\n",
    "    config.enable_noise_model = enable_noise_model \n",
    "    config.multiscale_lowres_count = multiscale_lowres_count\n",
    "    config.analytical_kl = analytical_kl\n",
    "    \n",
    "    return config\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. LVAE model initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check if the LVAE model constructor works as expected given the right inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create `config` object and initialize other required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "\n",
    "# Additional required parameters (not in the config)\n",
    "data_mean = data_std = np.array([0.5, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize `LadderVAE` instance to check constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GaussianLikelihood] PredLVar:pixelwise LowBLVar:-5\n",
      "[LadderVAE] Stoc:True RecMode:False TethInput:False TargetCh: 2\n"
     ]
    }
   ],
   "source": [
    "lvae_model = LadderVAE(\n",
    "    config=config, \n",
    "    data_mean=data_mean, \n",
    "    data_std=data_std\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LadderVAE` constructor: test passed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bottom-Up pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. First Bottom-Up layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we tested `LadderVAE` constructor, meaning that we implicitly tested that `LadderVAE.create_first_bottom_up()` works.\n",
    "\n",
    "Therefore we are left to test that:\n",
    "- `LadderVAE.create_first_bottom_up()` builds the model correctly given the input parameters.\n",
    "- The forward method of the resulting `first_bottom_up` is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GaussianLikelihood] PredLVar:pixelwise LowBLVar:-5\n",
      "[LadderVAE] Stoc:True RecMode:False TethInput:False TargetCh: 2\n"
     ]
    }
   ],
   "source": [
    "# Define custom config\n",
    "config = get_config(\n",
    "    image_size=64,\n",
    "    z_dims=[128, 128, 128, 128],\n",
    "    n_filters=64,\n",
    "    dropout=0.1,\n",
    "    nonlin=\"elu\",\n",
    "    enable_noise_model=False,\n",
    "    multiscale_lowres_count=1,\n",
    "    analytical_kl=True\n",
    ")\n",
    "\n",
    "# Initialize a LadderVAE instance\n",
    "lvae_model = LadderVAE(config=config, data_mean=np.empty((32, 1)), data_std=np.empty((32, 1)))\n",
    "\n",
    "# Extract the first bottom-up layer\n",
    "first_bottom_up = lvae_model.first_bottom_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the structure using `torchinfo.summary`. This allows to check also whether the `forward` method works correctly.\n",
    "\n",
    "**NOTE:** We assume that:\n",
    "- Input patches have size `(1, 64, 64)`.\n",
    "- The block doesn't do **downsampling**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Sequential                               [1, 1, 64, 64]            [1, 64, 64, 64]           --\n",
       "├─Conv2d: 1-1                            [1, 1, 64, 64]            [1, 64, 64, 64]           640\n",
       "├─ELU: 1-2                               [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
       "├─BottomUpDeterministicResBlock: 1-3     [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
       "│    └─ResidualBlock: 2-1                [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
       "│    │    └─Sequential: 3-1              [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
       "│    │    │    └─BatchNorm2d: 4-1        [1, 64, 64, 64]           [1, 64, 64, 64]           128\n",
       "│    │    │    └─ELU: 4-2                [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
       "│    │    │    └─Conv2d: 4-3             [1, 64, 64, 64]           [1, 64, 64, 64]           36,928\n",
       "│    │    │    └─Dropout2d: 4-4          [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
       "│    │    │    └─BatchNorm2d: 4-5        [1, 64, 64, 64]           [1, 64, 64, 64]           128\n",
       "│    │    │    └─ELU: 4-6                [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
       "│    │    │    └─Conv2d: 4-7             [1, 64, 64, 64]           [1, 64, 64, 64]           36,928\n",
       "│    │    │    └─Dropout2d: 4-8          [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
       "===================================================================================================================\n",
       "Total params: 74,752\n",
       "Trainable params: 74,752\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 305.14\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 10.49\n",
       "Params size (MB): 0.30\n",
       "Estimated Total Size (MB): 10.80\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    model=first_bottom_up,\n",
    "    input_size=(1, 64, 64),\n",
    "    batch_dim=0,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "    depth=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The parameters that can influence the structure of `first_bottom_up` layer are:\n",
    "- `self.no_initial_downscaling` -> if `False`, the `stride` of the initial `Conv2d` block is set to `2`. This parameters influences this layer only!\n",
    "- `self.encoder_n_filters` -> sets the number of channels within **all** the *Encoder* layers (recall that all the layers share the same number of channels).\n",
    "- `self.encoder_res_block_kernel`, `self.encoder_res_block_skip_padding`, `self.res_block_type` -> set the specifics of residual blocks throughout all the *Encoder* layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Bottom-Up Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the previous layer, we have to test that:\n",
    "- `LadderVAE.create_bottom_up_layers()` builds the model correctly given the input parameters.\n",
    "- The forward method of the resulting `bottom_u_layers` module list is consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the structure using `torchinfo.summary`. This allows to check also whether the `forward` method works correctly.\n",
    "\n",
    "**NOTE:** We assume that:\n",
    "- Input patches have size `(1, 64, 64)`.\n",
    "- `first_bottom_up` uses `64` channels, and do NOT perform *initial downsampling*.\n",
    "- There is **only one** downsampling step within each `BottomUpLayer`.\n",
    "- *Lateral Contextualization* is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GaussianLikelihood] PredLVar:pixelwise LowBLVar:-5\n",
      "[LadderVAE] Stoc:True RecMode:False TethInput:False TargetCh: 2\n"
     ]
    }
   ],
   "source": [
    "# Define custom config\n",
    "config = config = get_config(\n",
    "    image_size=64,\n",
    "    z_dims=[128, 128, 128, 128],\n",
    "    n_filters=64,\n",
    "    dropout=0.1,\n",
    "    nonlin=\"elu\",\n",
    "    enable_noise_model=False,\n",
    "    multiscale_lowres_count=1,\n",
    "    analytical_kl=True\n",
    ")\n",
    "\n",
    "# Initialize a LadderVAE instance\n",
    "lvae_model = LadderVAE(config=config, data_mean=np.empty((32, 1)), data_std=np.empty((32, 1)))\n",
    "\n",
    "# Extract the ModuleList of bottom-up layers\n",
    "bottom_up_layers = lvae_model.bottom_up_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
      "========================================================================================================================\n",
      "BottomUpLayer                                 [1, 64, 64, 64]           [1, 64, 32, 32]           --\n",
      "├─Sequential: 1-1                             [1, 64, 64, 64]           [1, 64, 32, 32]           --\n",
      "│    └─BottomUpDeterministicResBlock: 2-1     [1, 64, 64, 64]           [1, 64, 32, 32]           --\n",
      "│    │    └─Conv2d: 3-1                       [1, 64, 64, 64]           [1, 64, 32, 32]           36,928\n",
      "│    │    └─ResidualBlock: 3-2                [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    │    └─Sequential: 4-1              [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    │    │    └─BatchNorm2d: 5-1        [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    │    │    └─ELU: 5-2                [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    │    │    └─Conv2d: 5-3             [1, 64, 32, 32]           [1, 64, 32, 32]           36,928\n",
      "│    │    │    │    └─Dropout2d: 5-4          [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    │    │    └─BatchNorm2d: 5-5        [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
      "│    │    │    │    └─ELU: 5-6                [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    │    │    └─Conv2d: 5-7             [1, 64, 32, 32]           [1, 64, 32, 32]           36,928\n",
      "│    │    │    │    └─Dropout2d: 5-8          [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "│    │    │    │    └─GateLayer2d: 5-9        [1, 64, 32, 32]           [1, 64, 32, 32]           8,320\n",
      "├─Sequential: 1-2                             [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
      "========================================================================================================================\n",
      "Total params: 119,360\n",
      "Trainable params: 119,360\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 121.96\n",
      "========================================================================================================================\n",
      "Input size (MB): 1.05\n",
      "Forward/backward pass size (MB): 3.67\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 5.20\n",
      "========================================================================================================================\n",
      "========================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
      "========================================================================================================================\n",
      "BottomUpLayer                                 [1, 64, 32, 32]           [1, 64, 16, 16]           --\n",
      "├─Sequential: 1-1                             [1, 64, 32, 32]           [1, 64, 16, 16]           --\n",
      "│    └─BottomUpDeterministicResBlock: 2-1     [1, 64, 32, 32]           [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-1                       [1, 64, 32, 32]           [1, 64, 16, 16]           36,928\n",
      "│    │    └─ResidualBlock: 3-2                [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    └─Sequential: 4-1              [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─BatchNorm2d: 5-1        [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
      "│    │    │    │    └─ELU: 5-2                [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─Conv2d: 5-3             [1, 64, 16, 16]           [1, 64, 16, 16]           36,928\n",
      "│    │    │    │    └─Dropout2d: 5-4          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─BatchNorm2d: 5-5        [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
      "│    │    │    │    └─ELU: 5-6                [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─Conv2d: 5-7             [1, 64, 16, 16]           [1, 64, 16, 16]           36,928\n",
      "│    │    │    │    └─Dropout2d: 5-8          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─GateLayer2d: 5-9        [1, 64, 16, 16]           [1, 64, 16, 16]           8,320\n",
      "├─Sequential: 1-2                             [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "========================================================================================================================\n",
      "Total params: 119,360\n",
      "Trainable params: 119,360\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 30.49\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 1.66\n",
      "========================================================================================================================\n",
      "========================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
      "========================================================================================================================\n",
      "BottomUpLayer                                 [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
      "├─Sequential: 1-1                             [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
      "│    └─BottomUpDeterministicResBlock: 2-1     [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-1                       [1, 64, 16, 16]           [1, 64, 8, 8]             36,928\n",
      "│    │    └─ResidualBlock: 3-2                [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    └─Sequential: 4-1              [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-1        [1, 64, 8, 8]             [1, 64, 8, 8]             128\n",
      "│    │    │    │    └─ELU: 5-2                [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─Conv2d: 5-3             [1, 64, 8, 8]             [1, 64, 8, 8]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-4          [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-5        [1, 64, 8, 8]             [1, 64, 8, 8]             128\n",
      "│    │    │    │    └─ELU: 5-6                [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─Conv2d: 5-7             [1, 64, 8, 8]             [1, 64, 8, 8]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-8          [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─GateLayer2d: 5-9        [1, 64, 8, 8]             [1, 64, 8, 8]             8,320\n",
      "├─Sequential: 1-2                             [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "========================================================================================================================\n",
      "Total params: 119,360\n",
      "Trainable params: 119,360\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 7.62\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 0.23\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 0.77\n",
      "========================================================================================================================\n",
      "========================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
      "========================================================================================================================\n",
      "BottomUpLayer                                 [1, 64, 8, 8]             [1, 64, 4, 4]             --\n",
      "├─Sequential: 1-1                             [1, 64, 8, 8]             [1, 64, 4, 4]             --\n",
      "│    └─BottomUpDeterministicResBlock: 2-1     [1, 64, 8, 8]             [1, 64, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-1                       [1, 64, 8, 8]             [1, 64, 4, 4]             36,928\n",
      "│    │    └─ResidualBlock: 3-2                [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    └─Sequential: 4-1              [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-1        [1, 64, 4, 4]             [1, 64, 4, 4]             128\n",
      "│    │    │    │    └─ELU: 5-2                [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─Conv2d: 5-3             [1, 64, 4, 4]             [1, 64, 4, 4]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-4          [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-5        [1, 64, 4, 4]             [1, 64, 4, 4]             128\n",
      "│    │    │    │    └─ELU: 5-6                [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─Conv2d: 5-7             [1, 64, 4, 4]             [1, 64, 4, 4]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-8          [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─GateLayer2d: 5-9        [1, 64, 4, 4]             [1, 64, 4, 4]             8,320\n",
      "├─Sequential: 1-2                             [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "========================================================================================================================\n",
      "Total params: 119,360\n",
      "Trainable params: 119,360\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.91\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 0.55\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# bottom_up_layers is a ModuleList, so it doesn't have an explicit forward()\n",
    "# We need to call the forward() of the single modules\n",
    "inp_size = [64, 64, 64]\n",
    "\n",
    "for bottom_up_layer in bottom_up_layers: \n",
    "    curr_summary = summary(\n",
    "        model=bottom_up_layer,\n",
    "        input_size=inp_size,\n",
    "        batch_dim=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        depth=5\n",
    "    )\n",
    "    print(curr_summary)\n",
    "    inp_size[1] = inp_size[2] = inp_size[1] // 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** With the assumption that *Lateral Contextualization* is **disabled**, the parameters that can influence the structure of `bottom_up_layers` are:\n",
    "- `len(self.z_dims)` -> number of `BottomUpLayer`'s.\n",
    "- `self.encoder_blocks_per_layer` -> number of `BottomUpDeterministicResBlock`s in each `BottomUpLayer`\n",
    "- `self.encoder_n_filters` -> sets the number of channels within **all** the *Encoder* layers (recall that all the layers share the same number of channels).\n",
    "- `self.encoder_res_block_kernel`, `self.encoder_res_block_skip_padding`, `self.res_block_type` -> specifics of residual blocks throughout all the *Encoder* layers.\n",
    "\n",
    "The number of `downsampling_steps` is set in the `LadderVAE` constructor by default to `1` for each `BottomUpLayer` and cannot be changed from outside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOME NOTES ABOUT THE MODULE'S FUNCTIONING:**\n",
    "\n",
    "The output of each `BottomUpLayer` module is a tuple of two tensors:\n",
    "\n",
    "- The first tensor represents the output of the layer, i.e., the input to the following bottom-up layer (we call it `x`, see `_bottoup_pass()` method, line 660).\n",
    "- The second tensor represents, instead, the so-called `bu_value`, which is sent to the top-down pass for computing the inference distributions $q_\\phi(z_i|z_{i+1})$.\n",
    "\n",
    "Observe that in the simple case of disabled *LC,*  the two tensors coincide and their size is given by `(BxCxH*xW*)`, where `H* = H / (2*downsampling_steps)` and `W* = W / (2*downsampling_steps)`.\n",
    "\n",
    "To conclude, it is important to remark that the output of the `_bottoup_pass()` is a list containing the `bu_value` tensors computed at the different hierarchical levels of the *Encoder.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Lateral Contextualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we test again the Bottom-Up pass. However, we also enable LC, to see if the two of them get along together. \n",
    "\n",
    "**NOTE:** We assume that:\n",
    "- Input patches and lateral low-res patches both have size `(1, 64, 64)`.\n",
    "- The shape of single patches imply that the overall bottom-up input has shape `($n_{LC}$, 64, 64)`, where $n_{LC}$ is the number of LC inputs. \n",
    "- `first_bottom_up` uses `64` channels, and do NOT perform *initial downsampling*.\n",
    "- There is **only one** downsampling step within each `BottomUpLayer`.\n",
    "- *Lateral Contextualization* is **enabled**.\n",
    "- `multiscale_lowres_separate_branch` is `False`, meaning that low-res inputs and outputs of previous bottom-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GaussianLikelihood] PredLVar:pixelwise LowBLVar:-5\n",
      "[LadderVAE] Stoc:True RecMode:False TethInput:False TargetCh: 2\n"
     ]
    }
   ],
   "source": [
    "# Define custom config\n",
    "config = config = get_config(\n",
    "    image_size=64,\n",
    "    z_dims=[128, 128, 128, 128],\n",
    "    n_filters=64,\n",
    "    dropout=0.1,\n",
    "    nonlin=\"elu\",\n",
    "    enable_noise_model=False,\n",
    "    multiscale_lowres_count=3,\n",
    "    analytical_kl=True\n",
    ")\n",
    "\n",
    "# Initialize a LadderVAE instance\n",
    "lvae_model = LadderVAE(config=config, data_mean=np.empty((32, 1)), data_std=np.empty((32, 1)))\n",
    "\n",
    "# Extract first bottom-up layer\n",
    "first_bottom_up = lvae_model.first_bottom_up\n",
    "\n",
    "# Extract the ModuleList of bottom-up layers\n",
    "bottom_up_layers = lvae_model.bottom_up_layers\n",
    "\n",
    "# Extract the ModuleList of Input Branches for lateral inputs\n",
    "lowres_first_bottom_ups = lvae_model.lowres_first_bottom_ups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we test the *Input Branches* (a.k.a. `lowres_first_bottom_ups`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "Sequential                               [1, 1, 64, 64]            [1, 64, 64, 64]           --\n",
      "├─Conv2d: 1-1                            [1, 1, 64, 64]            [1, 64, 64, 64]           1,664\n",
      "├─ELU: 1-2                               [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "├─BottomUpDeterministicResBlock: 1-3     [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    └─ResidualBlock: 2-1                [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    └─Sequential: 3-1              [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    │    └─BatchNorm2d: 4-1        [1, 64, 64, 64]           [1, 64, 64, 64]           128\n",
      "│    │    │    └─ELU: 4-2                [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    │    └─Conv2d: 4-3             [1, 64, 64, 64]           [1, 64, 64, 64]           36,928\n",
      "│    │    │    └─Dropout2d: 4-4          [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    │    └─BatchNorm2d: 4-5        [1, 64, 64, 64]           [1, 64, 64, 64]           128\n",
      "│    │    │    └─ELU: 4-6                [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    │    └─Conv2d: 4-7             [1, 64, 64, 64]           [1, 64, 64, 64]           36,928\n",
      "│    │    │    └─Dropout2d: 4-8          [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "===================================================================================================================\n",
      "Total params: 75,776\n",
      "Trainable params: 75,776\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 309.33\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 10.49\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 10.81\n",
      "===================================================================================================================\n",
      "===================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
      "===================================================================================================================\n",
      "Sequential                               [1, 1, 64, 64]            [1, 64, 64, 64]           --\n",
      "├─Conv2d: 1-1                            [1, 1, 64, 64]            [1, 64, 64, 64]           1,664\n",
      "├─ELU: 1-2                               [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "├─BottomUpDeterministicResBlock: 1-3     [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    └─ResidualBlock: 2-1                [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    └─Sequential: 3-1              [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    │    └─BatchNorm2d: 4-1        [1, 64, 64, 64]           [1, 64, 64, 64]           128\n",
      "│    │    │    └─ELU: 4-2                [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    │    └─Conv2d: 4-3             [1, 64, 64, 64]           [1, 64, 64, 64]           36,928\n",
      "│    │    │    └─Dropout2d: 4-4          [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    │    └─BatchNorm2d: 4-5        [1, 64, 64, 64]           [1, 64, 64, 64]           128\n",
      "│    │    │    └─ELU: 4-6                [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "│    │    │    └─Conv2d: 4-7             [1, 64, 64, 64]           [1, 64, 64, 64]           36,928\n",
      "│    │    │    └─Dropout2d: 4-8          [1, 64, 64, 64]           [1, 64, 64, 64]           --\n",
      "===================================================================================================================\n",
      "Total params: 75,776\n",
      "Trainable params: 75,776\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 309.33\n",
      "===================================================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 10.49\n",
      "Params size (MB): 0.30\n",
      "Estimated Total Size (MB): 10.81\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# lowres_first_bottom_ups is a ModuleList, so it doesn't have an explicit forward()\n",
    "# We need to call the forward() of the single modules\n",
    "inp_size = [1, 64, 64]\n",
    "\n",
    "for lowres_first_bottom_up in lowres_first_bottom_ups: \n",
    "    curr_summary = summary(\n",
    "        model=lowres_first_bottom_up,\n",
    "        input_size=inp_size,\n",
    "        batch_dim=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        depth=5\n",
    "    )\n",
    "    print(curr_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lowres_first_bottom_ups`: test passed!\n",
    "\n",
    "**NOTE**: When you run `torchinfo.summary()`, the analyzed model is automatically moved to `CUDA`, if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test the `bottom_up_layers` with *Lateral Contextualization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_tensor = torch.rand((1, 3, 64, 64), device=\"cpu\")\n",
    "lvae_model = lvae_model.to(\"cpu\")\n",
    "out_tensor = lvae_model._bottomup_pass(\n",
    "    inp=inp_tensor,\n",
    "    first_bottom_up=lvae_model.first_bottom_up,\n",
    "    lowres_first_bottom_ups=lowres_first_bottom_ups,\n",
    "    bottom_up_layers=bottom_up_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of bu_values is consistent with the number of layers: True\n",
      "Level 0 --> Output shape: torch.Size([1, 64, 64, 64]), Expected output shape: (1, 64, 64, 64)\n",
      "Level 1 --> Output shape: torch.Size([1, 64, 64, 64]), Expected output shape: (1, 64, 64, 64)\n",
      "Level 2 --> Output shape: torch.Size([1, 64, 32, 32]), Expected output shape: (1, 64, 32, 32)\n",
      "Level 3 --> Output shape: torch.Size([1, 64, 16, 16]), Expected output shape: (1, 64, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "# The output is a list of bu_value tensors\n",
    "print(f\"The length of bu_values is consistent with the number of layers: {len(out_tensor) == lvae_model.n_layers}\")\n",
    "exp_shape = np.array((1, 64, 64, 64))\n",
    "for i in range(lvae_model.n_layers):\n",
    "    print(f\"Level {i} --> Output shape: {out_tensor[i].shape}, Expected output shape: {tuple(exp_shape)}\")\n",
    "    if lvae_model._multiscale_count - 1 <= i + 1:\n",
    "        exp_shape[2:] = exp_shape[2:] // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bottom_up_layers is a ModuleList, so it doesn't have an explicit forward()\n",
    "# # We need to call the forward() of the single modules\n",
    "# inp_size = [1, 64, 64, 64]\n",
    "# inp_data = {\n",
    "#     \"x\": torch.rand(inp_size),\n",
    "#     \"lowres_x\": torch.rand(inp_size)\n",
    "# }\n",
    "\n",
    "# for i, bottom_up_layer in enumerate(bottom_up_layers): \n",
    "#     curr_summary = summary(\n",
    "#         model=bottom_up_layer,\n",
    "#         input_data=inp_data,\n",
    "#         batch_dim=0,\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "#         depth=5\n",
    "#     )\n",
    "#     print(curr_summary)\n",
    "    \n",
    "#     if lvae_model._multiscale_count - 1 <= i + 1:\n",
    "#         inp_size[2] = inp_size[2] // 2\n",
    "#         inp_size[3] = inp_size[3] // 2\n",
    "#         inp_data[\"x\"] = torch.rand(inp_size)\n",
    "#         inp_data[\"lowres_x\"] = None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bottom_up_pass()` with *Lateral Contextualization*: test passed! (internal and output tensors have the expected shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Top-Down pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Top-Down Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required tests:\n",
    "- `LadderVAE.create_top_down_layers()` builds the model correctly given the input parameters.\n",
    "- The forward methods of the resulting `top_down_layers` modules are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GaussianLikelihood] PredLVar:pixelwise LowBLVar:-5\n",
      "[LadderVAE] Stoc:True RecMode:False TethInput:False TargetCh: 2\n"
     ]
    }
   ],
   "source": [
    "# Define custom config\n",
    "config = config = get_config(\n",
    "    image_size=64,\n",
    "    z_dims=[128, 128, 128, 128, 128],\n",
    "    n_filters=64,\n",
    "    dropout=0.1,\n",
    "    nonlin=\"elu\",\n",
    "    enable_noise_model=False,\n",
    "    multiscale_lowres_count=1,\n",
    "    analytical_kl=True\n",
    ")\n",
    "\n",
    "# Initialize a LadderVAE instance\n",
    "lvae_model = LadderVAE(config=config, data_mean=np.empty((32, 1)), data_std=np.empty((32, 1)))\n",
    "\n",
    "# Extract the first bottom-up layer\n",
    "top_down_layers = lvae_model.top_down_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** We assume that:\n",
    "- Inputs are the `bu_values` computed in the Bottom-Up pass. Their size depends on whether LC is enabled.\n",
    "    - if LC enabled --> `[B, C, H, W]` for all levels.\n",
    "    - if LC disabled --> `[B, C, H // 2**i, W // 2**i]`, where `i=0` is the bottom-most level, and `i=n_layers-1` is the top-most one.\n",
    "- The top-down layers sample the latent variable `z` from the latent distribution defined by `q_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bu_values shape: [torch.Size([1, 64, 32, 32]), torch.Size([1, 64, 16, 16]), torch.Size([1, 64, 8, 8]), torch.Size([1, 64, 4, 4]), torch.Size([1, 64, 2, 2])]\n"
     ]
    }
   ],
   "source": [
    "bu_list = []\n",
    "inp_size = [1, 64, 64, 64]\n",
    "for i in range(lvae_model.n_layers):\n",
    "    if i > lvae_model._multiscale_count - 2:\n",
    "        inp_size[2] = inp_size[2] // 2\n",
    "        inp_size[3] = inp_size[3] // 2 \n",
    "    bu_list.append(torch.rand(inp_size, device=\"cpu\"))\n",
    "  \n",
    "print(f\"Bu_values shape: {[tens.shape for tens in bu_list]}\")\n",
    "  \n",
    "lvae_model = lvae_model.to(\"cpu\")\n",
    "out_tensor, info_dict = lvae_model.topdown_pass(\n",
    "    bu_values = bu_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['z', 'kl', 'kl_restricted', 'kl_spatial', 'kl_channelwise', 'q_mu', 'q_lv', 'debug_qvar_max'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 64, 64, 64]), Expected output shape: (1, 64, 64, 64) --> Test Passed :)\n",
      "\n",
      "Latent shape test:\n",
      "    Layer0 --> Latent shape: torch.Size([1, 128, 32, 32]), Expected latent shape: (1, 128, 32, 32) --> Test Passed :)\n",
      "    Layer1 --> Latent shape: torch.Size([1, 128, 16, 16]), Expected latent shape: (1, 128, 16, 16) --> Test Passed :)\n",
      "    Layer2 --> Latent shape: torch.Size([1, 128, 8, 8]), Expected latent shape: (1, 128, 8, 8) --> Test Passed :)\n",
      "    Layer3 --> Latent shape: torch.Size([1, 128, 4, 4]), Expected latent shape: (1, 128, 4, 4) --> Test Passed :)\n",
      "    Layer4 --> Latent shape: torch.Size([1, 128, 2, 2]), Expected latent shape: (1, 128, 2, 2) --> Test Passed :)\n",
      "\n",
      "KL Divergence shape test:\n",
      "    Layer0 --> KL_spatial shape: torch.Size([1, 32, 32]), Expected shape: (1, 32, 32) --> Test Passed :)\n",
      "               KL_channelwise shape: torch.Size([1, 128]), Expected shape: (1, 128) --> Test Passed :)\n",
      "    Layer1 --> KL_spatial shape: torch.Size([1, 16, 16]), Expected shape: (1, 16, 16) --> Test Passed :)\n",
      "               KL_channelwise shape: torch.Size([1, 128]), Expected shape: (1, 128) --> Test Passed :)\n",
      "    Layer2 --> KL_spatial shape: torch.Size([1, 8, 8]), Expected shape: (1, 8, 8) --> Test Passed :)\n",
      "               KL_channelwise shape: torch.Size([1, 128]), Expected shape: (1, 128) --> Test Passed :)\n",
      "    Layer3 --> KL_spatial shape: torch.Size([1, 4, 4]), Expected shape: (1, 4, 4) --> Test Passed :)\n",
      "               KL_channelwise shape: torch.Size([1, 128]), Expected shape: (1, 128) --> Test Passed :)\n",
      "    Layer4 --> KL_spatial shape: torch.Size([1, 2, 2]), Expected shape: (1, 2, 2) --> Test Passed :)\n",
      "               KL_channelwise shape: torch.Size([1, 128]), Expected shape: (1, 128) --> Test Passed :)\n",
      "\n",
      "Q_params shape test:\n",
      "    Layer0 --> q_mu shape: torch.Size([1, 128, 32, 32]), Expected shape: (1, 128, 32, 32) --> Test Passed :)\n",
      "    Layer1 --> q_mu shape: torch.Size([1, 128, 16, 16]), Expected shape: (1, 128, 16, 16) --> Test Passed :)\n",
      "    Layer2 --> q_mu shape: torch.Size([1, 128, 8, 8]), Expected shape: (1, 128, 8, 8) --> Test Passed :)\n",
      "    Layer3 --> q_mu shape: torch.Size([1, 128, 4, 4]), Expected shape: (1, 128, 4, 4) --> Test Passed :)\n",
      "    Layer4 --> q_mu shape: torch.Size([1, 128, 2, 2]), Expected shape: (1, 128, 2, 2) --> Test Passed :)\n"
     ]
    }
   ],
   "source": [
    "# Some tests to assess output consistency\n",
    "exp_output_shape = (1, lvae_model.encoder_n_filters, lvae_model.image_size, lvae_model.image_size)\n",
    "print(f\"Output shape test: {out_tensor.shape}, Expected output shape: {exp_output_shape} --> Test {'Passed :)' if out_tensor.shape == exp_output_shape else 'Failed :('}\")\n",
    "\n",
    "print(\"\\nLatent shape test:\")\n",
    "for i in range(lvae_model.n_layers):\n",
    "    exp_latent_shape = (1, lvae_model.z_dims[i], bu_list[i].shape[2], bu_list[i].shape[3])\n",
    "    latent_shape = info_dict[\"z\"][i].shape \n",
    "    print(f\"    Layer{i} --> Latent shape: {latent_shape}, Expected latent shape: {exp_latent_shape} --> Test {'Passed :)' if latent_shape == exp_latent_shape else 'Failed :('}\")\n",
    "    \n",
    "print(\"\\nKL Divergence shape test:\")\n",
    "for i in range(lvae_model.n_layers):\n",
    "    exp_kl_spatial_shape = (1, bu_list[i].shape[2], bu_list[i].shape[3])\n",
    "    exp_kl_channelwise_shape = (1, lvae_model.z_dims[i])\n",
    "    kl_spatial_shape = info_dict[\"kl_spatial\"][i].shape\n",
    "    kl_channelwise_shape = info_dict[\"kl_channelwise\"][i].shape \n",
    "    print(f\"    Layer{i} --> KL_spatial shape: {kl_spatial_shape}, Expected shape: {exp_kl_spatial_shape} --> Test {'Passed :)' if kl_spatial_shape == exp_kl_spatial_shape else 'Failed :('}\")\n",
    "    print(f\"               KL_channelwise shape: {kl_channelwise_shape}, Expected shape: {exp_kl_channelwise_shape} --> Test {'Passed :)' if exp_kl_channelwise_shape == exp_kl_channelwise_shape else 'Failed :('}\")\n",
    "    \n",
    "print(\"\\nQ_params shape test:\")\n",
    "for i in range(lvae_model.n_layers):\n",
    "    exp_shape = (1, lvae_model.z_dims[i], bu_list[i].shape[2], bu_list[i].shape[3])\n",
    "    q_mu_shape = info_dict[\"q_mu\"][i]._mean.shape \n",
    "    print(f\"    Layer{i} --> q_mu shape: {q_mu_shape}, Expected shape: {exp_shape} --> Test {'Passed :)' if q_mu_shape == exp_shape else 'Failed :('}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # top_down_layers is a ModuleList, so it doesn't have an explicit forward()\n",
    "# # We need to call the forward() of the single modules\n",
    "\n",
    "# # Define a dict of the inputs\n",
    "# inp_size = torch.tensor([1, 64, 8, 8])\n",
    "# others_inp_data = {\n",
    "#     \"input_\": torch.rand(tuple(inp_size)), # we start from (topmost-1)-th layer\n",
    "#     \"skip_connection_input\": None,\n",
    "#     \"inference_mode\": True,\n",
    "#     \"bu_value\": torch.rand(tuple(inp_size)),\n",
    "#     \"n_img_prior\": None,\n",
    "#     \"forced_latent\": None,\n",
    "#     \"use_mode\": False,\n",
    "#     \"force_constant_output\": False,\n",
    "#     \"mode_pred\": False,\n",
    "#     \"use_uncond_mode\": False,\n",
    "#     \"var_clip_max\": None\n",
    "# }\n",
    "\n",
    "# topmost_inp_data = deepcopy(others_inp_data)\n",
    "# topmost_inp_data[\"input_\"] = None\n",
    "# topmost_inp_data[\"bu_value\"] = torch.rand((1, 64, 4, 4))\n",
    "\n",
    "# for i in range(len(top_down_layers) - 2, -1, -1):\n",
    "#     is_top = i == len(top_down_layers) - 1\n",
    "    \n",
    "#     if is_top:\n",
    "#         curr_summary = summary(\n",
    "#             input_data=topmost_inp_data,\n",
    "#             model=top_down_layers[i],\n",
    "#             batch_dim=0,\n",
    "#             col_names=[\"input_size\", \"output_size\"],\n",
    "#             depth=5\n",
    "#         )\n",
    "#     else:\n",
    "#         curr_summary = summary(\n",
    "#             input_data=others_inp_data,\n",
    "#             model=top_down_layers[i],\n",
    "#             batch_dim=0,\n",
    "#             col_names=[\"input_size\", \"output_size\"],\n",
    "#             depth=5\n",
    "#         )\n",
    "#     print(curr_summary)\n",
    "    \n",
    "#     inp_size[2:] = inp_size[2:] * 2 \n",
    "#     others_inp_data[\"input_\"] = torch.tensor(tuple(inp_size))\n",
    "#     print(others_inp_data[\"input_\"].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The parameters that can influence the structure of `first_bottom_up` layer are:\n",
    "- `self.no_initial_downscaling` -> if `False`, the `stride` of the initial `Conv2d` block is set to `2`. This parameters influences this layer only!\n",
    "- `self.encoder_n_filters` -> sets the number of channels within **all** the *Encoder* layers (recall that all the layers share the same number of channels).\n",
    "- `self.encoder_res_block_kernel`, `self.encoder_res_block_skip_padding`, `self.res_block_type` -> set the specifics of residual blocks throughout all the *Encoder* layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Likelihood Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lvae_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
