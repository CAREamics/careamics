{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `LadderVAE` module\n",
    "In this notebook we test the different layers of LadderVAE model to check:\n",
    "- Whether all the necessary blocks/layers are here,\n",
    "- Whether the current version of the blocks/layers does the right thing (i.e., model flow, size of outputs given inputs, ...).\n",
    "\n",
    "We will do this by initializing a standard LadderVAE model (default options). Afterward, we will progressively adding supplementary features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/miniforge3/envs/lvae_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import ml_collections\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/federico.carrara/Documents/projects/careamics/src/careamics/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lvae.lvae import LadderVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a first thing we create a model `config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a default config object\n",
    "def get_default_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.data = ml_collections.ConfigDict()\n",
    "    # config.data.sampler_type = SamplerType.DefaultSampler\n",
    "    config.data.sampler_type = None\n",
    "\n",
    "    config.model = ml_collections.ConfigDict()\n",
    "    config.model.use_vampprior = False\n",
    "    config.model.encoder = ml_collections.ConfigDict()\n",
    "    config.model.decoder = ml_collections.ConfigDict()\n",
    "    config.model.decoder.conv2d_bias = True\n",
    "\n",
    "    config.loss = ml_collections.ConfigDict()\n",
    "\n",
    "    config.training = ml_collections.ConfigDict()\n",
    "    config.training.batch_size = 32\n",
    "\n",
    "    config.training.grad_clip_norm_value = 0.5  # Taken from https://github.com/openai/vdvae/blob/main/hps.py#L38\n",
    "    config.training.gradient_clip_algorithm = 'value'\n",
    "    config.training.earlystop_patience = 100\n",
    "    config.training.precision = 32\n",
    "    config.training.pre_trained_ckpt_fpath = ''\n",
    "\n",
    "    config.git = ml_collections.ConfigDict()\n",
    "    config.git.changedFiles = []\n",
    "    config.git.branch = ''\n",
    "    config.git.untracked_files = []\n",
    "    config.git.latest_commit = ''\n",
    "\n",
    "    config.workdir = '/home/federico.carrara/Documents/projects/careamics/src/careamics/models/lvae'\n",
    "    config.datadir = ''\n",
    "    config.hostname = ''\n",
    "    config.exptname = ''\n",
    "    \n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for editing `config.model` fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_edit_model_config(config: ml_collections.ConfigDict) -> None:\n",
    "    \n",
    "    model = config.model\n",
    "\n",
    "    # Set the size of the latent spaces in the hierarchical levels\n",
    "    # NOTE: each entry is the latent space size of the corresponding level\n",
    "    # The number of entries should be equal to the number of levels\n",
    "    model.z_dims = [128, 128, 128, 128]\n",
    "\n",
    "    # Set the Encoder architecture\n",
    "    model.encoder.batchnorm = True\n",
    "    model.encoder.blocks_per_layer = 1\n",
    "    model.encoder.n_filters = 64\n",
    "    model.encoder.dropout = 0.1\n",
    "    model.encoder.res_block_kernel = 3\n",
    "    model.encoder.res_block_skip_padding = False\n",
    "\n",
    "    # Set the Decoder architecture\n",
    "    model.decoder.batchnorm = True\n",
    "    model.decoder.blocks_per_layer = 1\n",
    "    model.decoder.n_filters = 64\n",
    "    model.decoder.dropout = 0.1\n",
    "    model.decoder.res_block_kernel = 3\n",
    "    model.decoder.res_block_skip_padding = False\n",
    "    model.decoder.conv2d_bias = True\n",
    "\n",
    "    # Set common architecture parameters\n",
    "    model.res_block_type = 'bacdbacd'\n",
    "    model.gated = True\n",
    "    model.nonlin = 'elu'\n",
    "    model.merge_type = 'residual'\n",
    "    model.learn_top_prior = False\n",
    "    model.analytical_kl = False\n",
    "    model.mode_pred = False\n",
    "    model.no_initial_downscaling = True\n",
    "\n",
    "    # Whether to use a stochastic skip connection in the top-down pass\n",
    "    model.stochastic_skip = False\n",
    "\n",
    "    # Whether to predict_logvar, to be chosen among [None,'global','channelwise','pixelwise']\n",
    "    model.predict_logvar = None\n",
    "\n",
    "    # Set LC-related fields\n",
    "    model.multiscale_lowres_separate_branch = False\n",
    "    model.multiscale_retain_spatial_dims = True\n",
    "\n",
    "    # Whether to use stochastic block in the top-down pass\n",
    "    model.non_stochastic_version = False\n",
    "\n",
    "    # For enabling/disabling noise model\n",
    "    model.enable_noise_model = False\n",
    "    model.noise_model_ch1_fpath = ''\n",
    "    model.noise_model_ch2_fpath = ''\n",
    "    model.noise_model_type = 'gmm' #hist\n",
    "\n",
    "    # Additional parameters (most likely we don't need to change these)\n",
    "    model.monitor = 'val_psnr'  # {'val_loss','val_psnr'}\n",
    "    model.skip_nboundary_pixels_from_loss = None\n",
    "    model.logvar_lowerbound = -5  # -2.49 is log(1/12), from paper \"Re-parametrizing VAE for stablity.\"\n",
    "    model.var_clip_max = 20\n",
    "    model.img_shape = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to edit other `config` fields (needed to init the `LadderVAE` model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_edit_others_config(config: ml_collections.ConfigDict) -> None:\n",
    "    # Data fields\n",
    "    data = config.data\n",
    "\n",
    "    # Set info about input data shape\n",
    "    data.image_size = 64\n",
    "    data.multiscale_lowres_count = 1\n",
    "\n",
    "    # These are not used in the model, so no need to touch them\n",
    "    data.normalized_input = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utility function for custom `config` objects \n",
    "Actually we'd like to have a utility function that enables us to modify a subset of the config's fields that needs to be changed while doing different tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_config(\n",
    "    z_dims: List[int] = [128, 128, 128, 128],\n",
    "    blocks_per_layer: int = 1,\n",
    "    n_filters: int = 64,\n",
    "    learn_top_prior: bool = False,\n",
    "    no_initial_downscaling: bool = True,\n",
    "    stochastic_skip: bool = False,\n",
    "    predict_logvar: str = None,\n",
    "    multiscale_lowres_separate_branch: bool = False,\n",
    "    non_stochastic_version: bool = False,\n",
    "    image_size: int = 64,\n",
    "    multiscale_lowres_count: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    NOTE: `len(z_dims)` determines the number of hierarchical levels (e.g., number of `BottomUpLayers`)\n",
    "    in the model. The information is stored in the `self.n_layers` attribute.\n",
    "    \"\"\"\n",
    "    \n",
    "    config = get_default_config()\n",
    "    default_edit_model_config(config)\n",
    "    default_edit_others_config(config)\n",
    "    \n",
    "    model = config.model\n",
    "    model.z_dims = z_dims\n",
    "    model.encoder.blocks_per_layer = blocks_per_layer\n",
    "    model.encoder.n_filters = n_filters\n",
    "    model.decoder.blocks_per_layer = blocks_per_layer\n",
    "    model.decoder.n_filters = n_filters\n",
    "    model.learn_top_prior = learn_top_prior\n",
    "    model.no_initial_downscaling = no_initial_downscaling\n",
    "    model.stochastic_skip = stochastic_skip\n",
    "    model.predict_logvar = predict_logvar\n",
    "    model.multiscale_lowres_separate_branch = multiscale_lowres_separate_branch\n",
    "    model.non_stochastic_version = non_stochastic_version\n",
    "\n",
    "    config.data.image_size = image_size\n",
    "    config.data.multiscale_lowres_count = multiscale_lowres_count\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to check the functioning of the different components of the `LadderVAE` model.\n",
    "\n",
    "Specifically, for each component of the model we check:\n",
    "1. Whether all the submodules and parameters required to define the model are provided/available.\n",
    "2. Whether that module is consistent, i.e., given a certain input it produces outputs of the expected size.\n",
    "3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. LVAE model initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check if the LVAE model constructor works as expected given the right inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create `config` object and initialize other required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_custom_config()\n",
    "\n",
    "# Additional required parameters (not in the config)\n",
    "data_mean = data_std = np.array([0.5, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize `LadderVAE` instance to check constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GaussianLikelihood] PredLVar:None LowBLVar:-5\n",
      "[LadderVAE] Stoc:True RecMode:False TethInput:False TargetCh: 2\n"
     ]
    }
   ],
   "source": [
    "lvae_model = LadderVAE(\n",
    "    config=config, \n",
    "    data_mean=data_mean, \n",
    "    data_std=data_std\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LadderVAE` constructor: test passed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bottom-Up pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. First Bottom-Up layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we tested `LadderVAE` constructor, meaning that we implicitly tested that `LadderVAE.create_first_bottom_up()` works.\n",
    "\n",
    "Therefore we are left to test that:\n",
    "- `LadderVAE.create_first_bottom_up()` builds the model correctly given the input parameters.\n",
    "- The forward method of the resulting `first_bottom_up` is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom config\n",
    "config = get_custom_config(\n",
    "    z_dims=[128, 128, 128, 128],\n",
    "    blocks_per_layer=1,\n",
    "    n_filters=64,\n",
    "    learn_top_prior=False,\n",
    "    no_initial_downscaling=False,\n",
    "    stochastic_skip=False,\n",
    "    predict_logvar=None,\n",
    "    multiscale_lowres_separate_branch=False,\n",
    "    non_stochastic_version=False,\n",
    "    image_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GaussianLikelihood] PredLVar:None LowBLVar:-5\n",
      "[LadderVAE] Stoc:True RecMode:False TethInput:False TargetCh: 2\n"
     ]
    }
   ],
   "source": [
    "# Initialize a LadderVAE instance\n",
    "lvae_model = LadderVAE(config=config, data_mean=np.empty((32, 1)), data_std=np.empty((32, 1)))\n",
    "\n",
    "# Extract the first bottom-up layer\n",
    "first_bottom_up = lvae_model.first_bottom_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the structure using `torchinfo.summary`. This allows to check also whether the `forward` method works correctly.\n",
    "\n",
    "**NOTE:** We assume that:\n",
    "- Input patches have size `(1, 64, 64)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "Sequential                               [1, 1, 64, 64]            [1, 64, 32, 32]           --\n",
       "├─Conv2d: 1-1                            [1, 1, 64, 64]            [1, 64, 32, 32]           640\n",
       "├─ELU: 1-2                               [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
       "├─BottomUpDeterministicResBlock: 1-3     [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
       "│    └─ResidualBlock: 2-1                [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
       "│    │    └─Sequential: 3-1              [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
       "│    │    │    └─BatchNorm2d: 4-1        [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
       "│    │    │    └─ELU: 4-2                [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
       "│    │    │    └─Conv2d: 4-3             [1, 64, 32, 32]           [1, 64, 32, 32]           36,928\n",
       "│    │    │    └─Dropout2d: 4-4          [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
       "│    │    │    └─BatchNorm2d: 4-5        [1, 64, 32, 32]           [1, 64, 32, 32]           128\n",
       "│    │    │    └─ELU: 4-6                [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
       "│    │    │    └─Conv2d: 4-7             [1, 64, 32, 32]           [1, 64, 32, 32]           36,928\n",
       "│    │    │    └─Dropout2d: 4-8          [1, 64, 32, 32]           [1, 64, 32, 32]           --\n",
       "===================================================================================================================\n",
       "Total params: 74,752\n",
       "Trainable params: 74,752\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 76.28\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 2.62\n",
       "Params size (MB): 0.30\n",
       "Estimated Total Size (MB): 2.94\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    model=first_bottom_up,\n",
    "    input_size=(1, 64, 64),\n",
    "    batch_dim=0,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "    depth=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The parameters that can influence the structure of `first_bottom_up` layer are:\n",
    "- `self.no_initial_downscaling` -> if `False`, the `stride` of the initial `Conv2d` block is set to `2`. This parameters influences this layer only!\n",
    "- `self.encoder_n_filters` -> sets the number of channels within **all** the *Encoder* layers (recall that all the layers share the same number of channels).\n",
    "- `self.encoder_res_block_kernel`, `self.encoder_res_block_skip_padding`, `self.res_block_type` -> set the specifics of residual blocks throughout all the *Encoder* layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Bottom-Up Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the previous layer, we have to test that:\n",
    "- `LadderVAE.create_bottom_up_layers()` builds the model correctly given the input parameters.\n",
    "- The forward method of the resulting `bottom_u_layers` module list is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom config\n",
    "config = get_custom_config(\n",
    "    z_dims=[128, 128, 128, 128],\n",
    "    blocks_per_layer=1,\n",
    "    n_filters=64,\n",
    "    learn_top_prior=False,\n",
    "    no_initial_downscaling=False,\n",
    "    stochastic_skip=False,\n",
    "    predict_logvar=None,\n",
    "    multiscale_lowres_separate_branch=False,\n",
    "    non_stochastic_version=False,\n",
    "    image_size=64,\n",
    "    multiscale_lowres_count=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GaussianLikelihood] PredLVar:None LowBLVar:-5\n",
      "[LadderVAE] Stoc:True RecMode:False TethInput:False TargetCh: 2\n"
     ]
    }
   ],
   "source": [
    "# Initialize a LadderVAE instance\n",
    "lvae_model = LadderVAE(config=config, data_mean=np.empty((32, 1)), data_std=np.empty((32, 1)))\n",
    "\n",
    "# Extract the ModuleList of bottom-up layers\n",
    "bottom_up_layers = lvae_model.bottom_up_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the structure using `torchinfo.summary`. This allows to check also whether the `forward` method works correctly.\n",
    "\n",
    "**NOTE:** We assume that:\n",
    "- Input patches have size `(1, 64, 64)`.\n",
    "- `first_bottom_up` uses `64` channels, and that performs *initial downsampling*.\n",
    "- There is **only one** downsampling step within each `BottomUpLayer`.\n",
    "- *Lateral Contextualization* is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
      "========================================================================================================================\n",
      "BottomUpLayer                                 [1, 64, 32, 32]           [1, 64, 16, 16]           --\n",
      "├─Sequential: 1-1                             [1, 64, 32, 32]           [1, 64, 16, 16]           --\n",
      "│    └─BottomUpDeterministicResBlock: 2-1     [1, 64, 32, 32]           [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-1                       [1, 64, 32, 32]           [1, 64, 16, 16]           36,928\n",
      "│    │    └─ResidualBlock: 3-2                [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    └─Sequential: 4-1              [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─BatchNorm2d: 5-1        [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
      "│    │    │    │    └─ELU: 5-2                [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─Conv2d: 5-3             [1, 64, 16, 16]           [1, 64, 16, 16]           36,928\n",
      "│    │    │    │    └─Dropout2d: 5-4          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─BatchNorm2d: 5-5        [1, 64, 16, 16]           [1, 64, 16, 16]           128\n",
      "│    │    │    │    └─ELU: 5-6                [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─Conv2d: 5-7             [1, 64, 16, 16]           [1, 64, 16, 16]           36,928\n",
      "│    │    │    │    └─Dropout2d: 5-8          [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "│    │    │    │    └─GateLayer2d: 5-9        [1, 64, 16, 16]           [1, 64, 16, 16]           8,320\n",
      "├─Sequential: 1-2                             [1, 64, 16, 16]           [1, 64, 16, 16]           --\n",
      "========================================================================================================================\n",
      "Total params: 119,360\n",
      "Trainable params: 119,360\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 30.49\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.26\n",
      "Forward/backward pass size (MB): 0.92\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 1.66\n",
      "========================================================================================================================\n",
      "========================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
      "========================================================================================================================\n",
      "BottomUpLayer                                 [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
      "├─Sequential: 1-1                             [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
      "│    └─BottomUpDeterministicResBlock: 2-1     [1, 64, 16, 16]           [1, 64, 8, 8]             --\n",
      "│    │    └─Conv2d: 3-1                       [1, 64, 16, 16]           [1, 64, 8, 8]             36,928\n",
      "│    │    └─ResidualBlock: 3-2                [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    └─Sequential: 4-1              [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-1        [1, 64, 8, 8]             [1, 64, 8, 8]             128\n",
      "│    │    │    │    └─ELU: 5-2                [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─Conv2d: 5-3             [1, 64, 8, 8]             [1, 64, 8, 8]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-4          [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-5        [1, 64, 8, 8]             [1, 64, 8, 8]             128\n",
      "│    │    │    │    └─ELU: 5-6                [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─Conv2d: 5-7             [1, 64, 8, 8]             [1, 64, 8, 8]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-8          [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "│    │    │    │    └─GateLayer2d: 5-9        [1, 64, 8, 8]             [1, 64, 8, 8]             8,320\n",
      "├─Sequential: 1-2                             [1, 64, 8, 8]             [1, 64, 8, 8]             --\n",
      "========================================================================================================================\n",
      "Total params: 119,360\n",
      "Trainable params: 119,360\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 7.62\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 0.23\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 0.77\n",
      "========================================================================================================================\n",
      "========================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
      "========================================================================================================================\n",
      "BottomUpLayer                                 [1, 64, 8, 8]             [1, 64, 4, 4]             --\n",
      "├─Sequential: 1-1                             [1, 64, 8, 8]             [1, 64, 4, 4]             --\n",
      "│    └─BottomUpDeterministicResBlock: 2-1     [1, 64, 8, 8]             [1, 64, 4, 4]             --\n",
      "│    │    └─Conv2d: 3-1                       [1, 64, 8, 8]             [1, 64, 4, 4]             36,928\n",
      "│    │    └─ResidualBlock: 3-2                [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    └─Sequential: 4-1              [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-1        [1, 64, 4, 4]             [1, 64, 4, 4]             128\n",
      "│    │    │    │    └─ELU: 5-2                [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─Conv2d: 5-3             [1, 64, 4, 4]             [1, 64, 4, 4]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-4          [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-5        [1, 64, 4, 4]             [1, 64, 4, 4]             128\n",
      "│    │    │    │    └─ELU: 5-6                [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─Conv2d: 5-7             [1, 64, 4, 4]             [1, 64, 4, 4]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-8          [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "│    │    │    │    └─GateLayer2d: 5-9        [1, 64, 4, 4]             [1, 64, 4, 4]             8,320\n",
      "├─Sequential: 1-2                             [1, 64, 4, 4]             [1, 64, 4, 4]             --\n",
      "========================================================================================================================\n",
      "Total params: 119,360\n",
      "Trainable params: 119,360\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 1.91\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 0.55\n",
      "========================================================================================================================\n",
      "========================================================================================================================\n",
      "Layer (type:depth-idx)                        Input Shape               Output Shape              Param #\n",
      "========================================================================================================================\n",
      "BottomUpLayer                                 [1, 64, 4, 4]             [1, 64, 2, 2]             --\n",
      "├─Sequential: 1-1                             [1, 64, 4, 4]             [1, 64, 2, 2]             --\n",
      "│    └─BottomUpDeterministicResBlock: 2-1     [1, 64, 4, 4]             [1, 64, 2, 2]             --\n",
      "│    │    └─Conv2d: 3-1                       [1, 64, 4, 4]             [1, 64, 2, 2]             36,928\n",
      "│    │    └─ResidualBlock: 3-2                [1, 64, 2, 2]             [1, 64, 2, 2]             --\n",
      "│    │    │    └─Sequential: 4-1              [1, 64, 2, 2]             [1, 64, 2, 2]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-1        [1, 64, 2, 2]             [1, 64, 2, 2]             128\n",
      "│    │    │    │    └─ELU: 5-2                [1, 64, 2, 2]             [1, 64, 2, 2]             --\n",
      "│    │    │    │    └─Conv2d: 5-3             [1, 64, 2, 2]             [1, 64, 2, 2]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-4          [1, 64, 2, 2]             [1, 64, 2, 2]             --\n",
      "│    │    │    │    └─BatchNorm2d: 5-5        [1, 64, 2, 2]             [1, 64, 2, 2]             128\n",
      "│    │    │    │    └─ELU: 5-6                [1, 64, 2, 2]             [1, 64, 2, 2]             --\n",
      "│    │    │    │    └─Conv2d: 5-7             [1, 64, 2, 2]             [1, 64, 2, 2]             36,928\n",
      "│    │    │    │    └─Dropout2d: 5-8          [1, 64, 2, 2]             [1, 64, 2, 2]             --\n",
      "│    │    │    │    └─GateLayer2d: 5-9        [1, 64, 2, 2]             [1, 64, 2, 2]             8,320\n",
      "├─Sequential: 1-2                             [1, 64, 2, 2]             [1, 64, 2, 2]             --\n",
      "========================================================================================================================\n",
      "Total params: 119,360\n",
      "Trainable params: 119,360\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.48\n",
      "========================================================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 0.50\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# bottom_up_layers is a ModuleList, so it doesn't have an explicit forward()\n",
    "# We need to call the forward() of the single modules\n",
    "inp_size = [64, 32, 32]\n",
    "\n",
    "for bottom_up_layer in bottom_up_layers: \n",
    "    curr_summary = summary(\n",
    "        model=bottom_up_layer,\n",
    "        input_size=inp_size,\n",
    "        batch_dim=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        depth=5\n",
    "    )\n",
    "    print(curr_summary)\n",
    "    inp_size[1] = inp_size[2] = inp_size[1] // 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** With the assumption that *Lateral Contextualization* is **disabled**, the parameters that can influence the structure of `bottom_up_layers` are:\n",
    "- `self.encoder_blocks_per_layer` -> number of `BottomUpDeterministicResBlock`s in each `BottomUpLayer`\n",
    "- `self.encoder_n_filters` -> sets the number of channels within **all** the *Encoder* layers (recall that all the layers share the same number of channels).\n",
    "- `self.encoder_res_block_kernel`, `self.encoder_res_block_skip_padding`, `self.res_block_type` -> set the specifics of residual blocks throughout all the *Encoder* layers.\n",
    "\n",
    "The number of `downsampling_steps` is set in the `LadderVAE` constructor by default to `1` for each `BottomUpLayer` and cannot be changed from outside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Lateral Contextualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Top-Down pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Likelihood Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lvae_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
