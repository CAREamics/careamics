{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing `LadderVAE` module\n",
    "In this notebook we test the different layers of LadderVAE model to check:\n",
    "- Whether all the necessary blocks/layers are here,\n",
    "- Whether the current version of the blocks/layers does the right thing (i.e., model flow, size of outputs given inputs, ...).\n",
    "\n",
    "We will do this by initializing a standard LadderVAE model (default options). Afterward, we will progressively adding supplementary features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import ml_collections\n",
    "from torchinfo import summary\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/home/federico.carrara/Documents/projects/careamics/src/careamics/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lvae.lvae import LadderVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a first thing we create a model `config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a default config object\n",
    "def get_default_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "\n",
    "    config.data = ml_collections.ConfigDict()\n",
    "    # config.data.sampler_type = SamplerType.DefaultSampler\n",
    "    config.data.sampler_type = None\n",
    "\n",
    "    config.model = ml_collections.ConfigDict()\n",
    "    config.model.use_vampprior = False\n",
    "    config.model.encoder = ml_collections.ConfigDict()\n",
    "    config.model.decoder = ml_collections.ConfigDict()\n",
    "    config.model.decoder.conv2d_bias = True\n",
    "\n",
    "    config.loss = ml_collections.ConfigDict()\n",
    "\n",
    "    config.training = ml_collections.ConfigDict()\n",
    "    config.training.batch_size = 32\n",
    "\n",
    "    config.training.grad_clip_norm_value = 0.5  # Taken from https://github.com/openai/vdvae/blob/main/hps.py#L38\n",
    "    config.training.gradient_clip_algorithm = 'value'\n",
    "    config.training.earlystop_patience = 100\n",
    "    config.training.precision = 32\n",
    "    config.training.pre_trained_ckpt_fpath = ''\n",
    "\n",
    "    config.git = ml_collections.ConfigDict()\n",
    "    config.git.changedFiles = []\n",
    "    config.git.branch = ''\n",
    "    config.git.untracked_files = []\n",
    "    config.git.latest_commit = ''\n",
    "\n",
    "    config.workdir = '/home/federico.carrara/Documents/projects/careamics/src/careamics/models/lvae'\n",
    "    config.datadir = ''\n",
    "    config.hostname = ''\n",
    "    config.exptname = ''\n",
    "    \n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function for editing `config.model` fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_edit_model_config(config: ml_collections.ConfigDict) -> None:\n",
    "    \n",
    "    model = config.model\n",
    "\n",
    "    # Set the size of the latent spaces in the hierarchical levels\n",
    "    # NOTE: each entry is the latent space size of the corresponding level\n",
    "    # The number of entries should be equal to the number of levels\n",
    "    model.z_dims = [128, 128, 128, 128]\n",
    "\n",
    "    # Set the Encoder architecture\n",
    "    model.encoder.batchnorm = True\n",
    "    model.encoder.blocks_per_layer = 1\n",
    "    model.encoder.n_filters = 64\n",
    "    model.encoder.dropout = 0.1\n",
    "    model.encoder.res_block_kernel = 3\n",
    "    model.encoder.res_block_skip_padding = False\n",
    "\n",
    "    # Set the Decoder architecture\n",
    "    model.decoder.batchnorm = True\n",
    "    model.decoder.blocks_per_layer = 1\n",
    "    model.decoder.n_filters = 64\n",
    "    model.decoder.dropout = 0.1\n",
    "    model.decoder.res_block_kernel = 3\n",
    "    model.decoder.res_block_skip_padding = False\n",
    "    model.decoder.conv2d_bias = True\n",
    "\n",
    "    # Set common architecture parameters\n",
    "    model.res_block_type = 'bacdbacd'\n",
    "    model.gated = True\n",
    "    model.nonlin = 'elu'\n",
    "    model.merge_type = 'residual'\n",
    "    model.learn_top_prior = False\n",
    "    model.analytical_kl = False\n",
    "    model.mode_pred = False\n",
    "    model.no_initial_downscaling = True\n",
    "\n",
    "    # Whether to use a stochastic skip connection in the top-down pass\n",
    "    model.stochastic_skip = False\n",
    "\n",
    "    # Whether to predict_logvar, to be chosen among [None,'global','channelwise','pixelwise']\n",
    "    model.predict_logvar = None\n",
    "\n",
    "    # Set LC-related fields\n",
    "    model.multiscale_lowres_separate_branch = False\n",
    "    model.multiscale_retain_spatial_dims = True\n",
    "\n",
    "    # Whether to use stochastic block in the top-down pass\n",
    "    model.non_stochastic_version = False\n",
    "\n",
    "    # For enabling/disabling noise model\n",
    "    model.enable_noise_model = False\n",
    "    model.noise_model_ch1_fpath = ''\n",
    "    model.noise_model_ch2_fpath = ''\n",
    "    model.noise_model_type = 'gmm' #hist\n",
    "\n",
    "    # Additional parameters (most likely we don't need to change these)\n",
    "    model.monitor = 'val_psnr'  # {'val_loss','val_psnr'}\n",
    "    model.skip_nboundary_pixels_from_loss = None\n",
    "    model.logvar_lowerbound = -5  # -2.49 is log(1/12), from paper \"Re-parametrizing VAE for stablity.\"\n",
    "    model.var_clip_max = 20\n",
    "    model.img_shape = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Function to edit other `config` fields (needed to init the `LadderVAE` model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_edit_others_config(config: ml_collections.ConfigDict) -> None:\n",
    "    # Data fields\n",
    "    data = config.data\n",
    "\n",
    "    # Set info about input data shape\n",
    "    data.image_size = 64\n",
    "    data.multiscale_lowres_count = 1\n",
    "\n",
    "    # These are not used in the model, so no need to touch them\n",
    "    data.normalized_input = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utility function for custom `config` objects \n",
    "Actually we'd like to have a utility function that enables us to modify a subset of the config's fields that needs to be changed while doing different tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_config(\n",
    "    z_dims: List[int] = [128, 128, 128, 128],\n",
    "    blocks_per_layer: int = 1,\n",
    "    n_filters: int = 64,\n",
    "    learn_top_prior: bool = False,\n",
    "    no_initial_downscaling: bool = True,\n",
    "    stochastic_skip: bool = False,\n",
    "    predict_logvar: str = None,\n",
    "    multiscale_lowres_separate_branch: bool = False,\n",
    "    non_stochastic_version: bool = False,\n",
    "    image_size: int = 64,\n",
    "    multiscale_lowres_count: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    NOTE: `len(z_dims)` determines the number of hierarchical levels (e.g., number of `BottomUpLayers`)\n",
    "    in the model. The information is stored in the `self.n_layers` attribute.\n",
    "    \"\"\"\n",
    "    \n",
    "    config = get_default_config()\n",
    "    default_edit_model_config(config)\n",
    "    default_edit_others_config(config)\n",
    "    \n",
    "    model = config.model\n",
    "    model.z_dims = z_dims\n",
    "    model.encoder.blocks_per_layer = blocks_per_layer\n",
    "    model.encoder.n_filters = n_filters\n",
    "    model.decoder.blocks_per_layer = blocks_per_layer\n",
    "    model.decoder.n_filters = n_filters\n",
    "    model.learn_top_prior = learn_top_prior\n",
    "    model.no_initial_downscaling = no_initial_downscaling\n",
    "    model.stochastic_skip = stochastic_skip\n",
    "    model.predict_logvar = predict_logvar\n",
    "    model.multiscale_lowres_separate_branch = multiscale_lowres_separate_branch\n",
    "    model.non_stochastic_version = non_stochastic_version\n",
    "\n",
    "    config.data.image_size = image_size\n",
    "    config.data.multiscale_lowres_count = multiscale_lowres_count\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to check the functioning of the different components of the `LadderVAE` model.\n",
    "\n",
    "Specifically, for each component of the model we check:\n",
    "1. Whether all the submodules and parameters required to define the model are provided/available.\n",
    "2. Whether that module is consistent, i.e., given a certain input it produces outputs of the expected size.\n",
    "3. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. LVAE model initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we check if the LVAE model constructor works as expected given the right inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create `config` object and initialize other required parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_custom_config()\n",
    "\n",
    "# Additional required parameters (not in the config)\n",
    "data_mean = data_std = np.array([0.5, 0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize `LadderVAE` instance to check constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvae_model = LadderVAE(\n",
    "    config=config, \n",
    "    data_mean=data_mean, \n",
    "    data_std=data_std\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LadderVAE` constructor: test passed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bottom-Up pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. First Bottom-Up layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we tested `LadderVAE` constructor, meaning that we implicitly tested that `LadderVAE.create_first_bottom_up()` works.\n",
    "\n",
    "Therefore we are left to test that:\n",
    "- `LadderVAE.create_first_bottom_up()` builds the model correctly given the input parameters.\n",
    "- The forward method of the resulting `first_bottom_up` is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom config\n",
    "config = get_custom_config(\n",
    "    z_dims=[128, 128, 128, 128],\n",
    "    blocks_per_layer=1,\n",
    "    n_filters=64,\n",
    "    learn_top_prior=False,\n",
    "    no_initial_downscaling=False,\n",
    "    stochastic_skip=False,\n",
    "    predict_logvar=None,\n",
    "    multiscale_lowres_separate_branch=False,\n",
    "    non_stochastic_version=False,\n",
    "    image_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a LadderVAE instance\n",
    "lvae_model = LadderVAE(config=config, data_mean=np.empty((32, 1)), data_std=np.empty((32, 1)))\n",
    "\n",
    "# Extract the first bottom-up layer\n",
    "first_bottom_up = lvae_model.first_bottom_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the structure using `torchinfo.summary`. This allows to check also whether the `forward` method works correctly.\n",
    "\n",
    "**NOTE:** We assume that:\n",
    "- Input patches have size `(1, 64, 64)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(\n",
    "    model=first_bottom_up,\n",
    "    input_size=(1, 64, 64),\n",
    "    batch_dim=0,\n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "    depth=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The parameters that can influence the structure of `first_bottom_up` layer are:\n",
    "- `self.no_initial_downscaling` -> if `False`, the `stride` of the initial `Conv2d` block is set to `2`. This parameters influences this layer only!\n",
    "- `self.encoder_n_filters` -> sets the number of channels within **all** the *Encoder* layers (recall that all the layers share the same number of channels).\n",
    "- `self.encoder_res_block_kernel`, `self.encoder_res_block_skip_padding`, `self.res_block_type` -> set the specifics of residual blocks throughout all the *Encoder* layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Bottom-Up Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the previous layer, we have to test that:\n",
    "- `LadderVAE.create_bottom_up_layers()` builds the model correctly given the input parameters.\n",
    "- The forward method of the resulting `bottom_u_layers` module list is consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom config\n",
    "config = get_custom_config(\n",
    "    z_dims=[128, 128, 128, 128],\n",
    "    blocks_per_layer=1,\n",
    "    n_filters=64,\n",
    "    learn_top_prior=False,\n",
    "    no_initial_downscaling=False,\n",
    "    stochastic_skip=False,\n",
    "    predict_logvar=None,\n",
    "    multiscale_lowres_separate_branch=False,\n",
    "    non_stochastic_version=False,\n",
    "    image_size=64,\n",
    "    multiscale_lowres_count=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a LadderVAE instance\n",
    "lvae_model = LadderVAE(config=config, data_mean=np.empty((32, 1)), data_std=np.empty((32, 1)))\n",
    "\n",
    "# Extract the ModuleList of bottom-up layers\n",
    "bottom_up_layers = lvae_model.bottom_up_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the structure using `torchinfo.summary`. This allows to check also whether the `forward` method works correctly.\n",
    "\n",
    "**NOTE:** We assume that:\n",
    "- Input patches have size `(1, 64, 64)`.\n",
    "- `first_bottom_up` uses `64` channels, and that performs *initial downsampling*.\n",
    "- There is **only one** downsampling step within each `BottomUpLayer`.\n",
    "- *Lateral Contextualization* is disabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottom_up_layers is a ModuleList, so it doesn't have an explicit forward()\n",
    "# We need to call the forward() of the single modules\n",
    "inp_size = [64, 32, 32]\n",
    "\n",
    "for bottom_up_layer in bottom_up_layers: \n",
    "    curr_summary = summary(\n",
    "        model=bottom_up_layer,\n",
    "        input_size=inp_size,\n",
    "        batch_dim=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"],\n",
    "        depth=5\n",
    "    )\n",
    "    print(curr_summary)\n",
    "    inp_size[1] = inp_size[2] = inp_size[1] // 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** With the assumption that *Lateral Contextualization* is **disabled**, the parameters that can influence the structure of `bottom_up_layers` are:\n",
    "- `self.encoder_blocks_per_layer` -> number of `BottomUpDeterministicResBlock`s in each `BottomUpLayer`\n",
    "- `self.encoder_n_filters` -> sets the number of channels within **all** the *Encoder* layers (recall that all the layers share the same number of channels).\n",
    "- `self.encoder_res_block_kernel`, `self.encoder_res_block_skip_padding`, `self.res_block_type` -> set the specifics of residual blocks throughout all the *Encoder* layers.\n",
    "\n",
    "The number of `downsampling_steps` is set in the `LadderVAE` constructor by default to `1` for each `BottomUpLayer` and cannot be changed from outside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of each `BottomUpLayer` module is a tuple of two tensors:\n",
    "\n",
    "- The first tensor represents the output of the layer, i.e., the input to the following bottom-up layer (we call it `x`, see `_bottoup_pass()` method, line 660).\n",
    "- The second tensor represents, instead, the so-called `bu_value`, which is sent to the top-down pass for computing the inference distributions $q_\\phi(z_i|z_{i+1})$.\n",
    "\n",
    "Observe that in the simple case of disabled *LC,*  the two tensors coincide and their size is given by `(BxCxH*xW*)`, where `H* = H / (2*downsampling_steps)` and `W* = W / (2*downsampling_steps)`.\n",
    "\n",
    "To conclude, it is important to remark that the output of the `_bottoup_pass()` is a list containing the `bu_value` tensors computed at the different hierarchical levels of the *Encoder.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Lateral Contextualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will skip this for the moment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Top-Down pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Top-Down Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required tests:\n",
    "- `LadderVAE.create_top_down_layers()` builds the model correctly given the input parameters.\n",
    "- The forward methods of the resulting `top_down_layers` modules are consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom config\n",
    "config = get_custom_config(\n",
    "    z_dims=[128, 128, 128, 128],\n",
    "    blocks_per_layer=1,\n",
    "    n_filters=64,\n",
    "    learn_top_prior=False,\n",
    "    no_initial_downscaling=True,\n",
    "    stochastic_skip=False,\n",
    "    predict_logvar=None,\n",
    "    multiscale_lowres_separate_branch=False,\n",
    "    non_stochastic_version=False,\n",
    "    image_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a LadderVAE instance\n",
    "lvae_model = LadderVAE(config=config, data_mean=np.empty((32, 1)), data_std=np.empty((32, 1)))\n",
    "\n",
    "# Extract the first bottom-up layer\n",
    "top_down_layers = lvae_model.top_down_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the structure using `torchinfo.summary`. This allows to check also whether the `forward` method works correctly.\n",
    "\n",
    "**NOTE:** We assume that:\n",
    "- Inputs are the `bu_values` computed in the Bottom-Up pass. Their size is `[batch, ch, 2**(i+1), 2**(i+1)]`, where `i=0` is the topmost level, and `i=n_layers-1` is the bottom-most one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# top_down_layers is a ModuleList, so it doesn't have an explicit forward()\n",
    "# We need to call the forward() of the single modules\n",
    "\n",
    "# Define a dict of the inputs\n",
    "inp_size = torch.tensor([1, 64, 8, 8])\n",
    "others_inp_data = {\n",
    "    \"input_\": torch.rand(tuple(inp_size)), # we start from (topmost-1)-th layer\n",
    "    \"skip_connection_input\": None,\n",
    "    \"inference_mode\": True,\n",
    "    \"bu_value\": torch.rand(tuple(inp_size)),\n",
    "    \"n_img_prior\": None,\n",
    "    \"forced_latent\": None,\n",
    "    \"use_mode\": False,\n",
    "    \"force_constant_output\": False,\n",
    "    \"mode_pred\": False,\n",
    "    \"use_uncond_mode\": False,\n",
    "    \"var_clip_max\": None\n",
    "}\n",
    "\n",
    "topmost_inp_data = deepcopy(others_inp_data)\n",
    "topmost_inp_data[\"input_\"] = None\n",
    "topmost_inp_data[\"bu_value\"] = torch.rand((1, 64, 4, 4))\n",
    "\n",
    "for i in range(len(top_down_layers) - 2, -1, -1):\n",
    "    is_top = i == len(top_down_layers) - 1\n",
    "    \n",
    "    if is_top:\n",
    "        curr_summary = summary(\n",
    "            input_data=topmost_inp_data,\n",
    "            model=top_down_layers[i],\n",
    "            batch_dim=0,\n",
    "            col_names=[\"input_size\", \"output_size\"],\n",
    "            depth=5\n",
    "        )\n",
    "    else:\n",
    "        curr_summary = summary(\n",
    "            input_data=others_inp_data,\n",
    "            model=top_down_layers[i],\n",
    "            batch_dim=0,\n",
    "            col_names=[\"input_size\", \"output_size\"],\n",
    "            depth=5\n",
    "        )\n",
    "    print(curr_summary)\n",
    "    \n",
    "    inp_size[2:] = inp_size[2:] * 2 \n",
    "    others_inp_data[\"input_\"] = torch.tensor(tuple(inp_size))\n",
    "    print(others_inp_data[\"input_\"].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: find a smart way to print the intermediate results and outputs without using `torchinfo`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** The parameters that can influence the structure of `first_bottom_up` layer are:\n",
    "- `self.no_initial_downscaling` -> if `False`, the `stride` of the initial `Conv2d` block is set to `2`. This parameters influences this layer only!\n",
    "- `self.encoder_n_filters` -> sets the number of channels within **all** the *Encoder* layers (recall that all the layers share the same number of channels).\n",
    "- `self.encoder_res_block_kernel`, `self.encoder_res_block_skip_padding`, `self.res_block_type` -> set the specifics of residual blocks throughout all the *Encoder* layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Likelihood Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lvae_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
