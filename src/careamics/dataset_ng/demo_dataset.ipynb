{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tifffile\n",
    "\n",
    "from careamics.config import create_n2n_configuration\n",
    "from careamics.dataset_ng.dataset.dataset import Mode\n",
    "from careamics.dataset_ng.dataset.factory import create_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/igor.zubarev/projects/microSplit-reproducibility/examples/2D/custom_test/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1 = tifffile.imread(Path(data_path) / \"ch1/Neurofilament_01.tif\")\n",
    "ch2 = tifffile.imread(Path(data_path) / \"ch2/SV2_01.tif\")\n",
    "\n",
    "_, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(ch1, cmap=\"gray\")\n",
    "ax[1].imshow(ch2, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.stack([ch1, ch2], axis=0)\n",
    "print(input_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = (64, 64)\n",
    "coords = [(160, 1387), (1173, 786)]\n",
    "\n",
    "for context_level in range(1, 3):\n",
    "    print(context_level)\n",
    "    lc_coords = [(c - context_level * p // 2, e - context_level * p // 2) for (c, e), p in zip(coords, patch_size)]\n",
    "    lc_patch_size = [dim * context_level for dim in patch_size]\n",
    "    print(lc_coords, lc_coords[0][1] - coords[0][1], lc_coords[0][0] - coords[0][0], lc_patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 1. From an array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train val from an array\n",
    "\n",
    "train_data_config = create_n2n_configuration(\n",
    "    \"test_exp\",\n",
    "    data_type=\"array\",\n",
    "    axes=\"CYX\",\n",
    "    n_channels_in=2,\n",
    "    patch_size=(256, 256),\n",
    "    batch_size=1,\n",
    "    num_epochs=1,\n",
    "    augmentations=[],\n",
    ").data_config\n",
    "\n",
    "\n",
<<<<<<< HEAD
    "train_dataset = create_dataset(\n",
    "    config=train_data_config,\n",
    "    mode=Mode.TRAINING,\n",
    "    inputs=[example_data],\n",
    "    targets=[segmentation],\n",
    "    in_memory=True,\n",
    ")\n",
    "val_dataset = create_dataset(\n",
    "    config=val_data_config,\n",
    "    mode=Mode.VALIDATING,\n",
    "    inputs=[example_data],\n",
    "    targets=[segmentation],\n",
    "    in_memory=True,\n",
=======
    "# val_data_config = create_n2n_configuration(\n",
    "#     \"test_exp\",\n",
    "#     data_type=\"array\",\n",
    "#     axes=\"YX\",\n",
    "#     patch_size=(256, 256),\n",
    "#     batch_size=1,\n",
    "#     num_epochs=1,\n",
    "#     augmentations=[],\n",
    "# ).data_config\n",
    "\n",
    "for i in train_data_config:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CareamicsDataset(\n",
    "    data_config=train_data_config, inputs=None, targets=[input_img]\n",
>>>>>>> origin/iz/feat/ms_nextgen_ds
    ")\n",
    "# val_dataset = CareamicsDataset(\n",
    "#     data_config=val_data_config, inputs=None, targets=[data_path]\n",
    "# )\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "ax[0, 0].set_title(\"Train input\")\n",
    "ax[1, 0].set_title(\"Train target\")\n",
    "for i in range(5):\n",
    "    sample, target = train_dataset[i]\n",
    "    # ax[0, i].imshow(sample.data[0])\n",
    "    ax[1, i].imshow(target.data)"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "7",
=======
   "id": "8",
>>>>>>> origin/iz/feat/ms_nextgen_ds
   "metadata": {},
   "source": [
    "### 2. From tiff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "8",
=======
   "id": "9",
>>>>>>> origin/iz/feat/ms_nextgen_ds
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_config = create_n2n_configuration(\n",
    "    \"test_exp\",\n",
    "    data_type=\"tiff\",\n",
    "    axes=\"YX\",\n",
    "    patch_size=(32, 32),\n",
    "    batch_size=1,\n",
    "    num_epochs=1,\n",
    ").data_config\n",
    "\n",
    "val_data_config = create_n2n_configuration(\n",
    "    \"test_exp\",\n",
    "    data_type=\"tiff\",\n",
    "    axes=\"YX\",\n",
    "    patch_size=(32, 32),\n",
    "    batch_size=1,\n",
    "    num_epochs=1,\n",
    "    augmentations=[],\n",
    ").data_config\n",
    "\n",
    "data = sorted(Path(\"./\").glob(\"example_data*.tiff\"))\n",
    "targets = sorted(Path(\"./\").glob(\"example_target*.tiff\"))\n",
    "train_dataset = CareamicsDataset(\n",
    "    data_config=train_data_config, mode=Mode.TRAINING, inputs=data, targets=targets\n",
    ")\n",
    "val_dataset = CareamicsDataset(\n",
    "    data_config=val_data_config, mode=Mode.VALIDATING, inputs=data, targets=targets\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(2, 5, figsize=(10, 5))\n",
    "ax[0, 0].set_title(\"Train input\")\n",
    "ax[1, 0].set_title(\"Train target\")\n",
    "for i in range(5):\n",
    "    sample, target = train_dataset[i]\n",
    "    ax[0, i].imshow(sample.data[0])\n",
    "    ax[1, i].imshow(target.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "9",
=======
   "id": "10",
>>>>>>> origin/iz/feat/ms_nextgen_ds
   "metadata": {},
   "source": [
    "### 3. Prediction from array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "10",
=======
   "id": "11",
>>>>>>> origin/iz/feat/ms_nextgen_ds
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.config import InferenceConfig\n",
    "\n",
    "prediction_config = InferenceConfig(\n",
    "    data_type=\"array\",\n",
    "    tile_size=(32, 32),\n",
    "    tile_overlap=(16, 16),\n",
    "    axes=\"YX\",\n",
    "    image_means=(example_data.mean(),),\n",
    "    image_stds=(example_data.std(),),\n",
    "    tta_transforms=False,\n",
    "    batch_size=1,\n",
    ")\n",
    "prediction_dataset = create_dataset(\n",
    "    config=prediction_config,\n",
    "    mode=Mode.PREDICTING,\n",
    "    inputs=[example_data],\n",
    "    targets=None,\n",
    "    in_memory=True,\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(10, 5))\n",
    "ax[0].set_title(\"Prediction input\")\n",
    "for i in range(5):\n",
    "    sample, _ = prediction_dataset[i]\n",
    "    ax[i].imshow(sample.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
<<<<<<< HEAD
   "id": "11",
=======
   "id": "12",
>>>>>>> origin/iz/feat/ms_nextgen_ds
   "metadata": {},
   "source": [
    "### 4. From custom data type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "12",
=======
   "id": "13",
>>>>>>> origin/iz/feat/ms_nextgen_ds
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_config = create_n2n_configuration(\n",
    "    \"test_exp\",\n",
    "    data_type=\"custom\",\n",
    "    axes=\"YX\",\n",
    "    patch_size=(32, 32),\n",
    "    batch_size=1,\n",
    "    num_epochs=1,\n",
    ").data_config\n",
    "\n",
    "\n",
    "def read_data_func_test(example_data):\n",
    "    return 255 - example_data\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(10, 5))\n",
    "train_dataset = create_dataset(\n",
    "    config=train_data_config,\n",
    "    mode=Mode.TRAINING,\n",
    "    inputs=[example_data],\n",
    "    targets=[segmentation],\n",
    "    in_memory=True,\n",
    "    read_func=read_data_func_test,\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    sample, _ = train_dataset[i]\n",
    "    ax[i].imshow(sample.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
