{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from careamics_portfolio import PortfolioManager\n",
    "\n",
    "from careamics.config.configuration_factories import (\n",
    "    _create_ng_data_configuration,\n",
    "    create_n2v_configuration,\n",
    ")\n",
    "from careamics.config.data import NGDataConfig\n",
    "from careamics.lightning.callbacks import HyperParametersCallback\n",
    "from careamics.lightning.dataset_ng.data_module import CareamicsDataModule\n",
    "from careamics.lightning.dataset_ng.lightning_modules import N2VModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and set paths to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data portfolio manage and download the data\n",
    "root_path = Path(\"./data\")\n",
    "\n",
    "portfolio = PortfolioManager()\n",
    "files = portfolio.denoising.N2V_BSD68.download(root_path)\n",
    "\n",
    "# create paths for the data\n",
    "data_path = Path(root_path / \"denoising-N2V_BSD68.unzip/BSD68_reproducibility_data\")\n",
    "train_path = data_path / \"train\"\n",
    "val_path = data_path / \"val\"\n",
    "test_path = data_path / \"test\" / \"images\"\n",
    "gt_path = data_path / \"test\" / \"gt\"\n",
    "\n",
    "# list train, val and test files\n",
    "train_files = sorted(train_path.rglob(\"*.tiff\"))\n",
    "val_files = sorted(val_path.rglob(\"*.tiff\"))\n",
    "test_files = sorted(test_path.rglob(\"*.tiff\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a single train and val image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and validation image and show them side by side\n",
    "single_train_image = tifffile.imread(train_files[0])[0]\n",
    "single_val_image = tifffile.imread(val_files[0])[0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(single_train_image, cmap=\"gray\")\n",
    "ax[0].set_title(\"Training Image\")\n",
    "ax[1].imshow(single_val_image, cmap=\"gray\")\n",
    "ax[1].set_title(\"Validation Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_n2v_configuration(\n",
    "    experiment_name=\"bsd68_n2v\",\n",
    "    data_type=\"tiff\",\n",
    "    axes=\"SYX\",\n",
    "    patch_size=(64, 64),\n",
    "    batch_size=64,\n",
    "    num_epochs=100,\n",
    ")\n",
    "\n",
    "# TODO until the NGDataConfig is accepted by the Confiugration, these are separte\n",
    "ng_data_config = _create_ng_data_configuration(\n",
    "    data_type=config.data_config.data_type,\n",
    "    axes=config.data_config.axes,\n",
    "    patch_size=config.data_config.patch_size,\n",
    "    batch_size=config.data_config.batch_size,\n",
    "    augmentations=config.data_config.transforms,\n",
    "    train_dataloader_params=config.data_config.train_dataloader_params,\n",
    "    val_dataloader_params=config.data_config.val_dataloader_params,\n",
    "    seed=seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lightning datamodule and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_module = CareamicsDataModule(\n",
    "    data_config=ng_data_config,\n",
    "    train_data=train_files,\n",
    "    val_data=val_files,\n",
    ")\n",
    "\n",
    "model = N2VModule(config.algorithm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually initialize the datamodule and visualize single train and val batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_module.setup(\"fit\")\n",
    "train_data_module.setup(\"validate\")\n",
    "\n",
    "train_batch = next(iter(train_data_module.train_dataloader()))\n",
    "val_batch = next(iter(train_data_module.val_dataloader()))\n",
    "\n",
    "fig, ax = plt.subplots(1, 8, figsize=(10, 5))\n",
    "ax[0].set_title(\"Training Batch\")\n",
    "for i in range(8):\n",
    "    ax[i].imshow(train_batch[0].data[i][0].numpy(), cmap=\"gray\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 8, figsize=(10, 5))\n",
    "ax[0].set_title(\"Validation Batch\")\n",
    "for i in range(8):\n",
    "    ax[i].imshow(val_batch[0].data[i][0].numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "root = Path(\"bsd68_n2v\")\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath=root / \"checkpoints\",\n",
    "        filename=\"bsd68_new_lightning_module\",\n",
    "        save_last=True,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    HyperParametersCallback(config),\n",
    "]\n",
    "logger = WandbLogger(project=\"bsd68-n2v\", name=\"bsd68_new_lightning_module\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=50, default_root_dir=root, callbacks=callbacks, logger=logger\n",
    ")\n",
    "trainer.fit(model, datamodule=train_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an inference config and datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.dataset_ng.legacy_interoperability import imageregions_to_tileinfos\n",
    "from careamics.prediction_utils import convert_outputs\n",
    "\n",
    "config = NGDataConfig(\n",
    "    data_type=\"tiff\",\n",
    "    patching={\n",
    "        \"name\": \"tiled\",\n",
    "        \"patch_size\": (128, 128),\n",
    "        \"overlaps\": (32, 32),\n",
    "    },\n",
    "    axes=\"YX\",\n",
    "    batch_size=1,\n",
    "    image_means=train_data_module.train_dataset.input_stats.means,\n",
    "    image_stds=train_data_module.train_dataset.input_stats.stds,\n",
    ")\n",
    "\n",
    "inf_data_module = CareamicsDataModule(data_config=config, pred_data=test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert outputs to the legacy format and stitch the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(model, datamodule=inf_data_module)\n",
    "tile_infos = imageregions_to_tileinfos(predictions)\n",
    "predictions = convert_outputs(tile_infos, tiled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predictions and count metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.utils.metrics import psnr, scale_invariant_psnr\n",
    "\n",
    "noises = [tifffile.imread(f) for f in sorted(test_path.glob(\"*.tiff\"))]\n",
    "gts = [tifffile.imread(f) for f in sorted(gt_path.glob(\"*.tiff\"))]\n",
    "\n",
    "images = [0, 1, 2]\n",
    "fig, ax = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(3):\n",
    "    pred_image = predictions[images[i]].squeeze()\n",
    "    psnr_noisy = psnr(\n",
    "        gts[images[i]],\n",
    "        noises[images[i]],\n",
    "        data_range=gts[images[i]].max() - gts[images[i]].min(),\n",
    "    )\n",
    "    psnr_result = psnr(\n",
    "        gts[images[i]],\n",
    "        pred_image,\n",
    "        data_range=gts[images[i]].max() - gts[images[i]].min(),\n",
    "    )\n",
    "\n",
    "    scale_invariant_psnr_result = scale_invariant_psnr(gts[images[i]], pred_image)\n",
    "\n",
    "    ax[i, 0].imshow(noises[images[i]], cmap=\"gray\")\n",
    "    ax[i, 0].title.set_text(f\"Noisy\\nPSNR: {psnr_noisy:.2f}\")\n",
    "\n",
    "    ax[i, 1].imshow(pred_image, cmap=\"gray\")\n",
    "    ax[i, 1].title.set_text(\n",
    "        f\"Prediction\\nPSNR: {psnr_result:.2f}\\n\"\n",
    "        f\"Scale invariant PSNR: {scale_invariant_psnr_result:.2f}\"\n",
    "    )\n",
    "\n",
    "    ax[i, 2].imshow(gts[images[i]], cmap=\"gray\")\n",
    "    ax[i, 2].title.set_text(\"Ground-truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnrs = np.zeros((len(predictions), 1))\n",
    "scale_invariant_psnrs = np.zeros((len(predictions), 1))\n",
    "\n",
    "for i, (pred, gt) in enumerate(zip(predictions, gts, strict=False)):\n",
    "    psnrs[i] = psnr(gt, pred.squeeze(), data_range=gt.max() - gt.min())\n",
    "    scale_invariant_psnrs[i] = scale_invariant_psnr(gt, pred.squeeze())\n",
    "\n",
    "print(f\"PSNR: {psnrs.mean():.2f} +/- {psnrs.std():.2f}\")\n",
    "print(\n",
    "    f\"Scale invariant PSNR: \"\n",
    "    f\"{scale_invariant_psnrs.mean():.2f} +/- {scale_invariant_psnrs.std():.2f}\"\n",
    ")\n",
    "print(\"Reported PSNR: 27.71\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "czi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
