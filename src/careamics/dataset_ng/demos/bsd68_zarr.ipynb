{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from pathlib import Path\n",
    "from typing import TypedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import zarr\n",
    "\n",
    "from careamics.config.configuration_factories import (\n",
    "    _create_ng_data_configuration,\n",
    "    create_n2v_configuration,\n",
    ")\n",
    "from careamics.config.data import NGDataConfig\n",
    "from careamics.dataset_ng.patch_extractor.image_stack import ZarrImageStack\n",
    "from careamics.lightning.callbacks import HyperParametersCallback\n",
    "from careamics.lightning.dataset_ng.data_module import CareamicsDataModule\n",
    "from careamics.lightning.dataset_ng.lightning_modules import N2VModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and register internal paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate data portfolio manage and download the data\n",
    "root_path = Path(\"./data\") / \"bsd68.zarr\"\n",
    "\n",
    "\n",
    "data = zarr.open(root_path, mode=\"a\")\n",
    "train_source = data[\"train\"]\n",
    "val_source = data[\"val\"]\n",
    "test_source = data[\"test_raw\"]\n",
    "train_arrays = sorted([f for f in train_source])\n",
    "val_arrays = sorted([f for f in val_source])\n",
    "test_arrays = sorted([f for f in test_source])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a single train and val image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and validation image and show them side by side\n",
    "single_train_image = train_source[train_arrays[0]]\n",
    "single_val_image = val_source[val_arrays[0]]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(single_train_image, cmap=\"gray\")\n",
    "ax[0].set_title(\"Training Image\")\n",
    "ax[1].imshow(single_val_image, cmap=\"gray\")\n",
    "ax[1].set_title(\"Validation Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "config = create_n2v_configuration(\n",
    "    experiment_name=\"bsd68_n2v\",\n",
    "    data_type=\"custom\",\n",
    "    axes=\"YX\",\n",
    "    patch_size=(64, 64),\n",
    "    batch_size=2,\n",
    "    num_epochs=n_epochs, # Because we are using the Lightning API, this is not used!\n",
    ")\n",
    "\n",
    "# TODO until the NGDataConfig is accepted by the Confiugration, these are separte\n",
    "ng_data_config = _create_ng_data_configuration(\n",
    "    data_type=config.data_config.data_type,\n",
    "    axes=config.data_config.axes,\n",
    "    patch_size=config.data_config.patch_size,\n",
    "    batch_size=config.data_config.batch_size,\n",
    "    augmentations=config.data_config.transforms,\n",
    "    train_dataloader_params=config.data_config.train_dataloader_params,\n",
    "    val_dataloader_params=config.data_config.val_dataloader_params,\n",
    "    seed=seed,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a zarr image loader\n",
    "\n",
    "Currently, the OME-Zarr reading is very basic and does not cover multiple arrays stored \n",
    "in different groups. An alternative is simply to create our own image loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An image stack loader for zarr that loads all arrays within a group.\n",
    "class ZarrSource(TypedDict):\n",
    "    zarr_group: zarr.Group\n",
    "    data_path: str\n",
    "\n",
    "def zarr_image_stack_loader(\n",
    "    source: Sequence[ZarrSource],\n",
    "    axes: str,\n",
    ") -> Sequence[ZarrImageStack]:\n",
    "    image_stacks: list[ZarrImageStack] = []\n",
    "    for data_source in source:\n",
    "        zarr_group = data_source[\"zarr_group\"]\n",
    "        data_path = data_source[\"data_path\"]\n",
    "\n",
    "        if data_path not in zarr_group:\n",
    "            raise KeyError(f\"Data does not exist at path '{data_path}'\")\n",
    "\n",
    "        image_data = zarr_group[data_path]\n",
    "        if not isinstance(image_data, zarr.Array):\n",
    "            print(f\"Zarr node at path '{data_path}' is not an Array.\")\n",
    "        else:\n",
    "            image_stacks.append(ZarrImageStack(store = zarr_group, data_path=data_path, axes=axes))\n",
    "\n",
    "    return image_stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Zarr sources for training and validation\n",
    "train_sources: Sequence[ZarrSource] = [\n",
    "    {\"zarr_group\": train_source, \"data_path\": array_name} for array_name in train_arrays\n",
    "]\n",
    "\n",
    "val_sources: Sequence[ZarrSource] = [\n",
    "    {\"zarr_group\": val_source, \"data_path\": array_name} for array_name in val_arrays\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Lightning classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_module = CareamicsDataModule(\n",
    "    data_config=ng_data_config,\n",
    "    train_data=train_sources,\n",
    "    val_data=val_sources,\n",
    "    image_stack_loader=zarr_image_stack_loader,\n",
    ")\n",
    "\n",
    "model = N2VModule(config.algorithm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually initialize the datamodule and visualize single train and val batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAUTION: if you data is large, this may take a while\n",
    "train_data_module.setup(\"fit\")\n",
    "train_data_module.setup(\"validate\")\n",
    "\n",
    "train_batch = next(iter(train_data_module.train_dataloader()))\n",
    "val_batch = next(iter(train_data_module.val_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_title(\"Training Batch\")\n",
    "for i in range(2):\n",
    "    ax[i].imshow(train_batch[0].data[i][0].numpy(), cmap=\"gray\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].set_title(\"Validation Batch\")\n",
    "for i in range(2):\n",
    "    ax[i].imshow(val_batch[0].data[i][0].numpy(), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "root = Path(\"bsd68_n2v\")\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        dirpath=root / \"checkpoints\",\n",
    "        filename=\"bsd68_zarr_lightning\",\n",
    "        save_last=True,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "    ),\n",
    "    HyperParametersCallback(config),\n",
    "]\n",
    "# logger = WandbLogger(project=\"bsd68-n2v\", name=\"bsd68_zarr_lightning\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=n_epochs,\n",
    "    limit_train_batches=200,\n",
    "    default_root_dir=root,\n",
    "    callbacks=callbacks,\n",
    "    # logger=logger\n",
    ")\n",
    "trainer.fit(model, datamodule=train_data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an inference config and datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_sources: Sequence[ZarrSource] = [\n",
    "    {\"zarr_group\": test_source, \"data_path\": array_name} for array_name in test_arrays\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.dataset_ng.legacy_interoperability import imageregions_to_tileinfos\n",
    "from careamics.prediction_utils import convert_outputs\n",
    "\n",
    "config = NGDataConfig(\n",
    "    data_type=\"custom\",\n",
    "    patching={\n",
    "        \"name\": \"tiled\",\n",
    "        \"patch_size\": (128, 128),\n",
    "        \"overlaps\": (32, 32),\n",
    "    },\n",
    "    axes=\"YX\",\n",
    "    batch_size=1,\n",
    "    image_means=train_data_module.train_dataset.input_stats.means,\n",
    "    image_stds=train_data_module.train_dataset.input_stats.stds,\n",
    ")\n",
    "\n",
    "inf_data_module = CareamicsDataModule(\n",
    "    data_config=config,\n",
    "    pred_data=test_sources,\n",
    "    image_stack_loader=zarr_image_stack_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert outputs to the legacy format and stitch the tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(model, datamodule=inf_data_module)\n",
    "tile_infos = imageregions_to_tileinfos(predictions)\n",
    "predictions = convert_outputs(tile_infos, tiled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predictions and count metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from careamics.utils.metrics import psnr, scale_invariant_psnr\n",
    "\n",
    "noises = [np.array(test_source[array_name]) for array_name in test_arrays]\n",
    "gts = [np.array(data[\"test_gt\"][f]) for f in sorted(data[\"test_gt\"])]\n",
    "\n",
    "images = [0, 1, 2]\n",
    "fig, ax = plt.subplots(3, 3, figsize=(15, 15))\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(3):\n",
    "    pred_image = predictions[images[i]].squeeze()\n",
    "    psnr_noisy = psnr(\n",
    "        gts[images[i]],\n",
    "        noises[images[i]],\n",
    "        data_range=gts[images[i]].max() - gts[images[i]].min(),\n",
    "    )\n",
    "    psnr_result = psnr(\n",
    "        gts[images[i]],\n",
    "        pred_image,\n",
    "        data_range=gts[images[i]].max() - gts[images[i]].min(),\n",
    "    )\n",
    "\n",
    "    scale_invariant_psnr_result = scale_invariant_psnr(gts[images[i]], pred_image)\n",
    "\n",
    "    ax[i, 0].imshow(noises[images[i]], cmap=\"gray\")\n",
    "    ax[i, 0].title.set_text(f\"Noisy\\nPSNR: {psnr_noisy:.2f}\")\n",
    "\n",
    "    ax[i, 1].imshow(pred_image, cmap=\"gray\")\n",
    "    ax[i, 1].title.set_text(\n",
    "        f\"Prediction\\nPSNR: {psnr_result:.2f}\\n\"\n",
    "        f\"Scale invariant PSNR: {scale_invariant_psnr_result:.2f}\"\n",
    "    )\n",
    "\n",
    "    ax[i, 2].imshow(gts[images[i]], cmap=\"gray\")\n",
    "    ax[i, 2].title.set_text(\"Ground-truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psnrs = np.zeros((len(predictions), 1))\n",
    "scale_invariant_psnrs = np.zeros((len(predictions), 1))\n",
    "\n",
    "for i, (pred, gt) in enumerate(zip(predictions, gts, strict=False)):\n",
    "    psnrs[i] = psnr(gt, pred.squeeze(), data_range=gt.max() - gt.min())\n",
    "    scale_invariant_psnrs[i] = scale_invariant_psnr(gt, pred.squeeze())\n",
    "\n",
    "print(f\"PSNR: {psnrs.mean():.2f} +/- {psnrs.std():.2f}\")\n",
    "print(\n",
    "    f\"Scale invariant PSNR: \"\n",
    "    f\"{scale_invariant_psnrs.mean():.2f} +/- {scale_invariant_psnrs.std():.2f}\"\n",
    ")\n",
    "print(\"Reported PSNR: 27.71\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
