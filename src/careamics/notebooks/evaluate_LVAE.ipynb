{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61781be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa64aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import ml_collections\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02955501",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/group/jug/federico/careamics_training/data'\n",
    "OUT_ROOT = '/group/jug/federico/careamics_training/training'\n",
    "CODE_ROOT = '/home/federico.carrara/'\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91cc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(CODE_ROOT, 'Documents/projects/careamics/src'))\n",
    "\n",
    "from careamics.train_lvae import create_dataset\n",
    "from careamics.models.lvae.utils import (\n",
    "    ModelType, LossType\n",
    ")\n",
    "from careamics.models.lvae import get_config\n",
    "from careamics.models.lvae.data_utils import DataType, DataSplitType, GridAlignement, load_tiff\n",
    "from careamics.models.lvae.metrics import (\n",
    "    PSNR, \n",
    "    RangeInvariantPsnr,\n",
    "    avg_psnr,\n",
    "    avg_range_inv_psnr,\n",
    "    avg_ssim,\n",
    "    compute_masked_psnr,\n",
    "    compute_multiscale_ssim\n",
    ")\n",
    "from careamics.models.lvae.train_utils import get_mean_std_dict_for_model\n",
    "from careamics.models.lvae.lightning_module import LadderVAELight\n",
    "from careamics.models.lvae.eval_utils import (\n",
    "    show_for_one, \n",
    "    get_plots_output_dir,\n",
    "    get_dset_predictions,\n",
    "    stitch_predictions,\n",
    "    Calibration,\n",
    "    get_calibrated_factor_for_stdev,\n",
    "    plot_calibration,\n",
    "    clean_ax,\n",
    "    plot_error\n",
    ")\n",
    "# from disentangle.analysis.lvae_utils import get_img_from_forward_output\n",
    "# from disentangle.analysis.plot_utils import get_k_largest_indices,plot_imgs_from_idx\n",
    "# from disentangle.analysis.critic_notebook_utils import get_mmse_dict, get_label_separated_loss\n",
    "# from disentangle.sampler.random_sampler import RandomSampler\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ad155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seeds():\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa968bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join(OUT_ROOT, '2406/LVAE_denoiSplit/53')\n",
    "assert os.path.exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dtype(ckpt_fpath):\n",
    "#     if os.path.isdir(ckpt_fpath):\n",
    "#         ckpt_fpath = ckpt_fpath[:-1] if ckpt_fpath[-1] == '/' else ckpt_fpath\n",
    "#     elif os.path.isfile(ckpt_fpath):\n",
    "#         ckpt_fpath = os.path.dirname(ckpt_fpath)\n",
    "#     assert ckpt_fpath[-1] != '/'\n",
    "#     return int(ckpt_fpath.split('/')[-2].split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7232e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = get_dtype(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d8d61",
   "metadata": {},
   "source": [
    "### Set Evaluation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa301f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "mmse_count = 10\n",
    "image_size_for_grid_centers = 32 # what we retain from inner padding/tiling\n",
    "eval_patch_size = None # actual patch size --> if not specified data.image_size\n",
    "data_t_list = None # list of indexes of the data to be used\n",
    "model_type = ModelType.LadderVae\n",
    "eval_datasplit_type = DataSplitType.Val    \n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'\n",
    "enable_calibration = True\n",
    "which_ckpt = 'last' # 'best', 'last'\n",
    "\n",
    "save_comparative_plots = False\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None # for training -> get one 64x64 patch at random (not from the grid)\n",
    "\n",
    "# threshold = None # 0.02\n",
    "# compute_kl_loss = False\n",
    "# evaluate_train = False # inspect training performance\n",
    "# val_repeat_factor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204ca061",
   "metadata": {},
   "source": [
    "### Load config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efc44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_checkpoint(ckpt_dir, mode='best'):\n",
    "    output = []\n",
    "    if mode == 'best':\n",
    "        for filename in glob.glob(ckpt_dir + \"/*_best.ckpt\"):\n",
    "            output.append(filename)\n",
    "    elif mode == 'last':\n",
    "        for filename in glob.glob(ckpt_dir + \"/*_last.ckpt\"):\n",
    "            output.append(filename)\n",
    "    else:\n",
    "        raise ValueError(f\"Mode can be either 'best' or 'last', while you selected {mode}.\")\n",
    "    assert len(output) == 1, '\\n'.join(output)\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c8cd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fpath):\n",
    "    if os.path.isdir(config_fpath):\n",
    "        config_fpath = os.path.join(config_fpath, 'config.pkl')\n",
    "    else:\n",
    "        assert config_fpath[-4:] == '.pkl', f'{config_fpath} is not a pickle file. Aborting'\n",
    "    with open(config_fpath, 'rb') as f:\n",
    "        config = pickle.load(f)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66365274",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(ckpt_dir):\n",
    "    config = load_config(ckpt_dir)\n",
    "else:\n",
    "    config = load_config(os.path.dirname(ckpt_dir))\n",
    "\n",
    "config = ml_collections.ConfigDict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd2e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f7d93c",
   "metadata": {},
   "source": [
    "Changing config parameters should not be needed anymore, since only few parameters of the model are customizable now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bc3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_size = None\n",
    "training_grid_size = None\n",
    "with config.unlocked():\n",
    "#     if 'test_fraction' not in config.training:\n",
    "#         config.training.test_fraction =0.0\n",
    "\n",
    "    if 'datadir' not in config:\n",
    "        config.datadir = ''\n",
    "\n",
    "#     if 'encoder' not in config.model:\n",
    "#         config.model.encoder = ml_collections.ConfigDict()\n",
    "#         assert 'decoder' not in config.model\n",
    "#         config.model.decoder = ml_collections.ConfigDict()\n",
    "    \n",
    "#         config.model.encoder.dropout = config.model.dropout\n",
    "#         config.model.decoder.dropout = config.model.dropout\n",
    "#         config.model.encoder.n_filters = config.model.n_filters\n",
    "#         config.model.decoder.n_filters = config.model.n_filters\n",
    "        \n",
    "#     if 'multiscale_retain_spatial_dims' not in config.model.decoder:\n",
    "#         config.model.decoder.multiscale_retain_spatial_dims = False\n",
    "        \n",
    "#     if 'res_block_kernel' not in config.model.encoder:\n",
    "#         config.model.encoder.res_block_kernel = 3\n",
    "#         assert 'res_block_kernel' not in config.model.decoder\n",
    "#         config.model.decoder.res_block_kernel = 3\n",
    "    \n",
    "#     if 'res_block_skip_padding' not in config.model.encoder:\n",
    "#         config.model.encoder.res_block_skip_padding = False\n",
    "#         assert 'res_block_skip_padding' not in config.model.decoder\n",
    "#         config.model.decoder.res_block_skip_padding = False\n",
    "    \n",
    "#     if 'skip_bottom_layers_count' in config.model:\n",
    "#         config.model.skip_bottom_layers_count = 0\n",
    "        \n",
    "#     if 'logvar_lowerbound' not in config.model:\n",
    "#         config.model.logvar_lowerbound = None\n",
    "    \n",
    "#     if 'train_aug_rotate' not in config.data:\n",
    "#         config.data.train_aug_rotate = False\n",
    "    \n",
    "#     if 'multiscale_lowres_separate_branch' not in config.model:\n",
    "#         config.model.multiscale_lowres_separate_branch = False\n",
    "    \n",
    "#     if 'multiscale_retain_spatial_dims' not in config.model:\n",
    "#         config.model.multiscale_retain_spatial_dims = False\n",
    "    \n",
    "#     config.data.train_aug_rotate=False\n",
    "    \n",
    "#     if 'randomized_channels' not in config.data:\n",
    "#         config.data.randomized_channels = False\n",
    "        \n",
    "    if 'predict_logvar' not in config.model:\n",
    "        config.model.predict_logvar = None\n",
    "    \n",
    "    # if 'batchnorm' in config.model and 'batchnorm' not in config.model.encoder:\n",
    "    #     assert 'batchnorm' not in config.model.decoder\n",
    "    #     config.model.decoder.batchnorm = config.model.batchnorm\n",
    "    #     config.model.encoder.batchnorm = config.model.batchnorm\n",
    "    \n",
    "#     if 'conv2d_bias' not in config.model.decoder:\n",
    "#         config.model.decoder.conv2d_bias = True\n",
    "        \n",
    "    if eval_patch_size is not None:\n",
    "        training_image_size = config.data.image_size\n",
    "        config.data.image_size = eval_patch_size\n",
    "\n",
    "    if image_size_for_grid_centers is not None:\n",
    "        training_grid_size = config.data.get('grid_size', \"grid_size not present\")\n",
    "        config.data.grid_size = image_size_for_grid_centers\n",
    "\n",
    "#     if use_deterministic_grid is not None:\n",
    "#         config.data.deterministic_grid = use_deterministic_grid\n",
    "\n",
    "#     if threshold is not None:\n",
    "#         config.data.threshold = threshold\n",
    "\n",
    "#     if val_repeat_factor is not None:\n",
    "#         config.training.val_repeat_factor = val_repeat_factor\n",
    "\n",
    "#     config.model.mode_pred = not compute_kl_loss\n",
    "    \n",
    "#     if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "#         config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "#     if 'lowres_merge_type' not in config.model.encoder:\n",
    "#         config.model.encoder.lowres_merge_type = 0\n",
    "    \n",
    "#     if 'validtarget_random_fraction' in config.data:\n",
    "#         config.data.validtarget_random_fraction = None\n",
    "\n",
    "#     if 'input_is_sum' not in config.data:\n",
    "#         config.data.input_is_sum = False\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef646b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = config.data.data_type\n",
    "\n",
    "if DEBUG:\n",
    "    if dtype == DataType.CustomSinosoid:\n",
    "        data_dir = f'{DATA_ROOT}/sinosoid/'\n",
    "    elif dtype == DataType.OptiMEM100_014:\n",
    "        data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "else:\n",
    "    if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "        data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "    elif dtype == DataType.OptiMEM100_014:\n",
    "        data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "    elif dtype == DataType.Prevedel_EMBL:\n",
    "        data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "    elif dtype == DataType.AllenCellMito:\n",
    "        data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "    elif dtype == DataType.SeparateTiffData:\n",
    "        data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "    elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "        data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "    elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "        data_dir = f'{DATA_ROOT}/pavia2'\n",
    "    elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "        data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "    elif dtype == DataType.ShroffMitoEr:\n",
    "        data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "    elif dtype == DataType.HTIba1Ki67:\n",
    "        data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "    elif dtype == DataType.BioSR_MRC:\n",
    "        data_dir = f'{DATA_ROOT}/BioSR/'\n",
    "    elif dtype == DataType.ExpMicroscopyV2:\n",
    "        data_dir = f'{DATA_ROOT}/expansion_microscopy_v2/'\n",
    "    elif dtype == DataType.TavernaSox2GolgiV2:\n",
    "        data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/acquisition2/'\n",
    "    elif dtype == DataType.Pavia3SeqData:\n",
    "        data_dir = f'{DATA_ROOT}/pavia3_sequential/'\n",
    "    elif dtype == DataType.NicolaData:\n",
    "        data_dir = f'{DATA_ROOT}/nikola_data/raw'\n",
    "        \n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60999e3b",
   "metadata": {},
   "source": [
    "### Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfbbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_kwargs = {'mode': 'constant',}\n",
    "padding_kwargs['constant_values'] = config.data.get('padding_value', 0)\n",
    "\n",
    "dloader_kwargs = {\n",
    "    'overlapping_padding_kwargs': padding_kwargs, \n",
    "    'grid_alignment': GridAlignement.Center\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, val_dset = create_dataset(\n",
    "    config, \n",
    "    data_dir, \n",
    "    eval_datasplit_type=eval_datasplit_type,\n",
    "    kwargs_dict=dloader_kwargs\n",
    ")\n",
    "data_mean, data_std = train_dset.get_mean_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ac09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset without poisson noise as ground truth\n",
    "new_config = deepcopy(ml_collections.ConfigDict(config))\n",
    "if 'poisson_noise_factor' in new_config.data:\n",
    "    new_config.data.poisson_noise_factor = -1\n",
    "if 'enable_gaussian_noise' in new_config.data:\n",
    "    new_config.data.enable_gaussian_noise = False  \n",
    "    \n",
    "_, highsnr_val_dset = create_dataset(\n",
    "    new_config, \n",
    "    data_dir, \n",
    "    eval_datasplit_type=eval_datasplit_type,\n",
    "    kwargs_dict=dloader_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c730657",
   "metadata": {},
   "outputs": [],
   "source": [
    "with config.unlocked():\n",
    "    if training_image_size is not None:\n",
    "        config.data.image_size = training_image_size\n",
    "        \n",
    "mean_dict, std_dict = get_mean_std_dict_for_model(config, train_dset)\n",
    "  \n",
    "model = LadderVAELight(\n",
    "    config, \n",
    "    mean_dict, \n",
    "    std_dict,\n",
    "    target_ch=config.data.num_channels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3f431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(ckpt_dir):\n",
    "    ckpt_fpath = get_model_checkpoint(ckpt_dir, mode=which_ckpt)\n",
    "else:\n",
    "    assert os.path.isfile(ckpt_dir)\n",
    "    ckpt_fpath = ckpt_dir\n",
    "\n",
    "print('Loading checkpoint from', ckpt_fpath)\n",
    "checkpoint = torch.load(ckpt_fpath)\n",
    "\n",
    "_ = model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "model.eval()\n",
    "_= model.cuda()\n",
    "\n",
    "model.set_params_to_same_device_as(torch.Tensor(1).cuda())\n",
    "\n",
    "print('Loading from epoch', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Model has {count_parameters(model)/1000_000:.3f}M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccae02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and eval_patch_size is not None:\n",
    "    model.reset_for_different_output_size(eval_patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8b1a0",
   "metadata": {},
   "source": [
    "### From here on we perform evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623dd899",
   "metadata": {},
   "source": [
    "Visualize Data: noisy & ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print input (first row) and target (second row) of the val_dset\n",
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "gt_inp_tmp, gt_tar_tmp, *_ = highsnr_val_dset[idx]\n",
    "\n",
    "# Noisy\n",
    "ncols = len(tar_tmp)\n",
    "nrows = 2\n",
    "_, ax = plt.subplots(figsize=(4*ncols,4*nrows), ncols=ncols, nrows=nrows)\n",
    "plt.suptitle(\"Noisy patches\")\n",
    "for i in range(min(ncols, len(inp_tmp))):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(tar_tmp[channel_id])\n",
    "    \n",
    "# Ground truth\n",
    "ncols = len(gt_tar_tmp)\n",
    "_, ax = plt.subplots(figsize=(4*ncols,4*nrows), ncols=ncols, nrows=nrows)\n",
    "plt.suptitle(\"Ground Truth patches\")\n",
    "for i in range(min(ncols, len(gt_inp_tmp))):\n",
    "    ax[0,i].imshow(gt_inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(gt_tar_tmp[channel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_t_list is not None:\n",
    "    val_dset.reduce_data(t_list=data_t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ae4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_input_frame(idx, dset):\n",
    "    img_tuples, noise_tuples = dset._load_img(idx)\n",
    "    if len(noise_tuples) > 0:\n",
    "        factor = np.sqrt(2) if dset._input_is_sum else 1.0\n",
    "        img_tuples = [x + noise_tuples[0] * factor for x in img_tuples]\n",
    "\n",
    "    inp = 0\n",
    "    for nch in img_tuples:\n",
    "        inp += nch/len(img_tuples)\n",
    "    h_start, w_start = dset._get_deterministic_hw(idx)\n",
    "    return inp, h_start, w_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f11b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(len(val_dset))\n",
    "inp, tar = val_dset[index]\n",
    "frame, h_start, w_start = get_full_input_frame(index, val_dset)\n",
    "print(h_start, w_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f13333",
   "metadata": {},
   "source": [
    "#### Plot predictions against a baseline for specific indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77918a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hwt_start(idx):\n",
    "    h,w,t = val_dset.idx_manager.hwt_from_idx(idx, grid_size=64)\n",
    "    print(h,w,t)\n",
    "    pad = val_dset.per_side_overlap_pixelcount()\n",
    "    h =  h - pad\n",
    "    w = w - pad\n",
    "    return h,w,t\n",
    "\n",
    "def get_crop_from_fulldset_prediction(full_dset_pred, idx, patch_size=256):\n",
    "    h,w,t = get_hwt_start(idx)\n",
    "    return np.swapaxes(full_dset_pred[t,h:h+patch_size,w:w+patch_size].astype(np.float32)[None], 0, 3)[...,0]\n",
    "\n",
    "if save_comparative_plots: # this is false...\n",
    "    assert eval_datasplit_type == DataSplitType.Test\n",
    "    # CCP vs Microtubules: 925, 659, 502\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_67.tif')\n",
    "    hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G32_M5_Sk0/pred_disentangle_2403_D23-M3-S0-L0_29.tif')\n",
    "\n",
    "    # ER vs Microtubule 853, 859, 332\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_60.tif')\n",
    "\n",
    "    #  ER vs CCP 327, 479, 637, 568\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_59.tif')\n",
    "\n",
    "    #  F-actin vs ER 797\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G32_M10_Sk0/pred_disentangle_2403_D23-M3-S0-L0_15.tif')\n",
    "\n",
    "    idx = 10 #np.random.randint(len(val_dset))\n",
    "    patch_size = 500\n",
    "    mmse_count = 50\n",
    "    print(idx)\n",
    "    show_for_one(\n",
    "        idx, val_dset, \n",
    "        highsnr_val_dset, \n",
    "        model, \n",
    "        None, \n",
    "        mmse_count=mmse_count, \n",
    "        patch_size=patch_size, \n",
    "        baseline_preds=[\n",
    "            get_crop_from_fulldset_prediction(hdn_usplitdata, idx).astype(np.float32),\n",
    "        ],\n",
    "        num_samples=0\n",
    "    )\n",
    "\n",
    "    plotsdir = get_plots_output_dir(\n",
    "        ckpt_dir, \n",
    "        patch_size, \n",
    "        mmse_count=mmse_count\n",
    "    )\n",
    "    \n",
    "    model_id = ckpt_dir.strip('/').split('/')[-1]\n",
    "    fname = f'patch_comparison_{idx}_{model_id}.png'\n",
    "    fpath = os.path.join(plotsdir, fname)\n",
    "    plt.savefig(fpath, dpi=200, bbox_inches='tight')\n",
    "    print(f'Saved to {fpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5310f61",
   "metadata": {},
   "source": [
    "#### Compute predictions and related metrics (PSNR) for the entire validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac092b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch-wise PSNR here\n",
    "\n",
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(\n",
    "  model, \n",
    "  val_dset,\n",
    "  batch_size,\n",
    "  num_workers=num_workers,\n",
    "  mmse_count=mmse_count,\n",
    "  model_type = model_type,\n",
    ")\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp, np.mean(tmp))\n",
    "print(f'Number of predicted tiles: {pred_tiled.shape[0]}, channels: {pred_tiled.shape[1]}, shape: {pred_tiled.shape[2:]}')\n",
    "print(f'Reconstruction loss distrib: {np.quantile(rec_loss, [0,0.01,0.5, 0.9,0.99,0.999,1]).round(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b693a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tiles in which the logvar is very low\n",
    "idx_list = np.where(logvar_tiled.squeeze() < -6)[0]\n",
    "if len(idx_list) > 0:\n",
    "    plt.imshow(val_dset[idx_list[0]][1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8822c77",
   "metadata": {},
   "source": [
    "Get full image predictions by stitching the predicted tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75b35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_tiled.shape[-1] != val_dset.get_img_sz():\n",
    "    pad = (val_dset.get_img_sz() - pred_tiled.shape[-1] )//2\n",
    "    pred_tiled = np.pad(pred_tiled, ((0,0),(0,0),(pad,pad),(pad,pad)))\n",
    "\n",
    "# Stitch tiled predictions\n",
    "pred = stitch_predictions(\n",
    "    pred_tiled, \n",
    "    val_dset, \n",
    "    smoothening_pixelcount=0\n",
    ")\n",
    "\n",
    "# Stitch predicted tiled logvar\n",
    "if len(np.unique(logvar_tiled)) == 1:\n",
    "    logvar = None\n",
    "else:\n",
    "    logvar = stitch_predictions(logvar_tiled, val_dset, smoothening_pixelcount=0)\n",
    "\n",
    "# Stitch the std of the predictions (i.e., std computed on the mmse_count predictions)\n",
    "pred_std = stitch_predictions(pred_std_tiled, val_dset, smoothening_pixelcount=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66deb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'target_idx_list' in config.data and config.data.target_idx_list is not None:\n",
    "    pred = pred[...,:len(config.data.target_idx_list)]\n",
    "    pred_std = pred_std[...,:len(config.data.target_idx_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8474735",
   "metadata": {},
   "source": [
    "Ignore (and remove) the pixels which are present in the last few rows and columns (since not multiples of patch_size)\n",
    "1. They don't come in the batches. So, in prediction, they are simply zeros. So they are being are ignored right now. \n",
    "2. For the border pixels which are on the top and the left, overlapping yields worse performance. This is becuase, there is nothing to overlap on one side. So, they are essentially zero padded. This makes the performance worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2ad25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ignored_pixels():\n",
    "    ignored_pixels = 1\n",
    "    while(pred[0, -ignored_pixels:, -ignored_pixels:,].std() == 0):\n",
    "        ignored_pixels+=1\n",
    "    ignored_pixels-=1\n",
    "    print(f'In {pred.shape}, last {ignored_pixels} many rows and columns are all zero.')\n",
    "    return ignored_pixels\n",
    "\n",
    "actual_ignored_pixels = get_ignored_pixels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadedfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.data_type in [\n",
    "    DataType.OptiMEM100_014,\n",
    "    DataType.SemiSupBloodVesselsEMBL, \n",
    "    DataType.Pavia2VanillaSplitting,\n",
    "    DataType.ExpansionMicroscopyMitoTub,\n",
    "    DataType.ShroffMitoEr,\n",
    "    DataType.HTIba1Ki67\n",
    "]:\n",
    "    ignored_last_pixels = 32 \n",
    "elif config.data.data_type == DataType.BioSR_MRC:\n",
    "    ignored_last_pixels = 44\n",
    "    if val_dset.get_img_sz() == 128:\n",
    "        ignored_last_pixels = 108\n",
    "elif config.data.data_type == DataType.NicolaData:\n",
    "    ignored_last_pixels = 8\n",
    "else:\n",
    "    ignored_last_pixels = 0\n",
    "\n",
    "ignore_first_pixels = 0\n",
    "# ignored_last_pixels = 160\n",
    "assert actual_ignored_pixels <= ignored_last_pixels, f'Set ignored_last_pixels={actual_ignored_pixels}'\n",
    "print(ignored_last_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = val_dset._data\n",
    "if 'target_idx_list' in config.data and config.data.target_idx_list is not None:\n",
    "    tar = tar[...,config.data.target_idx_list]\n",
    "\n",
    "def ignore_pixels(arr, patch_size):\n",
    "    if arr.shape[2] % patch_size:\n",
    "        if ignore_first_pixels:\n",
    "            arr = arr[:,ignore_first_pixels:,ignore_first_pixels:]\n",
    "        if ignored_last_pixels:\n",
    "            arr = arr[:,:-ignored_last_pixels,:-ignored_last_pixels]\n",
    "\n",
    "    return arr\n",
    "\n",
    "pred = ignore_pixels(pred, val_dset.get_img_sz())\n",
    "tar = ignore_pixels(tar, val_dset.get_img_sz())\n",
    "if pred_std is not None:\n",
    "    pred_std = ignore_pixels(pred_std, val_dset.get_img_sz())\n",
    "    \n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27761d4",
   "metadata": {},
   "source": [
    "#### Perform Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7311e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mean, sep_std = model.data_mean, model.data_std\n",
    "if isinstance(sep_mean, dict):\n",
    "    sep_mean = sep_mean['target']\n",
    "    sep_std = sep_std['target']\n",
    "\n",
    "if isinstance(sep_mean, int):\n",
    "    pass\n",
    "else:\n",
    "    sep_mean = sep_mean.squeeze()[None,None,None]\n",
    "    sep_std = sep_std.squeeze()[None,None,None]\n",
    "    sep_mean = sep_mean.cpu().numpy() \n",
    "    sep_std = sep_std.cpu().numpy()\n",
    "\n",
    "tar_normalized = (tar - sep_mean)/ sep_std\n",
    "\n",
    "# Check if normalization is correct (i.e., not already applied on tar)\n",
    "print(f\"Channelwise means: tar -> {tar.mean(axis=(0,1,2))}, normalized -> {tar_normalized.mean(axis=(0,1,2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a73c93",
   "metadata": {},
   "source": [
    "Plot RMV vs. RMSE without Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f39008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Recall the `pred_std` here is the pixel-wise std of the mmse_count many predictions\n",
    "if enable_calibration:\n",
    "    calib = Calibration(\n",
    "        num_bins=30, \n",
    "        mode='pixelwise'\n",
    "    )\n",
    "    native_stats = calib.compute_stats(\n",
    "        pred=pred, \n",
    "        pred_logvar=pred_std, \n",
    "        target=tar_normalized\n",
    "    )\n",
    "    count = np.array(native_stats[0]['bin_count'])\n",
    "    count = count / count.sum()\n",
    "    # print(count.cumsum()[:-1])\n",
    "    plt.plot(native_stats[0]['rmv'][1:-1], native_stats[0]['rmse'][1:-1], 'o')\n",
    "    plt.title(\"RMV vs. RMSE plot - Not Calibrated\")\n",
    "    plt.xlabel('RMV'), plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6c844",
   "metadata": {},
   "source": [
    "Observe that the plot is far from resembling y = x!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration_fnames(ckpt_dir):\n",
    "    tokens = ckpt_dir.strip('/').split('/')\n",
    "    modelid = int(tokens[-1])\n",
    "    model_specs = tokens[-2].replace('-','')\n",
    "    monthyear = tokens[-3]\n",
    "    fname_factor = f'calibration_factor_{monthyear}_{model_specs}_{modelid}.npy'\n",
    "    fname_stats = f'calibration_stats_{monthyear}_{model_specs}_{modelid}.pkl.npy'\n",
    "    return {'stats': fname_stats, 'factor': fname_factor}\n",
    "\n",
    "def get_calibration_factor_fname(ckpt_dir):\n",
    "    return get_calibration_fnames(ckpt_dir)['factor']\n",
    "\n",
    "def get_calibration_stats_fname(ckpt_dir):\n",
    "    return get_calibration_fnames(ckpt_dir)['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_calibration:\n",
    "    inp, _ = val_dset[0]\n",
    "    plotsdir = get_plots_output_dir(OUT_ROOT, inp.shape[1], mmse_count=mmse_count)\n",
    "    fname = get_calibration_factor_fname(ckpt_dir)\n",
    "    factor_fpath = os.path.join(plotsdir, fname)\n",
    "    \n",
    "    # Compute calibration factors\n",
    "    if eval_datasplit_type == DataSplitType.Val:\n",
    "        # Compute calibration factors for the channels\n",
    "        calib_factor0 = get_calibrated_factor_for_stdev(pred[...,0], np.log(pred_std[...,0]**2), tar_normalized[...,0], batch_size=8, lr=0.1)\n",
    "        calib_factor1 = get_calibrated_factor_for_stdev(pred[...,1], np.log(pred_std[...,1]**2), tar_normalized[...,1], batch_size=8, lr=0.1)\n",
    "        print(calib_factor0, calib_factor1)\n",
    "        calib_factor = np.array([calib_factor0, calib_factor1]).reshape(1,1,1,2)\n",
    "        np.save(factor_fpath, calib_factor)\n",
    "        print(f'Saved calibration factor fitted on validation set to {factor_fpath}')\n",
    "\n",
    "    # Use pre-computed calibration factor\n",
    "    elif eval_datasplit_type == DataSplitType.Test:\n",
    "        print('Loading the calibration factor from the file', factor_fpath)\n",
    "        calib_factor = np.load(factor_fpath)\n",
    "\n",
    "    # Given the calibration factor, plot RMV vs. RMSE\n",
    "    calib = Calibration(num_bins=30, mode='pixelwise')\n",
    "    pred_logvar = 2* np.log(pred_std * calib_factor)\n",
    "    stats = calib.compute_stats(\n",
    "        pred,\n",
    "        pred_logvar, \n",
    "        tar_normalized\n",
    "    )\n",
    "    _,ax = plt.subplots(figsize=(5,5))\n",
    "    plt.title(\"RMV vs. RMSE plot - Calibrated\")\n",
    "    plot_calibration(ax, stats)\n",
    "\n",
    "if eval_datasplit_type == DataSplitType.Test:\n",
    "    stats_fpath = os.path.join(plotsdir, get_calibration_stats_fname(ckpt_dir))\n",
    "    np.save(stats_fpath, stats)\n",
    "    print('Saved stats of Test set to ', stats_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2794e3",
   "metadata": {},
   "source": [
    "A fancier Calibration Plot with multiple calibration factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b747034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_index(bin_count, quantile):\n",
    "    cumsum = np.cumsum(bin_count)\n",
    "    normalized_cumsum = cumsum / cumsum[-1]\n",
    "    for i in range(1, len(normalized_cumsum)):\n",
    "        if normalized_cumsum[-i] < quantile:\n",
    "            return i - 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_first_index(bin_count, quantile):\n",
    "    cumsum = np.cumsum(bin_count)\n",
    "    normalized_cumsum = cumsum / cumsum[-1]\n",
    "    for i in range(len(normalized_cumsum)):\n",
    "        if normalized_cumsum[i] > quantile:\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb0b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    calib_factors = [\n",
    "        np.load(os.path.join('/path/to/calibration/factors/dir/', fpath), allow_pickle=True) \n",
    "        for fpath in [\n",
    "            'calibration_stats_1.pkl.npy',\n",
    "            'calibration_stats_2.pkl.npy',\n",
    "            'calibration_stats_3.pkl.npy', \n",
    "        ]\n",
    "    ]\n",
    "    labels = ['w=0.5', 'w=0.9', 'w=1']\n",
    "except FileNotFoundError:\n",
    "    print('Calibration factors not found. Skipping the plot.')\n",
    "    calib_factors = []\n",
    "\n",
    "if len(calib_factors) > 0:\n",
    "    _,ax = plt.subplots(figsize=(5,2.5))\n",
    "    for i, calibration_stats in enumerate(calib_factors):\n",
    "        first_idx = get_first_index(calibration_stats[()][0]['bin_count'], 0.0001)\n",
    "        last_idx = get_last_index(calibration_stats[()][0]['bin_count'], 0.9999)\n",
    "        ax.plot(\n",
    "            calibration_stats[()][0]['rmv'][first_idx:-last_idx],\n",
    "            calibration_stats[()][0]['rmse'][first_idx:-last_idx],\n",
    "            '-+',\n",
    "            label=labels[i]\n",
    "        )\n",
    "\n",
    "    ax.yaxis.grid(color='gray', linestyle='dashed')\n",
    "    ax.xaxis.grid(color='gray', linestyle='dashed')\n",
    "    ax.plot(np.arange(0,1.5, 0.01), np.arange(0,1.5, 0.01), 'k--')\n",
    "    ax.set_facecolor('xkcd:light grey')\n",
    "    plt.legend(loc='lower right')\n",
    "    # plt.xlim(0,3)\n",
    "    # plt.ylim(0,1.25)\n",
    "    plt.xlabel('RMV')\n",
    "    plt.ylabel('RMSE')\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "    plotsdir = get_plots_output_dir(ckpt_dir, 0, mmse_count=0)\n",
    "    model_id = ckpt_dir.strip('/').split('/')[-1]\n",
    "    fname = f'calibration_plot_{model_id}.png'\n",
    "    fpath = os.path.join(plotsdir, fname)\n",
    "    # plt.savefig(fpath, dpi=200, bbox_inches='tight')\n",
    "    print(f'Saved to {fpath}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee028b6",
   "metadata": {},
   "source": [
    "#### Visually compare Targets and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77adb410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One random target vs predicted image (patch of shape [sz x sz])\n",
    "ncols = tar.shape[-1]\n",
    "_,ax = plt.subplots(figsize=(ncols*5, 2*5), nrows=2, ncols=ncols)\n",
    "img_idx = 0\n",
    "sz = 800\n",
    "hs = np.random.randint(tar.shape[1] - sz)\n",
    "ws = np.random.randint(tar.shape[2] - sz)\n",
    "for i in range(ncols):\n",
    "    ax[i,0].set_title(f'Target Channel {i+1}')\n",
    "    ax[i,0].imshow(tar[0, hs:hs+sz, ws:ws+sz, i])\n",
    "    ax[i,1].set_title(f'Predicted Channel {i+1}')\n",
    "    ax[i,1].imshow(pred[0, hs:hs+sz, ws:ws+sz, i])\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "# clean_ax(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24708c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = pred.shape[-1]\n",
    "img_sz = 3\n",
    "_,ax = plt.subplots(figsize=(4*img_sz,nrows*img_sz), ncols=4, nrows=nrows)\n",
    "idx = np.random.randint(len(pred))\n",
    "print(idx)\n",
    "for ch_id in range(nrows):\n",
    "    ax[ch_id,0].set_title(f'Target Channel {ch_id+1}')\n",
    "    ax[ch_id,0].imshow(tar_normalized[idx,..., ch_id], cmap='magma')\n",
    "    ax[ch_id,1].set_title(f'Predicted Channel {ch_id+1}')\n",
    "    ax[ch_id,1].imshow(pred[idx,:,:,ch_id], cmap='magma')\n",
    "    plot_error(\n",
    "        tar_normalized[idx,...,ch_id], \n",
    "        pred[idx,:,:,ch_id], \n",
    "        cmap = matplotlib.cm.coolwarm, \n",
    "        ax = ax[ch_id,2], \n",
    "        max_val = None\n",
    "    )\n",
    "\n",
    "    cropsz = 256\n",
    "    h_s = np.random.randint(0, tar_normalized.shape[1] - cropsz)\n",
    "    h_e = h_s + cropsz\n",
    "    w_s = np.random.randint(0, tar_normalized.shape[2] - cropsz)\n",
    "    w_e = w_s + cropsz\n",
    "\n",
    "    plot_error(\n",
    "        tar_normalized[idx,h_s:h_e,w_s:w_e, ch_id], \n",
    "        pred[idx,h_s:h_e,w_s:w_e,ch_id], \n",
    "        cmap = matplotlib.cm.coolwarm, \n",
    "        ax = ax[ch_id,3], \n",
    "        max_val = None\n",
    "    )\n",
    "\n",
    "    # Add rectangle to the region\n",
    "    rect = patches.Rectangle((w_s, h_s), w_e-w_s, h_e-h_s, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax[ch_id,2].add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913ef45",
   "metadata": {},
   "source": [
    "#### Compute metrics between predicted data and high-SNR (ground truth) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b735d108",
   "metadata": {},
   "source": [
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919db5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch1_pred_unnorm = pred[...,0]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy()\n",
    "# ch2_pred_unnorm = pred[...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy()\n",
    "pred_unnorm = []\n",
    "for i in range(pred.shape[-1]):\n",
    "    if sep_std.shape[-1]==1:\n",
    "        temp_pred_unnorm = pred[...,i]*sep_std[...,0] + sep_mean[...,0]\n",
    "    else:\n",
    "        temp_pred_unnorm = pred[...,i]*sep_std[...,i] + sep_mean[...,i]\n",
    "    pred_unnorm.append(temp_pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get & process high-SNR data from previously loaded dataset\n",
    "highres_data = highsnr_val_dset._data\n",
    "if highres_data is not None:\n",
    "    highres_data = ignore_pixels(highres_data, highsnr_val_dset.get_img_sz()).copy()\n",
    "    if data_t_list is not None:\n",
    "        highres_data = highres_data[data_t_list].copy()\n",
    "    \n",
    "    if 'target_idx_list' in config.data and config.data.target_idx_list is not None:\n",
    "        highres_data = highres_data[...,config.data.target_idx_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896e3810",
   "metadata": {},
   "source": [
    "Compute metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if highres_data is not None:\n",
    "    print(f'{DataSplitType.name(eval_datasplit_type)}_P{eval_patch_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}')\n",
    "    psnr_list = [avg_range_inv_psnr(highres_data[...,k], pred_unnorm[k]) for k in range(len(pred_unnorm))]\n",
    "    tar_tmp = (highres_data - sep_mean) /sep_std\n",
    "    # tar0_tmp = (highres_data[...,0] - sep_mean[...,0]) /sep_std[...,0]\n",
    "    ssim_list = compute_multiscale_ssim(tar_tmp, pred)\n",
    "    # ssim1_hres_mean, ssim1_hres_std = avg_ssim(highres_data[...,0], pred_unnorm[0])\n",
    "    # ssim2_hres_mean, ssim2_hres_std = avg_ssim(highres_data[...,1], pred_unnorm[1])\n",
    "    print('PSNR on Highres', ' '.join([str(x) for x in psnr_list]))\n",
    "    print('SSIM on Highres', ' '.join([str(np.round(x,3)) for x in ssim_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc1983",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_arr = []\n",
    "psnr_arr = []\n",
    "rinv_psnr_arr = []\n",
    "ssim_arr = []\n",
    "for ch_id in range(pred.shape[-1]):\n",
    "    rmse =np.sqrt(((pred[...,ch_id] - tar_normalized[...,ch_id])**2).reshape(len(pred),-1).mean(axis=1))\n",
    "    rmse_arr.append(rmse)\n",
    "    psnr = avg_psnr(tar_normalized[...,ch_id].copy(), pred[...,ch_id].copy()) \n",
    "    rinv_psnr = avg_range_inv_psnr(tar_normalized[...,ch_id].copy(), pred[...,ch_id].copy())\n",
    "    ssim_mean, ssim_std = avg_ssim(tar[...,ch_id], pred_unnorm[ch_id])\n",
    "    psnr_arr.append(psnr)\n",
    "    rinv_psnr_arr.append(rinv_psnr)\n",
    "    ssim_arr.append((ssim_mean,ssim_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87868b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{DataSplitType.name(eval_datasplit_type)}_P{eval_patch_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}')\n",
    "print('Rec Loss: ', np.round(rec_loss.mean(),3) )\n",
    "print('RMSE: ', ' <--> '.join([str(np.mean(x).round(3)) for x in rmse_arr]))\n",
    "print('PSNR: ', ' <--> '.join([str(x) for x in psnr_arr]))\n",
    "print('RangeInvPSNR: ',' <--> '.join([str(x) for x in rinv_psnr_arr]))\n",
    "print('SSIM: ',' <--> '.join([f'{round(x,3)}Â±{round(y,4)}' for (x,y) in ssim_arr]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532b8e1",
   "metadata": {},
   "source": [
    "#### Other evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19442f1",
   "metadata": {},
   "source": [
    "##### To save to tiff file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a537930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch1_pred_unnorm = pred[...,0]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy()\n",
    "# input_pred_unnorm = pred[...,2]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy()\n",
    "# ch2_pred_unnorm = input_pred_unnorm - ch1_pred_unnorm\n",
    "# ch2_pred_unnorm = pred[...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy() #ch2_pred_unnorm - ch2_pred_unnorm.min()\n",
    "\n",
    "# ch1_pred_unnorm = ch1_pred_unnorm.astype(np.int32)\n",
    "# input_pred_unnorm = input_pred_unnorm.astype(np.int32)\n",
    "# ch2_pred_unnorm = ch2_pred_unnorm.astype(np.int32)\n",
    "\n",
    "# data = np.concatenate([val_dset._data[:,:480,:480], ch1_pred_unnorm[...,None],\n",
    "# ch2_pred_unnorm[...,None], input_pred_unnorm[...,None]],\n",
    "# axis=-1)\n",
    "\n",
    "# import tifffile\n",
    "# tifffile.imwrite(\"prediction2.tif\", \n",
    "# np.swapaxes(data[:,None],1,4)[...,0].astype(np.uint16),\n",
    "# imagej=True, \n",
    "# #  metadata={ 'axes': 'ZYXC'}, \n",
    "#  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e00983",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax  = plt.subplots(figsize=(10,5),ncols=2)\n",
    "ax[0].imshow(highsnr_val_dset._data[0,:200,:200,0])\n",
    "ax[1].imshow(val_dset._data[0,:200,:200,0])\n",
    "highsnr_val_dset._data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "break here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df298730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93db4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from disentangle.analysis.paper_plots import show_for_one\n",
    "# # show_for_one(np.random.randint(len(val_dset)), mmse_count=50, patch_size=256)\n",
    "# # show_for_one(899, mmse_count=50, patch_size=256)\n",
    "# # show_for_one(51, mmse_count=50, patch_size=256)\n",
    "# # # show_for_one(352, mmse_count=50, patch_size=256)\n",
    "# # show_for_one(872, mmse_count=50, patch_size=256)\n",
    "# # show_for_one(552, mmse_count=50, patch_size=256)\n",
    "# 656, 327, 612, 490\n",
    "# 51, 899, 352, 872, 552 ER vs Microtubules (144)\n",
    "# 716, 599, 173 CCP vs Microtubules (145)\n",
    "#  703, 189, 423 ER vs CCP (143)\n",
    "# 772, 694, 237. Adverse:630 F-actin vs Er \n",
    "idx = 716\n",
    "patch_size = 256\n",
    "mmse_count = 50\n",
    "print(idx)\n",
    "# fname = f'patch_comparison_{idx}.png'\n",
    "# show_for_one(idx, val_dset, highsnr_val_dset, model, None, mmse_count=mmse_count, patch_size=patch_size, baseline_preds=[\n",
    "#     get_crop_from_fulldset_prediction(hdn_usplitdata, idx).astype(np.float32),\n",
    "# ], num_samples=0)\n",
    "\n",
    "show_for_one(idx, val_dset, highsnr_val_dset, model, stats, mmse_count=mmse_count, patch_size=patch_size, num_samples=2)\n",
    "\n",
    "plotsdir = get_plotoutput_dir(ckpt_dir, patch_size, mmse_count=mmse_count)\n",
    "model_id = ckpt_dir.strip('/').split('/')[-1]\n",
    "fname = f'sampling_figure_{idx}_{model_id}.png'\n",
    "fpath = os.path.join(plotsdir, fname)\n",
    "plt.savefig(fpath, dpi=200, bbox_inches='tight')\n",
    "print(f'Saved to {fpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a75811",
   "metadata": {},
   "outputs": [],
   "source": [
    "break here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441abaf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "824ecf7e",
   "metadata": {},
   "source": [
    "##### Creating tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de631db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.paper_plots import get_plotoutput_dir, get_predictions\n",
    "patch_size = 256\n",
    "mmse_count = 50\n",
    "idx_list = [51, 899, 352, 872, 552, 841] # Tub vs MT\n",
    "\n",
    "\n",
    "plotsdir = get_plotoutput_dir(ckpt_dir, patch_size, mmse_count=mmse_count)\n",
    "for idx in idx_list:\n",
    "    inp, tar, tar_hsnr, recon_img_list = get_predictions(idx, val_dset, model, mmse_count=mmse_count, patch_size=patch_size)\n",
    "    highsnr_val_dset.set_img_sz(patch_size, 64)\n",
    "    highsnr_val_dset.disable_noise()\n",
    "    _, tar_hsnr = highsnr_val_dset[idx]\n",
    "    plotfpath = os.path.join(plotsdir, f'{idx}.npy')\n",
    "    np.save(plotfpath, {'inp':inp, 'tar':tar, 'tar_hsnr':tar_hsnr, 'recon_img_list':recon_img_list})\n",
    "    print(f'Generated {plotfpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e9b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict = np.load('/group/jug/ashesh/data/paper_figures/patch_256_mmse_50/2402-D16M3S0-150/841.npy', allow_pickle=True)\n",
    "plt.imshow(ddict[()]['inp'][0,0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_crops(ddict[()]['inp'], ddict[()]['tar'], ddict[()]['tar_hsnr'], ddict[()]['recon_img_list'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84bc45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "pred_unnorm = np.concatenate([ch1_pred_unnorm[...,None],\n",
    "                              ch2_pred_unnorm[...,None]],\n",
    "                              axis=-1)\n",
    "for ch_idx in [0,1]:\n",
    "    tif_fname = f'{fname_prefix}_P{eval_patch_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}_C{ch_idx}.tif'\n",
    "    tif_fpath=os.path.join('paper_tifs',tif_fname)\n",
    "    if config.data.data_type in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "        output = np.concatenate([\n",
    "                            pred_unnorm[None,:50,...,ch_idx],tar[None,:50,...,ch_idx],\n",
    "        ],axis=0)\n",
    "    else:\n",
    "        output = np.concatenate([\n",
    "                                pred_unnorm[:1,...,ch_idx],tar[:1,...,ch_idx],\n",
    "        ],axis=0)\n",
    "    imsave(tif_fpath,output,plugin='tifffile')\n",
    "    print(tif_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a8d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls -lhrt paper_tifs/2211-D8M3S0-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls paper_tifs/2211-D3M3S0-0_P64_G*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(len(val_dset))\n",
    "inp, tar = val_dset[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b56b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(inp) > 1:\n",
    "    _,ax = plt.subplots(figsize=(10,2.5),ncols=4)\n",
    "    ax[0].imshow(inp[0])\n",
    "    ax[1].imshow(inp[1])\n",
    "    ax[2].imshow(inp[2])\n",
    "    ax[3].imshow(inp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9fe5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax = plt.subplots(figsize=(10,10))\n",
    "# tmp_data =tar_unnorm[idx,:,:,1]\n",
    "# q = np.quantile(tmp_data,0.95)\n",
    "# tmp_data[tmp_data >q] = q\n",
    "# plt.imshow(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unnorm.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d38fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =  np.random.randint(len(tar_unnorm))\n",
    "print(idx)\n",
    "_,ax = plt.subplots(figsize=(20,20),ncols=2,nrows=2)\n",
    "ax[0,0].set_title('Channel 1',size=20)\n",
    "ax[0,1].set_title('Channel 2',size=20)\n",
    "ax[0,0].set_ylabel('Target',size=20)\n",
    "ax[1,0].set_ylabel('Predictions',size=20)\n",
    "ax[0,0].imshow(tar_unnorm[idx,:,:,0])\n",
    "ax[0,1].imshow(tar_unnorm[idx,:,:,1])\n",
    "ax[1,0].imshow(pred_unnorm[idx,:,:,0])\n",
    "ax[1,1].imshow(pred_unnorm[idx,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d4b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =  0#np.random.randint(len(tar_unnorm))\n",
    "print(idx)\n",
    "_,ax = plt.subplots(figsize=(20,30),ncols=2,nrows=3)\n",
    "ax[0,0].set_title('Target',size=20)\n",
    "ax[0,1].set_title('Prediction',size=20)\n",
    "ax[0,0].set_ylabel('Mixed Input',size=20)\n",
    "ax[1,0].set_ylabel('Channel 1',size=20)\n",
    "ax[2,0].set_ylabel('Channel 2',size=20)\n",
    "sz = 400\n",
    "ax[0,0].imshow(np.mean(tar_unnorm[idx, 1000:1000+sz,400:400+sz], axis=2))\n",
    "ax[0,1].imshow(np.mean(pred_unnorm[idx,1000:1000+sz,400:400+sz], axis=2))\n",
    "\n",
    "ax[1,0].imshow(tar_unnorm[idx, 1000:1000+sz,400:400+sz,0],vmax=126,vmin=88)\n",
    "ax[1,1].imshow(pred_unnorm[idx,1000:1000+sz,400:400+sz,0], vmax=126,vmin=88)\n",
    "\n",
    "ax[2,0].imshow(tar_unnorm[idx, 1000:1000+sz,400:400+sz,1],vmax=126,vmin=78)\n",
    "ax[2,1].imshow(pred_unnorm[idx,1000:1000+sz,400:400+sz,1],vmax=126,vmin=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c6d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[idx, 1000:1500,400:900,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa229c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_unnorm[idx,1000:1500,400:900,0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8285b5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f14602",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =  np.random.randint(len(tar_unnorm))\n",
    "print(idx)\n",
    "_,ax = plt.subplots(figsize=(20,30),ncols=2,nrows=3)\n",
    "ax[0,0].set_title('Target',size=20)\n",
    "ax[0,1].set_title('Prediction',size=20)\n",
    "ax[0,0].set_ylabel('Mixed Input',size=20)\n",
    "ax[1,0].set_ylabel('Channel 1',size=20)\n",
    "ax[2,0].set_ylabel('Channel 2',size=20)\n",
    "\n",
    "ax[0,0].imshow(np.mean(tar_unnorm[idx, 1000:1500,400:900], axis=2))\n",
    "ax[0,1].imshow(np.mean(pred_unnorm[idx,1000:1500,400:900], axis=2))\n",
    "\n",
    "ax[1,0].imshow(tar_unnorm[idx, 1000:1500,400:900,0])\n",
    "ax[1,1].imshow(pred_unnorm[idx,1000:1500,400:900,0])\n",
    "\n",
    "ax[2,0].imshow(tar_unnorm[idx, 1000:1500,400:900,1])\n",
    "ax[2,1].imshow(pred_unnorm[idx,1000:1500,400:900,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5306061",
   "metadata": {},
   "outputs": [],
   "source": [
    "break here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63fb49d",
   "metadata": {},
   "source": [
    "##### Comparing PSNR with high res data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe03625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.data_split_type import  get_datasplit_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_datasplit_type == DataSplitType.Val:\n",
    "    N = len(pred1)/config.training.val_fraction\n",
    "elif eval_datasplit_type == DataSplitType.Test:\n",
    "    N = len(pred1)/config.training.test_fraction\n",
    "train_idx,val_idx,test_idx = get_datasplit_tuples(config.training.val_fraction,config.training.test_fraction,N,\n",
    "                                          starting_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "highres_actin = load_tiff('/home/ashesh.ashesh/data/ventura_gigascience/actin-60x-noise2-highsnr.tif')[...,None]\n",
    "highres_mito = load_tiff('/home/ashesh.ashesh/data/ventura_gigascience/mito-60x-noise2-highsnr.tif')[...,None]\n",
    "\n",
    "if eval_datasplit_type == DataSplitType.Val:\n",
    "    highres_data = np.concatenate([highres_actin[val_idx[0]:val_idx[1]],\n",
    "                                   highres_mito[val_idx[0]:val_idx[1]]],\n",
    "                                  axis=-1).astype(np.float32)\n",
    "elif eval_datasplit_type == DataSplitType.Test:\n",
    "    highres_data = np.concatenate([highres_actin[test_idx[0]:test_idx[1]],\n",
    "                                   highres_mito[test_idx[0]:test_idx[1]]],\n",
    "                                  axis=-1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d325d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.quantile(highres_data,config.data.clip_percentile)\n",
    "highres_data[highres_data > thresh]=thresh\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daa9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,8),ncols=2,nrows=2)\n",
    "ax[0,0].imshow(tar_unnorm[5,...,0])\n",
    "ax[0,1].imshow(highres_data[5,...,0])\n",
    "ax[1,0].imshow(tar_unnorm[8,...,1])\n",
    "ax[1,1].imshow(highres_data[8,...,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53ddb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PSNR with HighRes', avg_psnr(highres_data[...,0], pred1),avg_psnr(highres_data[...,1], pred2))\n",
    "print('RangeInvPSNR with HighRes', avg_range_inv_psnr(highres_data[...,0], pred1), \n",
    "      avg_range_inv_psnr(highres_data[...,1], pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba9fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RangeInvPSNR with HighRes 16.82 18.33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_1_tmp.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8537fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.psnr import fix_range, zero_mean\n",
    "def fix_range_with_highresdata(pred,tar):\n",
    "    pred_1_tmp = torch.Tensor(pred.reshape(len(pred),-1))\n",
    "    tar_1_tmp = torch.Tensor(tar.reshape(len(tar),-1))\n",
    "    pred_1_tmp = zero_mean(pred_1_tmp)\n",
    "    tar_1_tmp = zero_mean(tar_1_tmp)\n",
    "#     import pdb;pdb.set_trace()\n",
    "    tar_1_tmp = tar_1_tmp / torch.std(tar_1_tmp, dim=1, keepdim=True)\n",
    "    \n",
    "    pred_1_tmp = fix_range(tar_1_tmp,pred_1_tmp)\n",
    "    pred_1_tmp = pred_1_tmp.reshape_as(torch.Tensor(pred))\n",
    "    tar_1_tmp = tar_1_tmp.reshape_as(torch.Tensor(pred))\n",
    "    return pred_1_tmp, tar_1_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3faaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_tmp, tar1_tmp = fix_range_with_highresdata(pred1, highres_data[...,0])\n",
    "pred2_tmp, tar2_tmp = fix_range_with_highresdata(pred2, highres_data[...,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7076ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim1_mean, ssim1_std = avg_ssim(tar1_tmp.numpy(), pred1_tmp.numpy())\n",
    "ssim2_mean, ssim2_std = avg_ssim(tar2_tmp.numpy(), pred2_tmp.numpy())\n",
    "print(ssim1_mean, ssim2_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6557f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "ax[0].imshow(pred_1_tmp[0])\n",
    "ax[1].imshow(tar_1_tmp[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c40d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "break here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f992749",
   "metadata": {},
   "source": [
    "##### Inspecting the performance on grid boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.analysis.stitch_prediction import stitched_prediction_mask\n",
    "\n",
    "\n",
    "skip_boundary_pixel_count = 0\n",
    "for sk_c in [1,16,32,48,56]:\n",
    "    mask = stitched_prediction_mask(val_dset, \n",
    "                                (val_dset._img_sz,val_dset._img_sz), \n",
    "                                skip_boundary_pixel_count, \n",
    "                                sk_c)\n",
    "    mask = ignore_pixels(mask)\n",
    "    psnr1, psnr2 = compute_masked_psnr(mask, tar1,tar2,pred1,pred2)\n",
    "    print(f'[Pad:{val_dset.per_side_overlap_pixelcount()}] SkipCentral', sk_c,\n",
    "          psnr1,psnr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7c325b",
   "metadata": {},
   "source": [
    "##### Inspecting the performance on central regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_central_pixel_count = 0\n",
    "\n",
    "for sk_b in [1,8,16,20,24]:\n",
    "    mask = stitched_prediction_mask(val_dset, \n",
    "                                (val_dset._img_sz,val_dset._img_sz), \n",
    "                                sk_b, \n",
    "                                skip_central_pixel_count)\n",
    "    mask = ignore_pixels(mask)\n",
    "    psnr1, psnr2 = compute_masked_psnr(mask, tar1,tar2,pred1,pred2)\n",
    "    print(f'[Pad:{val_dset.per_side_overlap_pixelcount()}] SkipBoundary', sk_b, psnr1,psnr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w in range(2,202,25):\n",
    "#     print(f'RangeInvPSNR but skipping {w}', avg_range_inv_psnr(np.copy(tar1[:,w:-w,w:-w]), \n",
    "#                                                                np.copy(pred1[:,w:-w,w:-w])),\n",
    "    \n",
    "#                                             avg_range_inv_psnr(np.copy(tar2[:,w:-w,w:-w]), \n",
    "#                                                                np.copy(pred2[:,w:-w,w:-w]).copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff40aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79275615",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 1200\n",
    "w = 1200\n",
    "sz = 512\n",
    "x = tar_unnorm[:1,h:h+sz,w:w+sz].mean(axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de600304",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_count = 32\n",
    "y1 = np.pad(x,np.array([[0, 0], [p_count, p_count], [p_count, p_count]]))\n",
    "y2 = np.pad(x,np.array([[0, 0], [p_count, p_count], [p_count, p_count]]), constant_values=237)\n",
    "y3 = np.pad(x,np.array([[0, 0], [p_count, p_count], [p_count, p_count]]), mode='linear_ramp', end_values=237)\n",
    "y4 = np.pad(x,np.array([[0, 0], [p_count, p_count], [p_count, p_count]]),mode='reflect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae212914",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(x, [0,0.05, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdf5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(16,4),ncols=4)\n",
    "ax[0].imshow(y1[0], )\n",
    "ax[1].imshow(y2[0], )\n",
    "ax[2].imshow(y3[0], )\n",
    "ax[3].imshow(y4[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a7a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=2)\n",
    "sns.histplot(tar_unnorm[0,:,:,0].reshape(-1,),ax=ax[0])\n",
    "sns.histplot(tar_unnorm[0,:,:,1].reshape(-1,),ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d967c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=2)\n",
    "sns.histplot(tar_unnorm[-1,:,:,0].reshape(-1,),ax=ax[0])\n",
    "sns.histplot(tar_unnorm[-1,:,:,1].reshape(-1,),ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=2)\n",
    "sns.histplot(pred_unnorm[0,:,:,0].reshape(-1,),ax=ax[0])\n",
    "sns.histplot(pred_unnorm[0,:,:,1].reshape(-1,),ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104bbfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "# import seaborn.apionly as sns\n",
    "\n",
    "_,ax = plt.subplots(figsize=(20,4))\n",
    "sns.histplot(tar_unnorm[-1,:,:].mean(axis=2).reshape(-1,))\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(25))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30034a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_unnorm[-1,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp, tar = val_dset[11060]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ed9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax = plt.subplots(figsize=(16,4),ncols=4)\n",
    "# ax[0].imshow(inp[0])\n",
    "# ax[1].imshow(inp[1])\n",
    "# ax[2].imshow(inp[2])\n",
    "# ax[3].imshow(inp[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65aeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax = plt.subplots(figsize=(8,4),ncols=2)\n",
    "# ax[0].imshow(tar[0])\n",
    "# ax[1].imshow(tar[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950f3b3a",
   "metadata": {},
   "source": [
    "##### Inspecting the difference in behaviour when different sized inputs are passed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def compute_centered_diff(big,small):\n",
    "    pad = (big.shape[-1] - small.shape[-1])//2\n",
    "#     import pdb;pdb.set_trace()\n",
    "    return big[:,:,pad:-pad,pad:-pad] - small\n",
    " \n",
    "old_img_sz = val_dset.get_img_sz()\n",
    "val_dset.set_img_sz(128)\n",
    "inp2, tar2 = val_dset[10000]\n",
    "with torch.no_grad():\n",
    "    bu_values2 = model.bottomup_pass(torch.Tensor(inp2[None]).cuda())\n",
    "\n",
    "val_dset.set_img_sz(256)\n",
    "inp3, tar3 = val_dset[10000]\n",
    "with torch.no_grad():\n",
    "    bu_values3 = model.bottomup_pass(torch.Tensor(inp3[None]).cuda())\n",
    "\n",
    "diff = (bu_values2[0] - bu_values3[0][:,:,32:-32,32:-32]).cpu().numpy()\n",
    "sns.histplot(diff.reshape(-1,))\n",
    "\n",
    "##LOOKING AT bu_values\n",
    "idx=1\n",
    "diff = compute_centered_diff(bu_values3[idx],bu_values2[idx]).cpu().numpy()\n",
    "_,ax =plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(diff[0,0])\n",
    "\n",
    "## Looking at the difference in prediction.\n",
    "with torch.no_grad():\n",
    "    out2,_ = model(torch.Tensor(inp2[None,]).cuda())\n",
    "    out3,_ = model(torch.Tensor(inp3[None,]).cuda())\n",
    "    img2 = get_img_from_forward_output(out3,model)\n",
    "    img3 = get_img_from_forward_output(out2,model)\n",
    "diff = compute_centered_diff(img2,img3)\n",
    "_,ax =plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(diff[0,1].cpu().numpy())\n",
    "val_dset.set_img_sz(old_img_sz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c561780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from disentangle.core.tiff_reader import load_tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489b52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_tiff('/home/ashesh.ashesh/data/ventura_gigascience/actin-60x-noise2-highsnr.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1b606",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=4)\n",
    "ax[0].imshow(img[0])\n",
    "ax[1].imshow(img[1])\n",
    "ax[2].imshow(img[2])\n",
    "ax[3].imshow(img[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eea97dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 =load_tiff('/home/ashesh.ashesh/data/microscopy/OptiMEM100x014.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b01f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots(figsize=(20,5),ncols=4)\n",
    "ax[0].imshow(img2[0,...,0])\n",
    "ax[1].imshow(img2[1,...,0])\n",
    "ax[2].imshow(img2[2,...,0])\n",
    "ax[3].imshow(img2[3,...,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11536e0",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp, tar = val_dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551123e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _,ax = plt.subplots(figsize=(3,3))\n",
    "plt.imshow(tar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b01d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(inp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf517837",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.436+0.810)/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usplit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "e959a19f8af3b4149ff22eb57702a46c14a8caae5a2647a6be0b1f60abdfa4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
