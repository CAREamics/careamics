{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os \n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import ml_collections\n",
    "import glob\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/group/jug/federico/careamics_training/data'\n",
    "OUT_ROOT = '/group/jug/federico/careamics_training/training'\n",
    "CODE_ROOT = '/home/federico.carrara/'\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(CODE_ROOT, 'Documents/projects/careamics/src'))\n",
    "\n",
    "from careamics.lvae_training.train_lvae import create_dataset\n",
    "from careamics.models.lvae.utils import (\n",
    "    ModelType, LossType\n",
    ")\n",
    "from careamics.models.lvae import get_config\n",
    "from careamics.lvae_training.data_utils import DataType, DataSplitType, GridAlignement, load_tiff\n",
    "from careamics.lvae_training.metrics import (\n",
    "    PSNR, \n",
    "    RangeInvariantPsnr,\n",
    "    avg_psnr,\n",
    "    avg_range_inv_psnr,\n",
    "    avg_ssim,\n",
    "    compute_masked_psnr,\n",
    "    compute_multiscale_ssim\n",
    ")\n",
    "from careamics.lvae_training.train_utils import get_mean_std_dict_for_model\n",
    "from careamics.lvae_training.lightning_module import LadderVAELight\n",
    "from careamics.lvae_training.eval_utils import (\n",
    "    show_for_one, \n",
    "    get_plots_output_dir,\n",
    "    get_dset_predictions,\n",
    "    stitch_predictions,\n",
    "    Calibration,\n",
    "    get_calibrated_factor_for_stdev,\n",
    "    plot_calibration,\n",
    "    clean_ax,\n",
    "    plot_error\n",
    ")\n",
    "# from disentangle.analysis.lvae_utils import get_img_from_forward_output\n",
    "# from disentangle.analysis.plot_utils import get_k_largest_indices,plot_imgs_from_idx\n",
    "# from disentangle.analysis.critic_notebook_utils import get_mmse_dict, get_label_separated_loss\n",
    "# from disentangle.sampler.random_sampler import RandomSampler\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seeds():\n",
    "    torch.manual_seed(0)\n",
    "    torch.cuda.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = os.path.join(OUT_ROOT, '2406/LVAE_denoiSplit/53')\n",
    "assert os.path.exists(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_dtype(ckpt_fpath):\n",
    "#     if os.path.isdir(ckpt_fpath):\n",
    "#         ckpt_fpath = ckpt_fpath[:-1] if ckpt_fpath[-1] == '/' else ckpt_fpath\n",
    "#     elif os.path.isfile(ckpt_fpath):\n",
    "#         ckpt_fpath = os.path.dirname(ckpt_fpath)\n",
    "#     assert ckpt_fpath[-1] != '/'\n",
    "#     return int(ckpt_fpath.split('/')[-2].split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = get_dtype(ckpt_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Set Evaluation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "mmse_count = 10\n",
    "image_size_for_grid_centers = 32 # what we retain from inner padding/tiling\n",
    "eval_patch_size = None # actual patch size --> if not specified data.image_size\n",
    "data_t_list = None # list of indexes of the data to be used\n",
    "model_type = ModelType.LadderVae\n",
    "eval_datasplit_type = DataSplitType.Val    \n",
    "psnr_type = 'range_invariant' #'simple', 'range_invariant'\n",
    "enable_calibration = True\n",
    "which_ckpt = 'last' # 'best', 'last'\n",
    "\n",
    "save_comparative_plots = False\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "COMPUTE_LOSS = False\n",
    "use_deterministic_grid = None # for training -> get one 64x64 patch at random (not from the grid)\n",
    "\n",
    "# threshold = None # 0.02\n",
    "# compute_kl_loss = False\n",
    "# evaluate_train = False # inspect training performance\n",
    "# val_repeat_factor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Load config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_checkpoint(ckpt_dir, mode='best'):\n",
    "    output = []\n",
    "    if mode == 'best':\n",
    "        for filename in glob.glob(ckpt_dir + \"/*_best.ckpt\"):\n",
    "            output.append(filename)\n",
    "    elif mode == 'last':\n",
    "        for filename in glob.glob(ckpt_dir + \"/*_last.ckpt\"):\n",
    "            output.append(filename)\n",
    "    else:\n",
    "        raise ValueError(f\"Mode can be either 'best' or 'last', while you selected {mode}.\")\n",
    "    assert len(output) == 1, '\\n'.join(output)\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_fpath):\n",
    "    if os.path.isdir(config_fpath):\n",
    "        config_fpath = os.path.join(config_fpath, 'config.pkl')\n",
    "    else:\n",
    "        assert config_fpath[-4:] == '.pkl', f'{config_fpath} is not a pickle file. Aborting'\n",
    "    with open(config_fpath, 'rb') as f:\n",
    "        config = pickle.load(f)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(ckpt_dir):\n",
    "    config = load_config(ckpt_dir)\n",
    "else:\n",
    "    config = load_config(os.path.dirname(ckpt_dir))\n",
    "\n",
    "config = ml_collections.ConfigDict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Changing config parameters should not be needed anymore, since only few parameters of the model are customizable now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_image_size = None\n",
    "training_grid_size = None\n",
    "with config.unlocked():\n",
    "#     if 'test_fraction' not in config.training:\n",
    "#         config.training.test_fraction =0.0\n",
    "\n",
    "    if 'datadir' not in config:\n",
    "        config.datadir = ''\n",
    "\n",
    "#     if 'encoder' not in config.model:\n",
    "#         config.model.encoder = ml_collections.ConfigDict()\n",
    "#         assert 'decoder' not in config.model\n",
    "#         config.model.decoder = ml_collections.ConfigDict()\n",
    "    \n",
    "#         config.model.encoder.dropout = config.model.dropout\n",
    "#         config.model.decoder.dropout = config.model.dropout\n",
    "#         config.model.encoder.n_filters = config.model.n_filters\n",
    "#         config.model.decoder.n_filters = config.model.n_filters\n",
    "        \n",
    "#     if 'multiscale_retain_spatial_dims' not in config.model.decoder:\n",
    "#         config.model.decoder.multiscale_retain_spatial_dims = False\n",
    "        \n",
    "#     if 'res_block_kernel' not in config.model.encoder:\n",
    "#         config.model.encoder.res_block_kernel = 3\n",
    "#         assert 'res_block_kernel' not in config.model.decoder\n",
    "#         config.model.decoder.res_block_kernel = 3\n",
    "    \n",
    "#     if 'res_block_skip_padding' not in config.model.encoder:\n",
    "#         config.model.encoder.res_block_skip_padding = False\n",
    "#         assert 'res_block_skip_padding' not in config.model.decoder\n",
    "#         config.model.decoder.res_block_skip_padding = False\n",
    "    \n",
    "#     if 'skip_bottom_layers_count' in config.model:\n",
    "#         config.model.skip_bottom_layers_count = 0\n",
    "        \n",
    "#     if 'logvar_lowerbound' not in config.model:\n",
    "#         config.model.logvar_lowerbound = None\n",
    "    \n",
    "#     if 'train_aug_rotate' not in config.data:\n",
    "#         config.data.train_aug_rotate = False\n",
    "    \n",
    "#     if 'multiscale_lowres_separate_branch' not in config.model:\n",
    "#         config.model.multiscale_lowres_separate_branch = False\n",
    "    \n",
    "#     if 'multiscale_retain_spatial_dims' not in config.model:\n",
    "#         config.model.multiscale_retain_spatial_dims = False\n",
    "    \n",
    "#     config.data.train_aug_rotate=False\n",
    "    \n",
    "#     if 'randomized_channels' not in config.data:\n",
    "#         config.data.randomized_channels = False\n",
    "        \n",
    "    if 'predict_logvar' not in config.model:\n",
    "        config.model.predict_logvar = None\n",
    "    \n",
    "    # if 'batchnorm' in config.model and 'batchnorm' not in config.model.encoder:\n",
    "    #     assert 'batchnorm' not in config.model.decoder\n",
    "    #     config.model.decoder.batchnorm = config.model.batchnorm\n",
    "    #     config.model.encoder.batchnorm = config.model.batchnorm\n",
    "    \n",
    "#     if 'conv2d_bias' not in config.model.decoder:\n",
    "#         config.model.decoder.conv2d_bias = True\n",
    "        \n",
    "    if eval_patch_size is not None:\n",
    "        training_image_size = config.data.image_size\n",
    "        config.data.image_size = eval_patch_size\n",
    "\n",
    "    if image_size_for_grid_centers is not None:\n",
    "        training_grid_size = config.data.get('grid_size', \"grid_size not present\")\n",
    "        config.data.grid_size = image_size_for_grid_centers\n",
    "\n",
    "#     if use_deterministic_grid is not None:\n",
    "#         config.data.deterministic_grid = use_deterministic_grid\n",
    "\n",
    "#     if threshold is not None:\n",
    "#         config.data.threshold = threshold\n",
    "\n",
    "#     if val_repeat_factor is not None:\n",
    "#         config.training.val_repeat_factor = val_repeat_factor\n",
    "\n",
    "#     config.model.mode_pred = not compute_kl_loss\n",
    "    \n",
    "#     if 'skip_receptive_field_loss_tokens' not in config.loss:\n",
    "#         config.loss.skip_receptive_field_loss_tokens = []\n",
    "    \n",
    "#     if 'lowres_merge_type' not in config.model.encoder:\n",
    "#         config.model.encoder.lowres_merge_type = 0\n",
    "    \n",
    "#     if 'validtarget_random_fraction' in config.data:\n",
    "#         config.data.validtarget_random_fraction = None\n",
    "\n",
    "#     if 'input_is_sum' not in config.data:\n",
    "#         config.data.input_is_sum = False\n",
    "\n",
    "# print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = config.data.data_type\n",
    "\n",
    "if DEBUG:\n",
    "    if dtype == DataType.CustomSinosoid:\n",
    "        data_dir = f'{DATA_ROOT}/sinosoid/'\n",
    "    elif dtype == DataType.OptiMEM100_014:\n",
    "        data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "else:\n",
    "    if dtype in [DataType.CustomSinosoid, DataType.CustomSinosoidThreeCurve]:\n",
    "        data_dir = f'{DATA_ROOT}/sinosoid_without_test/sinosoid/'\n",
    "    elif dtype == DataType.OptiMEM100_014:\n",
    "        data_dir = f'{DATA_ROOT}/microscopy/'\n",
    "    elif dtype == DataType.Prevedel_EMBL:\n",
    "        data_dir = f'{DATA_ROOT}/Prevedel_EMBL/PKG_3P_dualcolor_stacks/NoAverage_NoRegistration/'\n",
    "    elif dtype == DataType.AllenCellMito:\n",
    "        data_dir = f'{DATA_ROOT}/allencell/2017_03_08_Struct_First_Pass_Seg/AICS-11/'\n",
    "    elif dtype == DataType.SeparateTiffData:\n",
    "        data_dir = f'{DATA_ROOT}/ventura_gigascience'\n",
    "    elif dtype == DataType.SemiSupBloodVesselsEMBL:\n",
    "        data_dir = f'{DATA_ROOT}/EMBL_halfsupervised/Demixing_3P'\n",
    "    elif dtype == DataType.Pavia2VanillaSplitting:\n",
    "        data_dir = f'{DATA_ROOT}/pavia2'\n",
    "    elif dtype == DataType.ExpansionMicroscopyMitoTub:\n",
    "        data_dir = f'{DATA_ROOT}/expansion_microscopy_Nick/'\n",
    "    elif dtype == DataType.ShroffMitoEr:\n",
    "        data_dir = f'{DATA_ROOT}/shrofflab/'\n",
    "    elif dtype == DataType.HTIba1Ki67:\n",
    "        data_dir = f'{DATA_ROOT}/Stefania/20230327_Ki67_and_Iba1_trainingdata/'\n",
    "    elif dtype == DataType.BioSR_MRC:\n",
    "        data_dir = f'{DATA_ROOT}/BioSR/'\n",
    "    elif dtype == DataType.ExpMicroscopyV2:\n",
    "        data_dir = f'{DATA_ROOT}/expansion_microscopy_v2/'\n",
    "    elif dtype == DataType.TavernaSox2GolgiV2:\n",
    "        data_dir = f'{DATA_ROOT}/TavernaSox2Golgi/acquisition2/'\n",
    "    elif dtype == DataType.Pavia3SeqData:\n",
    "        data_dir = f'{DATA_ROOT}/pavia3_sequential/'\n",
    "    elif dtype == DataType.NicolaData:\n",
    "        data_dir = f'{DATA_ROOT}/nikola_data/raw'\n",
    "        \n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_kwargs = {'mode': 'constant',}\n",
    "padding_kwargs['constant_values'] = config.data.get('padding_value', 0)\n",
    "\n",
    "dloader_kwargs = {\n",
    "    'overlapping_padding_kwargs': padding_kwargs, \n",
    "    'grid_alignment': GridAlignement.Center\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, val_dset = create_dataset(\n",
    "    config, \n",
    "    data_dir, \n",
    "    eval_datasplit_type=eval_datasplit_type,\n",
    "    kwargs_dict=dloader_kwargs\n",
    ")\n",
    "data_mean, data_std = train_dset.get_mean_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset without poisson noise as ground truth\n",
    "new_config = deepcopy(ml_collections.ConfigDict(config))\n",
    "if 'poisson_noise_factor' in new_config.data:\n",
    "    new_config.data.poisson_noise_factor = -1\n",
    "if 'enable_gaussian_noise' in new_config.data:\n",
    "    new_config.data.enable_gaussian_noise = False  \n",
    "    \n",
    "_, highsnr_val_dset = create_dataset(\n",
    "    new_config, \n",
    "    data_dir, \n",
    "    eval_datasplit_type=eval_datasplit_type,\n",
    "    kwargs_dict=dloader_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "with config.unlocked():\n",
    "    if training_image_size is not None:\n",
    "        config.data.image_size = training_image_size\n",
    "        \n",
    "mean_dict, std_dict = get_mean_std_dict_for_model(config, train_dset)\n",
    "  \n",
    "model = LadderVAELight(\n",
    "    config, \n",
    "    mean_dict, \n",
    "    std_dict,\n",
    "    target_ch=config.data.num_channels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(ckpt_dir):\n",
    "    ckpt_fpath = get_model_checkpoint(ckpt_dir, mode=which_ckpt)\n",
    "else:\n",
    "    assert os.path.isfile(ckpt_dir)\n",
    "    ckpt_fpath = ckpt_dir\n",
    "\n",
    "print('Loading checkpoint from', ckpt_fpath)\n",
    "checkpoint = torch.load(ckpt_fpath)\n",
    "\n",
    "_ = model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "model.eval()\n",
    "_= model.cuda()\n",
    "\n",
    "model.set_params_to_same_device_as(torch.Tensor(1).cuda())\n",
    "\n",
    "print('Loading from epoch', checkpoint['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Model has {count_parameters(model)/1000_000:.3f}M parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.multiscale_lowres_count is not None and eval_patch_size is not None:\n",
    "    model.reset_for_different_output_size(eval_patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### From here on we perform evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Visualize Data: noisy & ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print input (first row) and target (second row) of the val_dset\n",
    "idx = np.random.randint(len(val_dset))\n",
    "inp_tmp, tar_tmp, *_ = val_dset[idx]\n",
    "gt_inp_tmp, gt_tar_tmp, *_ = highsnr_val_dset[idx]\n",
    "\n",
    "# Noisy\n",
    "ncols = len(tar_tmp)\n",
    "nrows = 2\n",
    "_, ax = plt.subplots(figsize=(4*ncols,4*nrows), ncols=ncols, nrows=nrows)\n",
    "plt.suptitle(\"Noisy patches\")\n",
    "for i in range(min(ncols, len(inp_tmp))):\n",
    "    ax[0,i].imshow(inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(tar_tmp[channel_id])\n",
    "    \n",
    "# Ground truth\n",
    "ncols = len(gt_tar_tmp)\n",
    "_, ax = plt.subplots(figsize=(4*ncols,4*nrows), ncols=ncols, nrows=nrows)\n",
    "plt.suptitle(\"Ground Truth patches\")\n",
    "for i in range(min(ncols, len(gt_inp_tmp))):\n",
    "    ax[0,i].imshow(gt_inp_tmp[i])\n",
    "\n",
    "for channel_id in range(ncols):\n",
    "    ax[1,channel_id].imshow(gt_tar_tmp[channel_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_t_list is not None:\n",
    "    val_dset.reduce_data(t_list=data_t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_input_frame(idx, dset):\n",
    "    img_tuples, noise_tuples = dset._load_img(idx)\n",
    "    if len(noise_tuples) > 0:\n",
    "        factor = np.sqrt(2) if dset._input_is_sum else 1.0\n",
    "        img_tuples = [x + noise_tuples[0] * factor for x in img_tuples]\n",
    "\n",
    "    inp = 0\n",
    "    for nch in img_tuples:\n",
    "        inp += nch/len(img_tuples)\n",
    "    h_start, w_start = dset._get_deterministic_hw(idx)\n",
    "    return inp, h_start, w_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(len(val_dset))\n",
    "inp, tar = val_dset[index]\n",
    "frame, h_start, w_start = get_full_input_frame(index, val_dset)\n",
    "print(h_start, w_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "#### Plot predictions against a baseline for specific indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hwt_start(idx):\n",
    "    h,w,t = val_dset.idx_manager.hwt_from_idx(idx, grid_size=64)\n",
    "    print(h,w,t)\n",
    "    pad = val_dset.per_side_overlap_pixelcount()\n",
    "    h =  h - pad\n",
    "    w = w - pad\n",
    "    return h,w,t\n",
    "\n",
    "def get_crop_from_fulldset_prediction(full_dset_pred, idx, patch_size=256):\n",
    "    h,w,t = get_hwt_start(idx)\n",
    "    return np.swapaxes(full_dset_pred[t,h:h+patch_size,w:w+patch_size].astype(np.float32)[None], 0, 3)[...,0]\n",
    "\n",
    "if save_comparative_plots: # this is false...\n",
    "    assert eval_datasplit_type == DataSplitType.Test\n",
    "    # CCP vs Microtubules: 925, 659, 502\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_67.tif')\n",
    "    hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G32_M5_Sk0/pred_disentangle_2403_D23-M3-S0-L0_29.tif')\n",
    "\n",
    "    # ER vs Microtubule 853, 859, 332\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_60.tif')\n",
    "\n",
    "    #  ER vs CCP 327, 479, 637, 568\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G16_M3_Sk0/pred_disentangle_2402_D23-M3-S0-L0_59.tif')\n",
    "\n",
    "    #  F-actin vs ER 797\n",
    "    # hdn_usplitdata = load_tiff('/group/jug/ashesh/data/paper_stats/Test_PNone_G32_M10_Sk0/pred_disentangle_2403_D23-M3-S0-L0_15.tif')\n",
    "\n",
    "    idx = 10 #np.random.randint(len(val_dset))\n",
    "    patch_size = 500\n",
    "    mmse_count = 50\n",
    "    print(idx)\n",
    "    show_for_one(\n",
    "        idx, val_dset, \n",
    "        highsnr_val_dset, \n",
    "        model, \n",
    "        None, \n",
    "        mmse_count=mmse_count, \n",
    "        patch_size=patch_size, \n",
    "        baseline_preds=[\n",
    "            get_crop_from_fulldset_prediction(hdn_usplitdata, idx).astype(np.float32),\n",
    "        ],\n",
    "        num_samples=0\n",
    "    )\n",
    "\n",
    "    plotsdir = get_plots_output_dir(\n",
    "        ckpt_dir, \n",
    "        patch_size, \n",
    "        mmse_count=mmse_count\n",
    "    )\n",
    "    \n",
    "    model_id = ckpt_dir.strip('/').split('/')[-1]\n",
    "    fname = f'patch_comparison_{idx}_{model_id}.png'\n",
    "    fpath = os.path.join(plotsdir, fname)\n",
    "    plt.savefig(fpath, dpi=200, bbox_inches='tight')\n",
    "    print(f'Saved to {fpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "#### Compute predictions and related metrics (PSNR) for the entire validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch-wise PSNR here\n",
    "\n",
    "pred_tiled, rec_loss, logvar_tiled, patch_psnr_tuple, pred_std_tiled = get_dset_predictions(\n",
    "  model, \n",
    "  val_dset,\n",
    "  batch_size,\n",
    "  num_workers=num_workers,\n",
    "  mmse_count=mmse_count,\n",
    "  model_type = model_type,\n",
    ")\n",
    "tmp = np.round([x.item() for x in patch_psnr_tuple],2)\n",
    "print('Patch wise PSNR, as computed during training', tmp, np.mean(tmp))\n",
    "print(f'Number of predicted tiles: {pred_tiled.shape[0]}, channels: {pred_tiled.shape[1]}, shape: {pred_tiled.shape[2:]}')\n",
    "print(f'Reconstruction loss distrib: {np.quantile(rec_loss, [0,0.01,0.5, 0.9,0.99,0.999,1]).round(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tiles in which the logvar is very low\n",
    "idx_list = np.where(logvar_tiled.squeeze() < -6)[0]\n",
    "if len(idx_list) > 0:\n",
    "    plt.imshow(val_dset[idx_list[0]][1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Get full image predictions by stitching the predicted tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pred_tiled.shape[-1] != val_dset.get_img_sz():\n",
    "    pad = (val_dset.get_img_sz() - pred_tiled.shape[-1] )//2\n",
    "    pred_tiled = np.pad(pred_tiled, ((0,0),(0,0),(pad,pad),(pad,pad)))\n",
    "\n",
    "# Stitch tiled predictions\n",
    "pred = stitch_predictions(\n",
    "    pred_tiled, \n",
    "    val_dset, \n",
    "    smoothening_pixelcount=0\n",
    ")\n",
    "\n",
    "# Stitch predicted tiled logvar\n",
    "if len(np.unique(logvar_tiled)) == 1:\n",
    "    logvar = None\n",
    "else:\n",
    "    logvar = stitch_predictions(logvar_tiled, val_dset, smoothening_pixelcount=0)\n",
    "\n",
    "# Stitch the std of the predictions (i.e., std computed on the mmse_count predictions)\n",
    "pred_std = stitch_predictions(pred_std_tiled, val_dset, smoothening_pixelcount=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'target_idx_list' in config.data and config.data.target_idx_list is not None:\n",
    "    pred = pred[...,:len(config.data.target_idx_list)]\n",
    "    pred_std = pred_std[...,:len(config.data.target_idx_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Ignore (and remove) the pixels which are present in the last few rows and columns (since not multiples of patch_size)\n",
    "1. They don't come in the batches. So, in prediction, they are simply zeros. So they are being are ignored right now. \n",
    "2. For the border pixels which are on the top and the left, overlapping yields worse performance. This is becuase, there is nothing to overlap on one side. So, they are essentially zero padded. This makes the performance worse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ignored_pixels():\n",
    "    ignored_pixels = 1\n",
    "    while(pred[0, -ignored_pixels:, -ignored_pixels:,].std() == 0):\n",
    "        ignored_pixels+=1\n",
    "    ignored_pixels-=1\n",
    "    print(f'In {pred.shape}, last {ignored_pixels} many rows and columns are all zero.')\n",
    "    return ignored_pixels\n",
    "\n",
    "actual_ignored_pixels = get_ignored_pixels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.data.data_type in [\n",
    "    DataType.OptiMEM100_014,\n",
    "    DataType.SemiSupBloodVesselsEMBL, \n",
    "    DataType.Pavia2VanillaSplitting,\n",
    "    DataType.ExpansionMicroscopyMitoTub,\n",
    "    DataType.ShroffMitoEr,\n",
    "    DataType.HTIba1Ki67\n",
    "]:\n",
    "    ignored_last_pixels = 32 \n",
    "elif config.data.data_type == DataType.BioSR_MRC:\n",
    "    ignored_last_pixels = 44\n",
    "    if val_dset.get_img_sz() == 128:\n",
    "        ignored_last_pixels = 108\n",
    "elif config.data.data_type == DataType.NicolaData:\n",
    "    ignored_last_pixels = 8\n",
    "else:\n",
    "    ignored_last_pixels = 0\n",
    "\n",
    "ignore_first_pixels = 0\n",
    "# ignored_last_pixels = 160\n",
    "assert actual_ignored_pixels <= ignored_last_pixels, f'Set ignored_last_pixels={actual_ignored_pixels}'\n",
    "print(ignored_last_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = val_dset._data\n",
    "if 'target_idx_list' in config.data and config.data.target_idx_list is not None:\n",
    "    tar = tar[...,config.data.target_idx_list]\n",
    "\n",
    "def ignore_pixels(arr, patch_size):\n",
    "    if arr.shape[2] % patch_size:\n",
    "        if ignore_first_pixels:\n",
    "            arr = arr[:,ignore_first_pixels:,ignore_first_pixels:]\n",
    "        if ignored_last_pixels:\n",
    "            arr = arr[:,:-ignored_last_pixels,:-ignored_last_pixels]\n",
    "\n",
    "    return arr\n",
    "\n",
    "pred = ignore_pixels(pred, val_dset.get_img_sz())\n",
    "tar = ignore_pixels(tar, val_dset.get_img_sz())\n",
    "if pred_std is not None:\n",
    "    pred_std = ignore_pixels(pred_std, val_dset.get_img_sz())\n",
    "    \n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### Perform Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_mean, sep_std = model.data_mean, model.data_std\n",
    "if isinstance(sep_mean, dict):\n",
    "    sep_mean = sep_mean['target']\n",
    "    sep_std = sep_std['target']\n",
    "\n",
    "if isinstance(sep_mean, int):\n",
    "    pass\n",
    "else:\n",
    "    sep_mean = sep_mean.squeeze()[None,None,None]\n",
    "    sep_std = sep_std.squeeze()[None,None,None]\n",
    "    sep_mean = sep_mean.cpu().numpy() \n",
    "    sep_std = sep_std.cpu().numpy()\n",
    "\n",
    "tar_normalized = (tar - sep_mean)/ sep_std\n",
    "\n",
    "# Check if normalization is correct (i.e., not already applied on tar)\n",
    "print(f\"Channelwise means: tar -> {tar.mean(axis=(0,1,2))}, normalized -> {tar_normalized.mean(axis=(0,1,2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "Plot RMV vs. RMSE without Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Recall the `pred_std` here is the pixel-wise std of the mmse_count many predictions\n",
    "if enable_calibration:\n",
    "    calib = Calibration(\n",
    "        num_bins=30, \n",
    "        mode='pixelwise'\n",
    "    )\n",
    "    native_stats = calib.compute_stats(\n",
    "        pred=pred, \n",
    "        pred_logvar=pred_std, \n",
    "        target=tar_normalized\n",
    "    )\n",
    "    count = np.array(native_stats[0]['bin_count'])\n",
    "    count = count / count.sum()\n",
    "    # print(count.cumsum()[:-1])\n",
    "    plt.plot(native_stats[0]['rmv'][1:-1], native_stats[0]['rmse'][1:-1], 'o')\n",
    "    plt.title(\"RMV vs. RMSE plot - Not Calibrated\")\n",
    "    plt.xlabel('RMV'), plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Observe that the plot is far from resembling y = x!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calibration_fnames(ckpt_dir):\n",
    "    tokens = ckpt_dir.strip('/').split('/')\n",
    "    modelid = int(tokens[-1])\n",
    "    model_specs = tokens[-2].replace('-','')\n",
    "    monthyear = tokens[-3]\n",
    "    fname_factor = f'calibration_factor_{monthyear}_{model_specs}_{modelid}.npy'\n",
    "    fname_stats = f'calibration_stats_{monthyear}_{model_specs}_{modelid}.pkl.npy'\n",
    "    return {'stats': fname_stats, 'factor': fname_factor}\n",
    "\n",
    "def get_calibration_factor_fname(ckpt_dir):\n",
    "    return get_calibration_fnames(ckpt_dir)['factor']\n",
    "\n",
    "def get_calibration_stats_fname(ckpt_dir):\n",
    "    return get_calibration_fnames(ckpt_dir)['stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if enable_calibration:\n",
    "    inp, _ = val_dset[0]\n",
    "    plotsdir = get_plots_output_dir(OUT_ROOT, inp.shape[1], mmse_count=mmse_count)\n",
    "    fname = get_calibration_factor_fname(ckpt_dir)\n",
    "    factor_fpath = os.path.join(plotsdir, fname)\n",
    "    \n",
    "    # Compute calibration factors\n",
    "    if eval_datasplit_type == DataSplitType.Val:\n",
    "        # Compute calibration factors for the channels\n",
    "        calib_factor0 = get_calibrated_factor_for_stdev(pred[...,0], np.log(pred_std[...,0]**2), tar_normalized[...,0], batch_size=8, lr=0.1)\n",
    "        calib_factor1 = get_calibrated_factor_for_stdev(pred[...,1], np.log(pred_std[...,1]**2), tar_normalized[...,1], batch_size=8, lr=0.1)\n",
    "        print(calib_factor0, calib_factor1)\n",
    "        calib_factor = np.array([calib_factor0, calib_factor1]).reshape(1,1,1,2)\n",
    "        np.save(factor_fpath, calib_factor)\n",
    "        print(f'Saved calibration factor fitted on validation set to {factor_fpath}')\n",
    "\n",
    "    # Use pre-computed calibration factor\n",
    "    elif eval_datasplit_type == DataSplitType.Test:\n",
    "        print('Loading the calibration factor from the file', factor_fpath)\n",
    "        calib_factor = np.load(factor_fpath)\n",
    "\n",
    "    # Given the calibration factor, plot RMV vs. RMSE\n",
    "    calib = Calibration(num_bins=30, mode='pixelwise')\n",
    "    pred_logvar = 2* np.log(pred_std * calib_factor)\n",
    "    stats = calib.compute_stats(\n",
    "        pred,\n",
    "        pred_logvar, \n",
    "        tar_normalized\n",
    "    )\n",
    "    _,ax = plt.subplots(figsize=(5,5))\n",
    "    plt.title(\"RMV vs. RMSE plot - Calibrated\")\n",
    "    plot_calibration(ax, stats)\n",
    "\n",
    "if eval_datasplit_type == DataSplitType.Test:\n",
    "    stats_fpath = os.path.join(plotsdir, get_calibration_stats_fname(ckpt_dir))\n",
    "    np.save(stats_fpath, stats)\n",
    "    print('Saved stats of Test set to ', stats_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "A fancier Calibration Plot with multiple calibration factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_index(bin_count, quantile):\n",
    "    cumsum = np.cumsum(bin_count)\n",
    "    normalized_cumsum = cumsum / cumsum[-1]\n",
    "    for i in range(1, len(normalized_cumsum)):\n",
    "        if normalized_cumsum[-i] < quantile:\n",
    "            return i - 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_first_index(bin_count, quantile):\n",
    "    cumsum = np.cumsum(bin_count)\n",
    "    normalized_cumsum = cumsum / cumsum[-1]\n",
    "    for i in range(len(normalized_cumsum)):\n",
    "        if normalized_cumsum[i] > quantile:\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    calib_factors = [\n",
    "        np.load(os.path.join('/path/to/calibration/factors/dir/', fpath), allow_pickle=True) \n",
    "        for fpath in [\n",
    "            'calibration_stats_1.pkl.npy',\n",
    "            'calibration_stats_2.pkl.npy',\n",
    "            'calibration_stats_3.pkl.npy', \n",
    "        ]\n",
    "    ]\n",
    "    labels = ['w=0.5', 'w=0.9', 'w=1']\n",
    "except FileNotFoundError:\n",
    "    print('Calibration factors not found. Skipping the plot.')\n",
    "    calib_factors = []\n",
    "\n",
    "if len(calib_factors) > 0:\n",
    "    _,ax = plt.subplots(figsize=(5,2.5))\n",
    "    for i, calibration_stats in enumerate(calib_factors):\n",
    "        first_idx = get_first_index(calibration_stats[()][0]['bin_count'], 0.0001)\n",
    "        last_idx = get_last_index(calibration_stats[()][0]['bin_count'], 0.9999)\n",
    "        ax.plot(\n",
    "            calibration_stats[()][0]['rmv'][first_idx:-last_idx],\n",
    "            calibration_stats[()][0]['rmse'][first_idx:-last_idx],\n",
    "            '-+',\n",
    "            label=labels[i]\n",
    "        )\n",
    "\n",
    "    ax.yaxis.grid(color='gray', linestyle='dashed')\n",
    "    ax.xaxis.grid(color='gray', linestyle='dashed')\n",
    "    ax.plot(np.arange(0,1.5, 0.01), np.arange(0,1.5, 0.01), 'k--')\n",
    "    ax.set_facecolor('xkcd:light grey')\n",
    "    plt.legend(loc='lower right')\n",
    "    # plt.xlim(0,3)\n",
    "    # plt.ylim(0,1.25)\n",
    "    plt.xlabel('RMV')\n",
    "    plt.ylabel('RMSE')\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "    plotsdir = get_plots_output_dir(ckpt_dir, 0, mmse_count=0)\n",
    "    model_id = ckpt_dir.strip('/').split('/')[-1]\n",
    "    fname = f'calibration_plot_{model_id}.png'\n",
    "    fpath = os.path.join(plotsdir, fname)\n",
    "    # plt.savefig(fpath, dpi=200, bbox_inches='tight')\n",
    "    print(f'Saved to {fpath}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "#### Visually compare Targets and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One random target vs predicted image (patch of shape [sz x sz])\n",
    "ncols = tar.shape[-1]\n",
    "_,ax = plt.subplots(figsize=(ncols*5, 2*5), nrows=2, ncols=ncols)\n",
    "img_idx = 0\n",
    "sz = 800\n",
    "hs = np.random.randint(tar.shape[1] - sz)\n",
    "ws = np.random.randint(tar.shape[2] - sz)\n",
    "for i in range(ncols):\n",
    "    ax[i,0].set_title(f'Target Channel {i+1}')\n",
    "    ax[i,0].imshow(tar[0, hs:hs+sz, ws:ws+sz, i])\n",
    "    ax[i,1].set_title(f'Predicted Channel {i+1}')\n",
    "    ax[i,1].imshow(pred[0, hs:hs+sz, ws:ws+sz, i])\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "# clean_ax(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = pred.shape[-1]\n",
    "img_sz = 3\n",
    "_,ax = plt.subplots(figsize=(4*img_sz,nrows*img_sz), ncols=4, nrows=nrows)\n",
    "idx = np.random.randint(len(pred))\n",
    "print(idx)\n",
    "for ch_id in range(nrows):\n",
    "    ax[ch_id,0].set_title(f'Target Channel {ch_id+1}')\n",
    "    ax[ch_id,0].imshow(tar_normalized[idx,..., ch_id], cmap='magma')\n",
    "    ax[ch_id,1].set_title(f'Predicted Channel {ch_id+1}')\n",
    "    ax[ch_id,1].imshow(pred[idx,:,:,ch_id], cmap='magma')\n",
    "    plot_error(\n",
    "        tar_normalized[idx,...,ch_id], \n",
    "        pred[idx,:,:,ch_id], \n",
    "        cmap = matplotlib.cm.coolwarm, \n",
    "        ax = ax[ch_id,2], \n",
    "        max_val = None\n",
    "    )\n",
    "\n",
    "    cropsz = 256\n",
    "    h_s = np.random.randint(0, tar_normalized.shape[1] - cropsz)\n",
    "    h_e = h_s + cropsz\n",
    "    w_s = np.random.randint(0, tar_normalized.shape[2] - cropsz)\n",
    "    w_e = w_s + cropsz\n",
    "\n",
    "    plot_error(\n",
    "        tar_normalized[idx,h_s:h_e,w_s:w_e, ch_id], \n",
    "        pred[idx,h_s:h_e,w_s:w_e,ch_id], \n",
    "        cmap = matplotlib.cm.coolwarm, \n",
    "        ax = ax[ch_id,3], \n",
    "        max_val = None\n",
    "    )\n",
    "\n",
    "    # Add rectangle to the region\n",
    "    rect = patches.Rectangle((w_s, h_s), w_e-w_s, h_e-h_s, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    ax[ch_id,2].add_patch(rect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "#### Compute metrics between predicted data and high-SNR (ground truth) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch1_pred_unnorm = pred[...,0]*sep_std[...,0].cpu().numpy() + sep_mean[...,0].cpu().numpy()\n",
    "# ch2_pred_unnorm = pred[...,1]*sep_std[...,1].cpu().numpy() + sep_mean[...,1].cpu().numpy()\n",
    "pred_unnorm = []\n",
    "for i in range(pred.shape[-1]):\n",
    "    if sep_std.shape[-1]==1:\n",
    "        temp_pred_unnorm = pred[...,i]*sep_std[...,0] + sep_mean[...,0]\n",
    "    else:\n",
    "        temp_pred_unnorm = pred[...,i]*sep_std[...,i] + sep_mean[...,i]\n",
    "    pred_unnorm.append(temp_pred_unnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get & process high-SNR data from previously loaded dataset\n",
    "highres_data = highsnr_val_dset._data\n",
    "if highres_data is not None:\n",
    "    highres_data = ignore_pixels(highres_data, highsnr_val_dset.get_img_sz()).copy()\n",
    "    if data_t_list is not None:\n",
    "        highres_data = highres_data[data_t_list].copy()\n",
    "    \n",
    "    if 'target_idx_list' in config.data and config.data.target_idx_list is not None:\n",
    "        highres_data = highres_data[...,config.data.target_idx_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "Compute metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "if highres_data is not None:\n",
    "    print(f'{DataSplitType.name(eval_datasplit_type)}_P{eval_patch_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}')\n",
    "    psnr_list = [avg_range_inv_psnr(highres_data[...,k], pred_unnorm[k]) for k in range(len(pred_unnorm))]\n",
    "    tar_tmp = (highres_data - sep_mean) /sep_std\n",
    "    # tar0_tmp = (highres_data[...,0] - sep_mean[...,0]) /sep_std[...,0]\n",
    "    ssim_list = compute_multiscale_ssim(tar_tmp, pred)\n",
    "    # ssim1_hres_mean, ssim1_hres_std = avg_ssim(highres_data[...,0], pred_unnorm[0])\n",
    "    # ssim2_hres_mean, ssim2_hres_std = avg_ssim(highres_data[...,1], pred_unnorm[1])\n",
    "    print('PSNR on Highres', ' '.join([str(x) for x in psnr_list]))\n",
    "    print('SSIM on Highres', ' '.join([str(np.round(x,3)) for x in ssim_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_arr = []\n",
    "psnr_arr = []\n",
    "rinv_psnr_arr = []\n",
    "ssim_arr = []\n",
    "for ch_id in range(pred.shape[-1]):\n",
    "    rmse =np.sqrt(((pred[...,ch_id] - tar_normalized[...,ch_id])**2).reshape(len(pred),-1).mean(axis=1))\n",
    "    rmse_arr.append(rmse)\n",
    "    psnr = avg_psnr(tar_normalized[...,ch_id].copy(), pred[...,ch_id].copy()) \n",
    "    rinv_psnr = avg_range_inv_psnr(tar_normalized[...,ch_id].copy(), pred[...,ch_id].copy())\n",
    "    ssim_mean, ssim_std = avg_ssim(tar[...,ch_id], pred_unnorm[ch_id])\n",
    "    psnr_arr.append(psnr)\n",
    "    rinv_psnr_arr.append(rinv_psnr)\n",
    "    ssim_arr.append((ssim_mean,ssim_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{DataSplitType.name(eval_datasplit_type)}_P{eval_patch_size}_G{image_size_for_grid_centers}_M{mmse_count}_Sk{ignored_last_pixels}')\n",
    "print('Rec Loss: ', np.round(rec_loss.mean(),3) )\n",
    "print('RMSE: ', ' <--> '.join([str(np.mean(x).round(3)) for x in rmse_arr]))\n",
    "print('PSNR: ', ' <--> '.join([str(x) for x in psnr_arr]))\n",
    "print('RangeInvPSNR: ',' <--> '.join([str(x) for x in rinv_psnr_arr]))\n",
    "print('SSIM: ',' <--> '.join([f'{round(x,3)}Â±{round(y,4)}' for (x,y) in ssim_arr]))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usplit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  },
  "vscode": {
   "interpreter": {
    "hash": "e959a19f8af3b4149ff22eb57702a46c14a8caae5a2647a6be0b1f60abdfa4c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
