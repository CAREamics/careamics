{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "from pathlib import Path\n",
    "from typing import Optional, Literal, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from careamics.config import VAEAlgorithmConfig\n",
    "from careamics.config.architectures import LVAEModel\n",
    "from careamics.config.callback_model import CheckpointModel, EarlyStoppingModel\n",
    "from careamics.config.likelihood_model import (\n",
    "    GaussianLikelihoodConfig,\n",
    "    NMLikelihoodConfig,\n",
    ")\n",
    "from careamics.config.nm_model import GaussianMixtureNMConfig, MultiChannelNMConfig\n",
    "from careamics.lightning import VAEModule\n",
    "from careamics.models.lvae.noise_models import noise_model_factory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some parameters for the current training simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size: int = 64\n",
    "\"\"\"Spatial size of the input image.\"\"\"\n",
    "target_channels: int = 2\n",
    "\"\"\"Number of channels in the target image.\"\"\"\n",
    "multiscale_count: int = 5\n",
    "\"\"\"The number of LC inputs plus one (the actual input).\"\"\"\n",
    "predict_logvar: Optional[Literal[\"pixelwise\"]] = \"pixelwise\"\n",
    "\"\"\"Whether to compute also the log-variance as LVAE output.\"\"\"\n",
    "loss_type: Optional[Literal[\"musplit\", \"denoisplit\", \"denoisplit_musplit\"]] = \"musplit\"\n",
    "\"\"\"The type of reconstruction loss (i.e., likelihood) to use.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create `Dataset` and `Dataloader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        img_size: int = 64, \n",
    "        target_ch: int = 1,\n",
    "        multiscale_count: int = 1,\n",
    "    ):\n",
    "        self.num_samples = 100\n",
    "        self.img_size = img_size\n",
    "        self.target_ch = target_ch\n",
    "        self.multiscale_count = multiscale_count\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        input_ = torch.randn(self.multiscale_count, self.img_size, self.img_size)\n",
    "        target = torch.randn(self.target_ch, self.img_size, self.img_size)\n",
    "        return input_, target\n",
    "\n",
    "def dummy_dataloader(\n",
    "    batch_size: int = 1,\n",
    "    img_size: int = 64,\n",
    "    target_ch: int = 1,\n",
    "    multiscale_count: int = 1,\n",
    "):\n",
    "    dataset = DummyDataset(\n",
    "        img_size=img_size,\n",
    "        target_ch=target_ch,\n",
    "        multiscale_count=multiscale_count,\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, num_workers=3, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = dummy_dataloader(\n",
    "    img_size=img_size,\n",
    "    target_ch=target_channels,\n",
    "    multiscale_count=multiscale_count,\n",
    ")\n",
    "input_, target = next(iter(dloader))\n",
    "input_.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instantiate the lightning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_noise_model(\n",
    "    save_path: Optional[Union[Path, str]] = None,\n",
    "    n_gaussians: int = 3,\n",
    "    n_coeffs: int = 3,\n",
    ") -> Path:\n",
    "    weights = np.random.rand(3*n_gaussians, n_coeffs)\n",
    "    nm_dict = {\n",
    "        \"trained_weight\": weights,\n",
    "        \"min_signal\": np.array([0]),\n",
    "        \"max_signal\": np.array([2**16 - 1]),\n",
    "        \"min_sigma\": 0.125,\n",
    "    }\n",
    "    out_path = Path(save_path) / \"dummy_noise_model.npz\"\n",
    "    np.savez(out_path, **nm_dict)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split_lightning_model(\n",
    "    algorithm: str,\n",
    "    loss_type: str,\n",
    "    multiscale_count: int = 1,\n",
    "    predict_logvar: Optional[Literal[\"pixelwise\"]] = None,\n",
    "    target_ch: int = 1,\n",
    "    NM_path: Optional[Path] = None,\n",
    ") -> VAEModule:\n",
    "    \"\"\"Instantiate the muSplit lightining model.\"\"\"\n",
    "    lvae_config = LVAEModel(\n",
    "        architecture=\"LVAE\",\n",
    "        input_shape=64,\n",
    "        multiscale_count=multiscale_count,\n",
    "        z_dims=[128, 128, 128, 128],\n",
    "        output_channels=target_ch,\n",
    "        predict_logvar=predict_logvar,\n",
    "    )\n",
    "\n",
    "    # gaussian likelihood\n",
    "    if loss_type in [\"musplit\", \"denoisplit_musplit\"]:\n",
    "        gaussian_lik_config = GaussianLikelihoodConfig(\n",
    "            predict_logvar=predict_logvar,\n",
    "            logvar_lowerbound=0.0,\n",
    "        )\n",
    "    else:\n",
    "        gaussian_lik_config = None\n",
    "    # noise model likelihood\n",
    "    if loss_type in [\"denoisplit\", \"denoisplit_musplit\"]:\n",
    "        if NM_path is None:\n",
    "            NM_path = create_dummy_noise_model(Path(\"./\"), 3, 3)\n",
    "        gmm = GaussianMixtureNMConfig(\n",
    "            model_type=\"GaussianMixtureNoiseModel\",\n",
    "            path=NM_path,\n",
    "        )\n",
    "        noise_model_config = MultiChannelNMConfig(noise_models=[gmm] * target_ch)\n",
    "        nm = noise_model_factory(noise_model_config)\n",
    "        nm_lik_config = NMLikelihoodConfig(noise_model=nm)\n",
    "    else:\n",
    "        noise_model_config = None\n",
    "        nm_lik_config = None\n",
    "\n",
    "    vae_config = VAEAlgorithmConfig(\n",
    "        algorithm_type=\"vae\",\n",
    "        algorithm=algorithm,\n",
    "        loss=loss_type,\n",
    "        model=lvae_config,\n",
    "        gaussian_likelihood_model=gaussian_lik_config,\n",
    "        noise_model=noise_model_config,\n",
    "        noise_model_likelihood_model=nm_lik_config,\n",
    "    )\n",
    "\n",
    "    return VAEModule(\n",
    "        algorithm_config=vae_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = \"musplit\" if loss_type == \"musplit\" else \"denoisplit\"\n",
    "lightning_model = create_split_lightning_model(\n",
    "    algorithm=algo,\n",
    "    loss_type=loss_type,\n",
    "    multiscale_count=multiscale_count,\n",
    "    predict_logvar=predict_logvar,\n",
    "    target_ch=target_channels,\n",
    "    NM_path=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set utils for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from careamics.lvae_training.train_utils import get_new_model_version\n",
    "\n",
    "def get_new_model_version(model_dir: Union[Path, str]) -> int:\n",
    "    \"\"\"Create a unique version ID for a new model run.\"\"\"\n",
    "    versions = []\n",
    "    for version_dir in os.listdir(model_dir):\n",
    "        try:\n",
    "            versions.append(int(version_dir))\n",
    "        except:\n",
    "            print(\n",
    "                f\"Invalid subdirectory:{model_dir}/{version_dir}. Only integer versions are allowed\"\n",
    "            )\n",
    "            exit()\n",
    "    if len(versions) == 0:\n",
    "        return \"0\"\n",
    "    return f\"{max(versions) + 1}\"\n",
    "\n",
    "def get_workdir(\n",
    "    root_dir: str,\n",
    "    model_name: str,\n",
    ") -> tuple[Path, Path]:\n",
    "    \"\"\"Get the workdir for the current model.\n",
    "    \n",
    "    It has the following structure: \"root_dir/YYMM/model_name/version\"\n",
    "    \"\"\"\n",
    "    rel_path = datetime.now().strftime(\"%y%m\")\n",
    "    cur_workdir = os.path.join(root_dir, rel_path)\n",
    "    Path(cur_workdir).mkdir(exist_ok=True)\n",
    "\n",
    "    rel_path = os.path.join(rel_path, model_name)\n",
    "    cur_workdir = os.path.join(root_dir, rel_path)\n",
    "    Path(cur_workdir).mkdir(exist_ok=True)\n",
    "\n",
    "    rel_path = os.path.join(rel_path, get_new_model_version(cur_workdir))\n",
    "    cur_workdir = os.path.join(root_dir, rel_path)\n",
    "    try:\n",
    "        Path(cur_workdir).mkdir(exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        print(\n",
    "            f\"Workdir {cur_workdir} already exists.\"\n",
    "        )\n",
    "    return cur_workdir, rel_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/group/jug/federico/careamics_training/refac_v2/\"\n",
    "workdir, exp_tag = get_workdir(ROOT_DIR, \"dummy_debugging\")\n",
    "print(f\"Current workdir: {workdir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logger\n",
    "custom_logger = WandbLogger(\n",
    "    name=os.path.join(socket.gethostname(), exp_tag),\n",
    "    save_dir=workdir,\n",
    "    project=\"careamics_debugging_LVAE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks (e.g., ModelCheckpoint, EarlyStopping, etc.)\n",
    "early_stopping_config = EarlyStoppingModel(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=1e-6,\n",
    "    patience=10,\n",
    "    mode=\"min\",\n",
    "    verbose=True,\n",
    ")\n",
    "checkpoint_config = CheckpointModel(\n",
    "    monitor=\"val_loss\",\n",
    "    save_top_k=2,\n",
    "    mode=\"min\",\n",
    ")\n",
    "custom_callbacks = [\n",
    "    EarlyStopping(**early_stopping_config.model_dump()), \n",
    "    ModelCheckpoint(**checkpoint_config.model_dump()),\n",
    "    LearningRateMonitor(logging_interval=\"epoch\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save AlgorithmConfig\n",
    "with open(os.path.join(workdir, \"algorithm_config.json\"), \"w\") as f:\n",
    "    f.write(lightning_model.algorithm_config.model_dump_json())\n",
    "\n",
    "custom_logger.experiment.config.update(\n",
    "    lightning_model.algorithm_config.model_dump()    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_progress_bar=True,\n",
    "    logger=custom_logger,\n",
    "    callbacks=custom_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(\n",
    "    model=lightning_model,\n",
    "    train_dataloaders=dloader,\n",
    "    val_dataloaders=dloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_lvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
