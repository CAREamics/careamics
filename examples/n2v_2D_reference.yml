# Name, composed of letters, numbers, spaces, dashes and underscores
experiment_name: N2V_SEM

# Working directory (logs, models, etc), its parent folder must exist
working_directory: n2v_sem

# Optional
# Absolute or relative (wrt working_directory) path to model
# trained_model: best_model.pth

algorithm:
  # Loss, currently only n2v is supported
  loss: n2v

  # Model, currently only UNet is supported
  model: UNet

  # Dimensions 2D (False) or 3D (True)
  is_3D: True

  # Optional, masking strategy, currently only default is supported
  # masking_strategy: default
  # Optional, percentage of masked pixel per patch (between 0.1 and 20%)
  # masked_pixel_percentage: 0.2
  # Optional, parameters of the model
  # model_parameters:
  #   # Depth betwen 1 and 10
  #   depth: 2
  #   # Number of filters of the first level, must be divisible by 2
  #   num_filter_base: 96

training:
  # Number of epochs, greater or equal than 1
  num_epochs: 100

  # Patch size, 2D or 3D, divisible by 2
  patch_size: [64, 64]

  # Batch size, greater or equal than 1
  batch_size: 128

  # Optimizer
  optimizer:
    # Name, one of Adam or SGD
    name: Adam

    # Optional, parameters of the optimizer
    # see https://pytorch.org/docs/stable/optim.html#algorithms
    # parameters:
    #   lr: 0.0004

  # Learning rate scheduler
  lr_scheduler:
    # Name, one of ReduceLROnPlateau or StepLR
    name: ReduceLROnPlateau

    # Optional, parameters of the learning rate scheduler
    # see https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
    # parameters:
    #   mode: min

  # Extraction strategy, one of random or sequential
  extraction_strategy: random

  # Use augmentation (True or False)
  augmentation: True

  # Optional, use WandB (True or False), must be installed in your conda environment
  # use_wandb: True

  # Optional, number of workers for data loading, greater or equal than 0
  num_workers: 0

  # Optional, automatic mixed precision
  # amp:
  #   # Use (True or False)
  #   use: False

  #   # Optional, scaling parameter for mixed precision training, power of 2 recommended.
  #   # minimum is 512, maximum is 65536
  #   # init_scale: 1024

data:
  # Extension of the data, one of npy, tiff and tif
  data_format: npy

  # Axes, among STCZYX with constraints on order
  axes: SYX

  # Optional, path to the data, absolute or relative to working_directory
  training_path: data/training
  # validation_path: data/validation
  # prediction_path: data/prediction

# Optional
prediction:
  # Whether to use tiling or not (True or False).
  # If True, then tile_shape and overlaps must be specified
  use_tiling: True

  # Optional, tile shape for tiled prediction, 2D or 3D, divisible by 2
  tile_shape: [64, 64]

  # Optional, overlap for tiled prediction, 2D or 3D, divisible by 2, smaller than
  # tile shape
  overlaps: [48, 48]
